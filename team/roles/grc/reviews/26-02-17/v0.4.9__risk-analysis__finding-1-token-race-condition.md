# v0.4.9 — Risk Analysis: Finding #1 — Token Race Condition

**Version:** v0.4.9
**Date:** 2026-02-17
**Roles:** GRC (lead), AppSec, Architect
**Incident:** INC-002
**Finding:** #1 — Token auth bypass via race condition
**Human concern:** "The current solution is worse than the problem — adding more complexity to the architecture is also a big risk."

---

## Executive Summary

The token race condition allows concurrent requests to bypass token usage limits. The impact is **quota bypass** — an attacker can make more uploads than their token allows. The impact is **not** data breach — the server stores only encrypted bytes regardless of how many uploads occur.

Three possible fix approaches exist, ranging from zero-change (accept the risk) to major architecture change (DynamoDB). After applying the risk decision matrix, **we recommend reclassifying this to P5 and accepting the risk with monitoring**, not P3 with an immediate fix. The architectural complexity of a proper fix introduces more risk than it removes at the current stage of the product.

---

## The Vulnerability: What Actually Happens

### The Code Path

```
Service__Tokens.use() — lines 38-65 of Service__Tokens.py

1. READ:  token_data = cache_client.token__lookup(token_name)     ← 2 HTTP calls
2. CHECK: if usage_count >= usage_limit → reject
3. MODIFY: token_data['usage_count'] += 1                         ← in memory only
4. RESOLVE: cache_id = cache_client.token__lookup_cache_id(...)   ← 1 HTTP call
5. WRITE: cache_client.token__update(cache_id, token_data)        ← 1 HTTP call (blind overwrite)
```

The race window spans 4 sequential HTTP calls to an external cache service (~40-400ms). Two concurrent Lambda invocations both read `usage_count=49` (limit=50), both pass the check, both increment to 50, both write. The token is used 51 times instead of 50.

### What the Attacker Gets

| If race is exploited... | Attacker gains... | Data exposure? |
|------------------------|-------------------|---------------|
| Token used beyond limit | More uploads than quota allows | **No** — uploads are encrypted bytes the server cannot decrypt |
| Multiple concurrent uploads | More ciphertext stored on server | **No** — ciphertext without key is worthless |
| Usage count inaccurate | Audit trail shows wrong count | **Minor** — usage count is operational, not security-critical |

### What the Attacker Does NOT Get

- Access to any plaintext (server never has it)
- Access to decryption keys (never sent to server)
- Access to other users' data (tokens are scoped)
- Ability to read any transfer content
- Admin access (separate auth mechanism)
- Anything that compromises confidentiality or integrity of user data

---

## Threat Model: Five Scenarios

### Scenario 1: Malicious User Bypasses Quota

**Attacker:** Someone with a valid token (e.g., `linkedin-user`)
**Goal:** Upload more files than the token allows
**Method:** Script sends 20 concurrent upload requests
**Outcome:** Token with `usage_limit=50` gets used 65 times instead of 50
**Actual impact:** 15 extra encrypted blobs stored. Server cannot read any of them. Cost: ~pennies in storage. No data breach.
**Likelihood:** Low — requires writing a script, having a valid token, and caring enough to bypass a soft quota
**Severity per framework:** Q1=quota bypass (P4-P6), Q2=1 precondition (valid token), Q4=architecture change to fix

### Scenario 2: Attacker Uses Stolen Token Beyond Limits

**Attacker:** Someone who obtained a token they shouldn't have
**Goal:** Abuse the token for maximum uploads before it's exhausted
**Method:** Concurrent requests to extend token lifetime
**Outcome:** Gets more uploads than limit allows
**Actual impact:** The token theft is the real problem, not the race condition. Even with perfect atomicity, the attacker still has a valid token. The race gives them maybe 20% more uploads — from 50 to ~60. The damage from the stolen token (50 valid uploads of potentially abusive content) vastly exceeds the marginal damage from the race (10 extra uploads).
**Likelihood:** Low — requires token theft first
**Severity per framework:** The race is secondary to the token theft itself

### Scenario 3: Cost Exhaustion Attack

**Attacker:** Someone trying to run up our AWS bill
**Goal:** Upload maximum data to inflate storage costs
**Method:** Concurrent requests with maximum payload size
**Outcome:** Bypasses usage limit, uploads more data
**Actual impact:** Lambda has a 6MB payload limit. Even with 100 extra uploads beyond quota, that's 600MB of ciphertext. At S3 pricing ($0.023/GB/month), this costs ~$0.01/month. The Lambda invocation cost is higher than the storage cost, and Lambda has its own concurrency limits.
**Likelihood:** Very low — there are far cheaper ways to cost-attack an AWS account
**Severity per framework:** Q1=denial of service/cost (P4-P6), cost is negligible

### Scenario 4: Malware Distribution via Extended Quota

**Attacker:** Someone distributing malware via encrypted links
**Goal:** Distribute more malware payloads than quota allows
**Method:** Race condition to extend token lifetime
**Outcome:** More malicious payloads uploaded
**Actual impact:** This is the Firefox Send abuse scenario. But the race condition is not the enabling factor — the attacker already has a valid token and can distribute 50 payloads without exploiting any bug. The race gives them marginally more. The real mitigation is abuse detection and token revocation, not atomic counters.
**Likelihood:** The abuse risk exists with or without the race condition
**Severity per framework:** The race is not the attack vector — the token itself is

### Scenario 5: Future State — Real Users, Real Data, High Traffic

**Attacker:** In a future production environment with paying customers
**Goal:** Bypass enterprise-tier usage limits
**Method:** Same race condition, but now quotas are monetised
**Outcome:** Customer uses more than their paid tier allows
**Actual impact:** Revenue loss (customer gets free usage). Still no data breach. This is the strongest argument for eventually fixing it — but only when quotas are tied to revenue.
**Likelihood:** Depends on business model maturity
**Severity per framework:** P4 when monetised quotas exist. Not relevant today.

---

## Fix Options: Risk Assessment

### Option A: Accept the Risk (Zero Change)

**What changes:** Nothing. Document the race condition as a known, accepted risk.
**Risk of the vulnerability:** Quota bypass. Extra encrypted blobs stored. No data exposure.
**Risk of the fix:** Zero — no change means no new bugs.
**New failure modes:** None.
**Operational cost:** None.
**Monitoring:** Add a log line when `usage_count` exceeds `usage_limit` (one-line change). Alert on anomalous patterns.

**Risk acceptance statement:**
- Token race condition allows quota bypass of ~20% with concurrent requests
- Impact is limited to extra ciphertext storage (server cannot decrypt)
- No data confidentiality, integrity, or availability impact
- Cost impact is negligible ($0.01/month per 100 extra uploads)
- Accept until: (a) quotas are monetised, or (b) abuse detection flags anomalous patterns
- Re-evaluate at production launch or when pricing tiers are implemented

### Option B: Optimistic Locking via Version Field (Medium Change)

**What changes:** Add a `version` field to token data. On update, include `expected_version` — cache service rejects if version doesn't match. Retry on conflict.

```python
# Conceptual change in Service__Tokens.use():
token_data = cache_client.token__lookup(token_name)
version = token_data.get('version', 0)
token_data['usage_count'] += 1
token_data['version'] = version + 1
result = cache_client.token__update_if_version(cache_id, token_data, expected_version=version)
if not result.success:
    # Conflict — retry from the top
    return self.use(token_name, action)  # retry
```

**Risk of the vulnerability (after fix):** Eliminated for this code path.
**Risk of the fix:**
- Requires cache service to support conditional updates (does it? **unknown — needs research**)
- Retry logic introduces new failure modes: infinite retry loops, retry storms under load
- If cache service doesn't support CAS, this option is not viable without modifying the cache service too
- Partial fix: only covers `Service__Tokens.use()`, not `Transfer__Service` race (#23)

**New failure modes:**
- Retry storm under high concurrency (all requests conflict, all retry, all conflict again)
- Cache service version check has its own race window if not implemented atomically
- Error handling for "max retries exceeded" — does the request fail open or closed?

**Operational cost:** Medium — new retry logic to monitor, new error states to handle.

### Option C: DynamoDB Atomic Counter (Major Architecture Change)

**What changes:** Replace cache service token storage with DynamoDB. Use `UpdateExpression ADD usage_count :val` with `ConditionExpression usage_count < :limit`.

**Risk of the vulnerability (after fix):** Eliminated.
**Risk of the fix:**
- **New AWS dependency** — DynamoDB is a new service in the architecture. New IAM permissions, new cost model, new failure modes, new monitoring.
- **Migration** — existing tokens in cache service must be migrated or dual-read.
- **Cache service still used for everything else** — now two storage backends for related data (tokens in DynamoDB, transfers in cache/Memory-FS). Architectural split increases cognitive load.
- **DynamoDB has its own failure modes** — provisioned throughput exceeded, conditional check failures, eventual consistency on reads (unless using strongly consistent reads at 2x cost).
- **osbot-aws dependency** — must go through `osbot-aws`, never boto3 directly. Need to verify DynamoDB support in osbot-aws.
- **Testing** — in-memory tests now need a DynamoDB mock or LocalStack. This contradicts the "no mocks" principle.

**New failure modes:**
- DynamoDB throttling under burst load
- Network partition between Lambda and DynamoDB (different from cache service network partition — now two external dependencies that can fail independently)
- Conditional check failure handling (does it retry? fail open? fail closed?)
- Migration bugs (token exists in cache but not DynamoDB, or vice versa)
- IAM permission misconfiguration (new attack surface)

**Operational cost:** High — new service to monitor, new costs, new deployment configuration, new IAM policies, new failure modes to handle in on-call runbooks.

### Option D: S3 Conditional Write (Major Architecture Change)

**What changes:** Use S3 conditional writes (If-None-Match / If-Match with ETags) for token state.

**Risk of the vulnerability (after fix):** Partially eliminated (S3 conditional writes have their own consistency model).
**Risk of the fix:**
- S3 conditional writes are relatively new (2024) and have specific semantics
- S3 eventual consistency for reads means the race window is reduced but not eliminated in all cases
- Same migration concerns as Option C
- S3 is already in the architecture for file storage, so less new surface than DynamoDB

**New failure modes:** S3 conditional write failures, ETag mismatch handling, eventual consistency edge cases.
**Operational cost:** Medium-high.

---

## Comparative Risk Matrix

| Dimension | Option A (Accept) | Option B (Version) | Option C (DynamoDB) | Option D (S3 Conditional) |
|-----------|-------------------|-------------------|--------------------|-----------------------|
| **Vulnerability risk remaining** | Quota bypass (~20% over-usage) | Eliminated (if cache supports CAS) | Eliminated | Mostly eliminated |
| **Data breach risk remaining** | None (same as today) | None | None | None |
| **New failure modes** | 0 | 2-3 (retry storm, max retry, version check race) | 5+ (throttle, partition, migration, IAM, conditional check) | 3-4 (conditional write, ETag, consistency, migration) |
| **New dependencies** | 0 | 0 (if cache supports it) or 1 | 1 (DynamoDB) | 0 (S3 already used) |
| **New attack surface** | 0 | Minimal | New IAM policies, new service endpoint | Minimal |
| **Implementation effort** | Zero | Medium (+ cache service research) | High | High |
| **Testing complexity** | Zero | Low | High (LocalStack or new mock — conflicts with no-mock principle) | Medium |
| **Operational burden** | Zero | Low | High (new service monitoring) | Medium |
| **Reversibility** | N/A | Easy | Hard (migration) | Medium |

---

## AppSec Assessment

The race condition is real and the window is wide (~40-400ms, easily scriptable). From a pure vulnerability perspective, it's exploitable.

However, applying the risk decision matrix:

- **Q1 (What happens?):** Quota bypass. No data exposure. Impact class = "quota/rate bypass" → P4-P6.
- **Q2 (Preconditions?):** 1 — needs a valid token. Adjustment: -0 to -1.
- **Q3 (Known?):** Now known. Classify as known/accepted if we decide to accept.
- **Q4 (Fix risk?):** Options B-D all introduce medium to high fix risk. Option A is zero risk.
- **Q5 (Pragmatic decision?):** The fix risk (new dependencies, failure modes, architectural complexity) exceeds the vulnerability risk (quota bypass on encrypted-only data).

**AppSec recommendation:** Reclassify to **P5**. Accept with monitoring. Add a usage-count anomaly log. Re-evaluate when quotas are monetised or when the abuse detection system is built.

The one exception: if we discover a scenario where quota bypass leads to a cost explosion (e.g., unbounded Lambda concurrency × large payloads × S3 storage), the severity would increase. But with Lambda's 6MB limit and natural concurrency throttling, this is not realistic at current scale.

---

## Architect Assessment

From an architecture perspective, Options C and D are the "correct" solutions — they solve the problem properly. But they solve it at the wrong time.

**Current architecture:** Memory-FS abstraction with pluggable backends. The beauty of this design is simplicity — the application doesn't know or care what backend is active. Adding DynamoDB for one counter breaks this abstraction. Now the token service has a different storage model from the transfer service, creating architectural inconsistency.

**The real fix is upstream:** When we move to a production storage backend (S3 + DynamoDB), atomic operations should be a property of the storage layer, not bolted onto individual services. The Storage_FS abstraction should provide atomic increment as a primitive. This is a design decision for the production architecture, not a hotfix for a quota bypass.

**Architect recommendation:** Don't fix the race condition in isolation. Fix it as part of the production storage architecture work. In the meantime, accept the risk. The simplicity of the current system is a feature, not a bug.

---

## GRC Risk Classification

Applying the vulnerability classification framework:

```
Finding:        #1 — Token auth bypass via race condition
Our Severity:   P5 (reclassified from P3)
Impact Class:   Quota/rate bypass — no data exposure
Preconditions:  1 (valid token required)
Known/Unknown:  Now known — classify as known/accepted
Fix Risk:       HIGH — all fix options introduce architectural complexity,
                new dependencies, or new failure modes that exceed the
                vulnerability's actual impact

Decision:       ACCEPT WITH MONITORING
Rationale:      Server stores only encrypted bytes. Quota bypass has no
                confidentiality, integrity, or availability impact on user
                data. Fix options (DynamoDB, S3 conditional, CAS) add
                more risk (new failure modes, new dependencies, architectural
                inconsistency) than they remove. The race window is real
                but the damage ceiling is negligible.

Mitigating factors:
  - Zero-knowledge architecture: server cannot decrypt stored content
  - Lambda 6MB payload limit: natural upload size cap
  - Lambda concurrency limits: natural request throttling
  - Token scoping: each token is independent
  - Low traffic: current usage makes exploitation pointless

Monitoring:
  - Add log line when usage_count exceeds usage_limit (one-line code change)
  - Alert on >10% over-usage on any token
  - Review monthly or when traffic patterns change

Conditions for re-evaluation:
  - Quotas become monetised (paying customers)
  - Production storage architecture is designed (fix as part of that)
  - Abuse detection system is built (fix as part of that)
  - Traffic reaches levels where cost impact is meaningful

Acceptance period: Until production storage architecture redesign
Signed off by:  [PENDING — requires human approval]
```

---

## Recommendation to Human

**Reclassify #1 from P3 to P5. Accept with monitoring.**

The one-line monitoring change (log when usage exceeds limit) gives you visibility without adding complexity. The proper fix belongs in the production storage architecture work — where atomic operations become a property of the storage layer, not a bolt-on for one service.

This leaves two P3s for Wave 1:
- **#4 Token validation fails open** — still P3, simple fix, critical pattern
- **#5 Plaintext in localStorage** — still P3, client-side (no zero-knowledge discount), directly undermines the privacy promise

---

*Joint analysis by GRC (lead), AppSec, Architect | INC-002 | SGraph Send v0.4.9*
