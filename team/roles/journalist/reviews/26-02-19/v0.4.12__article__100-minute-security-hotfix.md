# v0.4.12 -- Article: The 100-Minute Security Hotfix

**Role:** Journalist
**Date:** 19 February 2026
**Version:** v0.4.12
**Type:** Incident narrative (internal + publishable)
**Related:** [AppSec incident response](../../appsec/reviews/26-02-19/v0.4.12__incident-response__access-token-leak.md), [Historian incident record](../../historian/reviews/26-02-19/v0.4.12__incident-record__INC-003__access-token-leak-hotfix.md)

---

## The Story

At 1:50pm on Wednesday 19 February 2026, Dinis Cruz was using SGraph Send the way any user would -- uploading a file and sharing the link. He looked at the URL and saw something that should not have been there.

```
https://send.sgraph.ai/.../download.html?token=[REDACTED]#[TRANSFER-ID]/[KEY-FRAGMENT]...
```

That `?token=[REDACTED]` is an access token. The sender's access token. Sitting in the query string of every shareable link the platform had generated since version 0.1.3.

By 3:30pm -- 100 minutes later -- the fix was live in production.

---

## What Went Wrong

When the download-side token validation feature was added in v0.1.3, the implementation took a shortcut: instead of creating a separate download authorization mechanism, it forwarded the sender's authentication token in the shareable URL. The backend actively supported this -- the transfer completion endpoint returned the token name with the comment: *"Include token name so UI can build share URL."*

Every shareable link since then carried the sender's credential. Unlike the encryption key (which lives safely in the hash fragment and is never sent to the server), the token sat in the query string -- visible to servers, logs, proxies, browser history, and every recipient.

The saving grace: SGraph Send's zero-knowledge architecture meant **no file content was ever at risk**. The encryption key stayed in the hash fragment. The server only ever stored encrypted ciphertext. Even with a leaked token, an attacker could authenticate to the platform but could never read anyone's files.

---

## What Happened Next

The response followed the project's P3-as-P1 philosophy -- treating every incident with P1 urgency regardless of the current blast radius.

**14:00** -- Incident classified. P3 by blast radius (beta, limited users), P1 by severity (authentication credential exposure).

**14:56** -- The AppSec role produced a full incident response report: root cause analysis, blast radius assessment, affected versions, token revocation recommendations, and six preventive measures.

**15:04** -- Security hotfix committed. Eight files changed across four frontend versions (v0.1.3 through v0.1.6), one backend route, and two test files. A new URL sanitisation test suite was added -- the project's first negative security test, verifying that sensitive data does *not* appear in URLs.

**15:10** -- Code review caught a process issue: the fix was on a feature branch containing unreviewed work. Merging it would pull in changes that hadn't been reviewed.

**15:20** -- Fix cherry-picked onto a clean hotfix branch from `dev`. One commit, one purpose.

**15:30** -- Deployed to production. 153 tests passing, including the new sanitisation suite.

The URLs now look like they should:

```
https://send.sgraph.ai/.../download.html#[TRANSFER-ID]/[DECRYPTION-KEY]
```

No query parameters. Transfer ID and encryption key in the hash fragment. Nothing sensitive sent to the server.

---

## What This Tells Us

### 1. Zero-Knowledge Architecture Limits Blast Radius

This is the second time in a week that the zero-knowledge model has proven its value. On 17 February, an external security reviewer validated the cryptographic model across 29 findings. On 19 February, a real credential leak in production URLs demonstrated that the architecture contains damage -- even when something goes wrong, file content stays encrypted.

The design principle is simple: the server never has the decryption key. It doesn't matter what else leaks. The most sensitive data -- the file content and the key to decrypt it -- is protected by architecture, not by access control.

### 2. The 5x Multiplier Is Real

The project's incident philosophy says fixing a problem today costs 1x, fixing it tomorrow costs 5x. The token had been in URLs since v0.1.3 -- weeks of exposure. Every day of delay would have meant more URLs in the wild carrying exposed tokens.

The 100-minute turnaround wasn't fast for the sake of speed. It was fast because every hour of delay increased the number of URLs that would need to be considered compromised.

### 3. Negative Tests Catch What Positive Tests Miss

The existing test suite verified that URLs *worked*. Every test passed. But no test checked what URLs *contained*. The hotfix introduced the project's first negative security test -- asserting that `token`, `key`, `secret`, and `password` do *not* appear in generated URLs.

This is a template for security testing: don't just test that the right things happen. Test that the wrong things don't.

### 4. Process Improvements Happen During Incidents

The hotfix branch discipline -- cherry-picking security fixes onto clean branches from `dev` -- wasn't planned in a retrospective. It was learned and applied in real time when the code review caught the wrong-branch issue. The correction took minutes, not days.

---

## The Numbers

| Metric | Value |
|--------|-------|
| Time from discovery to production fix | ~100 minutes |
| Files changed | 8 |
| Frontend versions patched | 4 (v0.1.3-v0.1.6) |
| Tests passing after fix | 153 |
| New test files added | 1 (URL sanitisation) |
| File content compromised | 0 |
| Encryption keys exposed | 0 |

---

## For the Record

This was the project's third incident (INC-003), and the first security vulnerability discovered and fixed in production. The previous incidents were a process issue (INC-001: commit impersonation, 12 Feb) and a planned security assessment (INC-002: external review, 17 Feb).

The incident handling philosophy documented on 13 February -- "Why We Treat Every Incident Like a Crisis" -- has now been tested against all three types of incident: process failure, external review, and internal discovery. Each time, the same principle applied: treat the systemic weakness with P1 urgency, regardless of the outcome's severity.

The token leak is fixed. The URLs are clean. The architecture held.

---

*Journalist article complete. This piece serves as both an internal record and a publishable account of the incident. All technical claims verified against the AppSec incident response report. Before external publication: confirm token rotation status, confirm server log audit completion, and get human approval on messaging.*
