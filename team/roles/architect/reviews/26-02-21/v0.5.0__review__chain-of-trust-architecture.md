# Architect Review: Chain of Trust, Key Graphs, and Layered Identity

**Version:** v0.5.0
**Date:** 21 February 2026
**Role:** Architect
**Team:** Explorer
**Responding to:** [`v0.4.27__architecture__chain-of-trust-and-key-graphs.md`](../../../humans/dinis_cruz/briefs/02/21/v0.4.27__architecture__chain-of-trust-and-key-graphs.md)
**Related briefs:**
- [`v0.4.27__dev-brief__key-discovery-and-public-registry.md`](../../../humans/dinis_cruz/briefs/02/21/v0.4.27__dev-brief__key-discovery-and-public-registry.md) -- Key discovery (immediate build priority)
- [`v0.4.27__architecture__secure-pod-multi-user-encryption.md`](../../../humans/dinis_cruz/briefs/02/21/v0.4.27__architecture__secure-pod-multi-user-encryption.md) -- Secure pod (future, customer-demand-driven)
- [`v0.4.20__appsec-research__service-worker-trust-anchor.md`](../../../humans/dinis_cruz/briefs/02/20/v0.4.20__appsec-research__service-worker-trust-anchor.md) -- Service Worker trust anchor
- [`v0.4.17__brief__pki-strategy-and-investor-deployment.md`](../../../humans/dinis_cruz/briefs/02/20/v0.4.17__brief__pki-strategy-and-investor-deployment.md) -- PKI strategy

**Previous Architect reviews:**
- [`v0.4.25__briefing__pki-messaging-architecture.md`](../26-02-20/v0.4.25__briefing__pki-messaging-architecture.md) -- PKI messaging system (deployed)
- [`v0.4.17__implementation-plan__browser-pki-key-management.md`](../26-02-20/v0.4.17__implementation-plan__browser-pki-key-management.md) -- Browser PKI implementation plan
- [`v0.4.12__response-to-briefs__17-18-19-feb.md`](../26-02-19/v0.4.12__response-to-briefs__17-18-19-feb.md) -- Multi-brief response (AD-17 through AD-24)

---

## Executive Summary

This brief is the most architecturally ambitious document the project has produced. It describes a complete trust infrastructure -- from key graphs and hash-chained integrity to layered identity and PKI-encrypted web delivery -- that would transform SG/Send from a zero-knowledge file transfer tool into a zero-knowledge identity and access platform.

The Architect's assessment: **the design is architecturally sound, internally consistent, and well-aligned with existing infrastructure.** The foundational principle (only encrypted blobs and tokens) is the correct north star. The six parts of the brief compose cleanly -- each builds on the previous. The brief correctly identifies which pieces are immediate (key discovery), which are design work (trust graphs, hash chains), and which are future (secure pod, encrypted page delivery).

Three areas require deeper attention before implementation:

1. **Key graph storage and consistency.** The brief proposes Issues-FS as the storage layer for the trust graph. This is conceptually correct -- the key graph IS a graph, and Issues-FS is a graph store -- but the consistency requirements of a trust infrastructure (linearisable reads, conflict resolution, partition tolerance) exceed what Issues-FS currently provides. This is solvable but must be explicitly designed.

2. **Hash chain verification and equivocation.** The git-style hash chain is elegant, but the brief underestimates the complexity of equivocation detection. A single server can show different chains to different clients. Without a gossip protocol or external witness, clients cannot detect this independently. This is the hardest unsolved problem in the design.

3. **Layered identity key management complexity.** Four key layers per session is powerful for security but creates a significant UX and operational burden. The implementation must be staged carefully to avoid overwhelming users with key management before they understand why it matters.

**Overall verdict:** Proceed. The design is the right architecture for the product's trajectory. Implement in phases, with key discovery (the immediate build priority) providing the foundation. The trust graph and hash chain are Phase 2 design work. Layered identity and encrypted page delivery are Phase 3+.

---

## Part 1: Key Graph as Chain of Trust -- Assessment

### What Works Well

The trust propagation model is clean and well-reasoned. The example is compelling: from one trusted key (Alice, obtained out-of-band), discover an entire organisation's key set. This solves a real user friction -- "I have one contact's key, how do I reach their colleagues?" -- that would otherwise require N separate out-of-band key exchanges.

The decision to use Obj_Ids for all graph nodes (no strings, no names) is consistent with the project's zero-knowledge principle and eliminates an entire class of injection and metadata-leakage attacks. This is the right default.

### Data Model Proposal for Issues-FS

The brief sketches the data model but leaves implementation detail open. Here is a concrete proposal that maps to Issues-FS and Memory-FS natively:

```
.keys/                                        # Root of the key graph store
  nodes/
    {obj_id}/                                 # One directory per node
      metadata.json                           # { type: "public-key" | "trust-group" | "identity", ... }
      public_key.pem                          # For public-key nodes only
  edges/
    {edge_id}/                                # One directory per edge
      metadata.json                           # { from: obj_id, to: obj_id, type: "has-member" | "trusts", signed_by: obj_id }
  chain/
    commits/
      {sequence_number}.json                  # Hash-chained commit (see Part 2)
    head.json                                 # { sequence: N, hash: "..." }
```

**Type_Safe schema (never Pydantic):**

```python
class Schema__Key_Node(Type_Safe):
    obj_id       : str            # 8-hex Obj_Id
    node_type    : str            # "public-key" | "trust-group" | "identity"
    algorithm    : str = ""       # "RSA-OAEP" | "ECDSA" | "" (for non-key nodes)
    key_size     : int = 0        # 4096, 256, etc.
    fingerprint  : str = ""       # "sha256:..." for key nodes
    created_at   : str            # ISO 8601
    status       : str = "active" # "active" | "revoked" | "expired"

class Schema__Key_Edge(Type_Safe):
    edge_id      : str            # 8-hex Obj_Id
    from_node    : str            # Obj_Id of source node
    to_node      : str            # Obj_Id of target node
    edge_type    : str            # "has-member" | "trusts" | "is-identity-of"
    signed_by    : str            # Obj_Id of the signing key
    signature    : str = ""       # Base64 of the signature bytes
    created_at   : str            # ISO 8601
    commit_ref   : str = ""       # Sequence number of the commit that created this edge
```

This fits cleanly into `Storage_FS`. Every node is a directory. Every edge is a directory. Graph traversal is a sequence of `Storage_FS` reads. No new storage primitives are needed.

### Open Questions

**Q1: Trust group administration.** Who can add members to a trust group? The brief implies a single admin key per group. For enterprise deployments, groups may need multiple admins (e.g., HR can add employees, IT can add contractors). The schema needs an `admin` edge type alongside `has-member`.

**Q2: Cross-group trust.** Can trust propagate across groups? If Alice is in Group-X and Bob is in Group-Y, and Group-X trusts Group-Y (an inter-group edge), can Alice discover Bob's key? The brief does not address cross-group trust. This is important for the data room scenario where multiple organisations (investor group, legal firm, target company) participate.

**Q3: Server key pinning.** The brief states that "each key in the response is SIGNED by the server's key (which you already trust -- it was pinned on first visit)." This is the TOFU (Trust On First Use) model from the Service Worker brief. It works, but it means the server's key is the root of trust for the entire graph. If the server key is compromised, the attacker can sign arbitrary graph responses. The Service Worker trust anchor (Layer 2 in the AppSec brief) mitigates this, but only after the first visit. The Architect recommends documenting this trust boundary explicitly: the server key is the weakest link in the chain-of-trust discovery flow.

### Risk: Issues-FS Consistency

Issues-FS and Memory-FS are designed for document-oriented workflows (issues, reviews, briefs). They provide eventual consistency for file reads and writes. A trust graph has stronger requirements:

| Property | Issues-FS Today | Trust Graph Needs |
|----------|----------------|-------------------|
| **Read-after-write consistency** | Depends on backend (memory: yes, S3: eventual) | Required -- a newly added member must be immediately discoverable |
| **Atomic multi-file writes** | Not guaranteed | Required -- adding a member requires creating a node, an edge, AND a commit atomically |
| **Conflict resolution** | Last-write-wins | Dangerous -- two admins adding members concurrently must not lose either write |
| **Ordered operations** | Not guaranteed across replicas | Required -- the hash chain requires strict ordering |

**Mitigation:** For the Explorer phase, the trust graph runs on the in-memory backend (Memory-FS), which provides all four properties. For production (S3 backend), the graph write operations must go through a serialisation layer (a single Lambda invocation per group that serialises writes). This is architecturally similar to the `compare_and_swap` primitive proposed in AD-24. The Architect recommends extending `Storage_FS` with a `transaction(paths, operations)` method that ensures atomic multi-file writes.

---

## Part 2: Git-Style Hash Chaining -- Assessment

### What Works Well

The commit chain model is the right abstraction. It provides exactly the properties listed in the brief: tamper evidence, append-only history, auditability, client verification. The analogy to git is precise and helps developers reason about the system. The commit structure (action, data, previous_hash, signed_by) is complete and well-defined.

The decision to make every graph mutation a signed, hash-chained commit is powerful. It transforms the trust graph from a mutable database into a verifiable log. This is directly useful for compliance (financial services, legal) and for the data room scenario.

### Concrete Commit Schema

```python
class Schema__Graph_Commit(Type_Safe):
    sequence     : int            # Monotonically increasing, 0-indexed
    action       : str            # "CREATE_GROUP" | "ADD_MEMBER" | "REVOKE_MEMBER" |
                                  # "ROTATE_KEY" | "UPDATE_ROLE" | "CREATE_DATA_ROOM"
    data         : dict           # Action-specific payload (all values are Obj_Ids or fingerprints)
    previous_hash: str            # SHA-256 hash of the previous commit (genesis: "0" * 64)
    commit_hash  : str            # SHA-256(action + canonical(data) + previous_hash)
    signed_by    : str            # Obj_Id of the signing key
    signature    : str            # Base64 of the signature over commit_hash
    timestamp    : str            # ISO 8601 (server-attested)
```

**Data canonicalisation is critical.** The hash must be computed over a canonical representation of the data. If the data dict is `{"group": "a3f7c891", "member": "b4e2d903"}`, the canonical form must be deterministic (sorted keys, no whitespace variation). The Architect recommends using sorted JSON with no whitespace: `json.dumps(data, sort_keys=True, separators=(',', ':'))`. This must be specified in the protocol and implemented identically on server and client.

### Verification Protocol

When a client requests the trust graph, the server returns the full commit chain (or the chain since the client's last-known commit). The client verifies:

```
For each commit C[i] where i > 0:
  1. Compute expected_hash = SHA-256(C[i].action + canonical(C[i].data) + C[i-1].commit_hash)
  2. Verify: expected_hash == C[i].commit_hash
  3. Verify: signature(C[i].commit_hash, C[i].signed_by) is valid
  4. Verify: C[i].signed_by was authorised to perform C[i].action at that point in the chain
     (e.g., only a group admin can ADD_MEMBER)
```

Step 4 is the most complex -- it requires the client to replay the entire chain to determine who was authorised at each point. For long chains, this is expensive. The Architect recommends:

- **Short-term (Explorer):** Full chain replay on every verification. Acceptable for chains under ~10,000 commits.
- **Medium-term:** Checkpoint mechanism. Every N commits, create a signed snapshot of the current graph state. Clients can verify from the latest checkpoint instead of from genesis.
- **Long-term:** Merkle tree over commits (like a Merkle log / certificate transparency log). Clients can verify inclusion of specific commits without replaying the entire chain.

### The Hard Problem: Equivocation Detection

**This is the most significant risk in the entire brief.**

The brief correctly identifies equivocation (the server showing different chains to different clients) and compares it to detecting a git force-push. But the analogy breaks down: in git, multiple developers push to and pull from the same repository, and they compare commit hashes naturally through the git protocol. In the trust graph, clients query the server independently. They have no mechanism to compare chains with each other.

**Attack scenario:**

```
Alice queries the trust graph --> Server returns Chain A (Eve is a member)
Bob queries the trust graph   --> Server returns Chain B (Eve is revoked)

Result: Alice encrypts for Eve (believing she's trusted).
        Bob does not encrypt for Eve (believing she's revoked).
        Neither Alice nor Bob knows the server is lying.
```

**Mitigation options:**

| Approach | How It Works | Complexity | Effectiveness |
|----------|-------------|------------|---------------|
| **Client gossip** | Clients periodically share their latest commit hash with each other (out-of-band or via the server). Mismatch = equivocation detected. | Low | Effective only if clients communicate |
| **External witness** | A third-party service (or multiple) independently stores the commit chain head hash. Clients verify against the witness. | Medium | Effective against server-only compromise |
| **Signed tree head (STH)** | Server publishes a signed tree head (a la Certificate Transparency). Multiple monitors fetch and compare STHs. | High | Gold standard -- proven by CT |
| **Blockchain anchor** | Periodically write the chain head hash to a public blockchain (Ethereum, Bitcoin). Clients verify the anchor. | Medium | Effective but adds external dependency |

**Architect recommendation:** For the Explorer phase, implement **client gossip** -- the simplest approach. When two clients are in the same data room or trust group, they include their latest commit hash in encrypted messages. The recipient compares. Mismatch triggers a warning. This is lightweight, requires no external infrastructure, and catches the most common equivocation scenarios.

For production, the **external witness** model aligns with the project's existing infrastructure. Deploy a witness Lambda in a separate AWS account (or a different cloud provider entirely). The witness receives every new commit hash from the main server and makes it available for client verification. This adds one HTTP request per graph query but provides genuine equivocation detection.

**AD-25: Equivocation detection strategy.** Choose between client gossip (Explorer) and external witness (production). The Architect recommends both -- gossip first, witness later.

---

## Part 3: Key Rotation -- Assessment

### What Works Well

The identity-anchored rotation model is correct. The insight that "identity endures, keys are ephemeral" is the right framing. OAuth/Cognito as the identity anchor is pragmatic -- users already authenticate with these providers, so adding key binding to the existing authentication flow is natural.

The multi-device model (multiple active public keys per identity) is well-understood from PGP subkeys and Signal's multi-device protocol. The brief's description is accurate.

### Architectural Concerns

**Concern 1: Server attestation trust.** When a user rotates their key, the server creates a ROTATE_KEY commit signed by the server's key. The server attests that the identity authenticated via OAuth/Cognito. This means key rotation trust is rooted in the server's key AND the OAuth provider. If either is compromised, an attacker can rotate any user's key.

This is acceptable for the Explorer phase (the server is trusted infrastructure), but for high-security deployments, consider requiring the user to sign the rotation request with their OLD key (if available) in addition to the server attestation. This provides key continuity: the chain shows `old_key -> server_attestation -> new_key`, which is stronger than `server_attestation -> new_key` alone.

**Concern 2: Key rotation notification UX.** The brief describes a dialog: "The key for this contact has changed. [Accept new key] [Reject -- verify out of band]". This is the Signal model. It works for individual contacts but creates notification fatigue in enterprise settings where key rotations are frequent (employees changing devices, browsers cleared by IT policy). For enterprise trust groups, the Architect recommends an auto-accept policy configurable by the group admin:

```python
class Schema__Trust_Group_Policy(Type_Safe):
    group_id                : str
    key_rotation_policy     : str = "prompt"    # "prompt" | "auto-accept" | "require-oob"
    max_active_keys_per_user: int = 5           # prevent key accumulation
    key_expiry_days         : int = 0           # 0 = no expiry
```

**Concern 3: Orphaned encrypted content.** When a key is rotated, content encrypted with the old key becomes undecryptable if the old private key is lost (the common case -- the user cleared their browser). The brief acknowledges this ("old encrypted content still references it"). The Architect notes this is a fundamental trade-off of the ephemeral key model and should be documented prominently for users: "If you lose your browser data, content encrypted to your old key is permanently inaccessible. Export important content before clearing your browser."

For the secure pod model (future), this is not a problem -- content is encrypted to the pod's key, not the user's key. The pod re-encrypts on access. Key rotation only affects the user's ability to receive new re-encrypted copies, not access to stored content.

---

## Part 4: Natural Revocation via Graph Maintenance -- Assessment

### What Works Well

This is the most elegant section of the brief. The insight that "revocation is the absence of trust, not the presence of a revocation entry" is architecturally clean and operationally simple. Traditional CRL/OCSP is clunky precisely because it requires maintaining a separate revocation infrastructure alongside the trust infrastructure. Unifying trust and revocation in the same graph eliminates that duplication.

The employee lifecycle mapping (hired = ADD_MEMBER, departed = REVOKE_MEMBER) is immediately understandable to enterprise customers and maps directly to HR workflows. This is a strong product differentiator.

### Architectural Concern: Revocation Latency

The graph-based revocation model depends on clients querying the graph before every encryption. If a client has a cached copy of the graph and does not refresh it, they will encrypt for a revoked user.

**The brief does not specify a cache policy.** This is a critical gap. Options:

| Policy | Latency | Cost | Risk |
|--------|---------|------|------|
| **No cache -- query on every encrypt** | Zero -- always current | High -- one HTTP request per encrypt operation | None |
| **Short TTL cache (5 minutes)** | Up to 5 minutes stale | Low | Revoked user can receive messages for up to 5 minutes |
| **Query + background refresh** | Near-zero for most operations | Medium | Race condition: encrypt while refresh is in flight |
| **Push notification on revocation** | Near-zero | Medium -- requires WebSocket or SSE | Client must be online to receive notification |

**Architect recommendation:** For the Explorer phase, query on every encrypt (no cache). The cost is one small HTTP request per encrypt operation. For production, short TTL cache (60 seconds) with a push notification channel for critical revocations (e.g., employee termination triggers an immediate notification to all active clients in the group). This aligns with AD-20's polling/WebSocket decision -- the same signalling channel used for chat can deliver revocation notifications.

**AD-26: Revocation cache policy.** No cache for Explorer; TTL + push for production.

### Connection to Secure Pod

The brief correctly notes that graph-based revocation is the mechanism that makes the secure pod work. When a user is revoked, the pod's authorisation check (step 2 in the access request flow) queries the graph. If the user is not in the graph, access is denied. The revocation is immediate (no cache -- the pod always queries the live graph). This is the correct architecture.

---

## Part 5: Layered Key Identity -- Assessment

### What Works Well

The four-layer model (API key, device/session, persona, admin) is comprehensive and correctly identifies the different trust levels needed for different operations. The challenge-response authentication pattern is well-established (SSH, WebAuthn) and maps cleanly to the Web Crypto API.

The multiple-persona model is a genuine product differentiator for the investor use case. A fund manager with separate personas for different portfolio companies achieves cryptographic isolation between roles. This is stronger than any ACL-based system.

### Architectural Concern: Complexity vs. Usability

Four key layers is powerful but creates a significant implementation and UX burden:

| Layer | Generation | Storage | Rotation | User Visibility |
|-------|-----------|---------|----------|----------------|
| API Key | Server-generated | Server + client (cookie/header) | Admin operation | Low (background) |
| Device/Session Key | Auto-generated per session | SessionStorage or IndexedDB | Automatic | None (invisible to user) |
| Persona Key | User-initiated generation | IndexedDB (non-extractable) | Identity-anchored (Part 3) | High (user manages personas) |
| Admin Key | Out-of-band ceremony | IndexedDB (non-extractable) | High ceremony | High (admin manages) |

**Risk: Key management overload.** A user who needs to generate personas, understand device keys, manage admin keys, AND keep track of which key is used for which operation will be overwhelmed. The existing PKI page (`pki.html`) already requires users to generate keys, copy public keys, import contacts. Adding three more key layers multiplies this complexity.

**Architect recommendation: Progressive disclosure.** Implement layers incrementally and expose them to users only when needed:

1. **Phase 1 (now):** Persona key only. This is what the existing `pki.html` already provides. One key pair per user. No layers visible to the user.
2. **Phase 2:** Add device/session key. Auto-generated, invisible to the user. Used internally for replay protection. No UI change.
3. **Phase 3:** Add admin key. Visible only to admin users. Installed via a separate admin ceremony page.
4. **Phase 4:** Add composable authentication (require multiple layers for sensitive operations). Visible only when the server challenges for it.

This means the user sees exactly one key (their persona) until they need admin access. The device key is invisible. The API key is background infrastructure. Complexity is introduced only when the user's security needs demand it.

### Composable Authentication: Server-Side Design

The challenge-response protocol needs a server-side schema:

```python
class Schema__Auth_Challenge(Type_Safe):
    challenge_id : str            # Random nonce (Obj_Id format)
    required_layers: list         # ["api_key", "device", "persona", "admin"]
    nonce        : str            # Random bytes, base64-encoded
    expires_at   : str            # ISO 8601 (short-lived, e.g., 60 seconds)
    operation    : str            # Description of the operation being authorised

class Schema__Auth_Response(Type_Safe):
    challenge_id : str            # Matches the challenge
    proofs       : dict           # { "device": { signature, fingerprint }, "persona": { signature, fingerprint }, ... }
```

The server validates each proof independently. All required proofs must be valid for the operation to proceed. This design is stateless on the server side (the challenge is self-contained with an expiry) and fits cleanly into the Lambda execution model.

**AD-27: Layered identity implementation order.** Persona first, device second, admin third, composable auth fourth.

---

## Part 6: PKI-Encrypted Personalised Web Delivery -- Assessment

### What Works Well

The concept of encrypting the entire web experience per-user is powerful and unique. The combination of Service Worker trust anchor (integrity) + PKI encryption (confidentiality) creates a defence-in-depth model that no other web platform offers.

The use cases are compelling:
- Investor data rooms where each participant sees only their authorised documents
- Admin panels that render as ciphertext without the admin key
- Regulatory compliance with cryptographic access enforcement

### Architectural Concerns

**Concern 1: Performance.** Encrypting and decrypting every HTTP response (HTML, JS, CSS) adds latency. RSA-OAEP decryption of a 4096-bit wrapped key takes ~2ms in a modern browser. AES-256-GCM decryption of a 100KB HTML page takes ~1ms. The total overhead per page load is ~3-5ms. This is acceptable for document-oriented data rooms but may be noticeable for interactive applications with many small API calls.

**Mitigation:** Encrypt page-level responses (HTML, initial data). Do NOT encrypt static assets that are the same for all users (shared CSS framework, shared JS libraries). Only encrypt content that differs per user or contains sensitive information. The Service Worker can distinguish between encrypted responses (which need decryption) and plaintext responses (shared assets) based on a response header (e.g., `X-SG-Encrypted: true`).

**Concern 2: Caching.** Per-user encrypted responses cannot be cached by CDNs (each user gets different ciphertext). This eliminates CloudFront caching for encrypted pages. The Lambda must handle every request directly.

**Mitigation:** For the data room scenario, traffic is low-volume (tens of users, not thousands). Lambda can handle this directly. For high-traffic scenarios, encrypt at the CDN edge (CloudFront Lambda@Edge or CloudFlare Workers) rather than at the origin. This keeps the encryption close to the user and avoids origin load. This is a Villager-track optimisation.

**Concern 3: Key discovery before page load.** The Service Worker must know the user's public key fingerprint before requesting encrypted content from the server. This creates a chicken-and-egg problem for the first page load: the Service Worker needs the user's key to request encrypted content, but the user's key is stored in IndexedDB, which is only accessible from the page context (not from the Service Worker directly).

**Resolution:** The Service Worker can access IndexedDB. Unlike localStorage, IndexedDB is available in Service Worker contexts. The flow:

```
1. Service Worker intercepts page request
2. Service Worker opens IndexedDB, reads user's public key fingerprint
3. Service Worker adds fingerprint to request header: X-SG-Key-Fingerprint: sha256:...
4. Server encrypts response with the user's public key
5. Service Worker decrypts response
6. Decrypted HTML rendered in browser
```

If no key is found in IndexedDB (first visit, cleared browser), the Service Worker falls back to requesting the unencrypted version (or a "please register your key" landing page).

### Implementation Dependencies

PKI-encrypted web delivery depends on ALL previous parts being implemented:
- Part 1: Key graph (server knows user's public key via the graph)
- Part 2: Hash chain (the encrypted page delivery events are logged and verifiable)
- Part 3: Key rotation (when a user rotates their key, the server encrypts with the new key)
- Part 4: Revocation (revoked user's requests return access-denied, not encrypted content)
- Part 5: Layered identity (persona key determines which encrypted view the user receives)
- Service Worker trust anchor (the Service Worker must be trusted to handle decryption)

This is the capstone feature. It should be implemented last.

---

## Data Room Architecture -- Assessment

The data room architecture described in the brief (trust graph + content + thread + hash chain + Service Worker trust bundle) is the composition of all six parts. The Architect confirms that these parts compose correctly and do not conflict.

**One addition:** The data room needs a **permissions model** that maps trust graph positions to content access levels. The brief shows content encrypted for specific audiences ("all parties", "investor + legal only", "investor only", "legal only") but does not specify how these access levels are defined or enforced.

Proposed schema:

```python
class Schema__Data_Room_Permission(Type_Safe):
    content_obj_id  : str          # Obj_Id of the encrypted content
    authorised_groups: list        # List of trust-group Obj_Ids that can access this content
    encryption_mode : str          # "direct-pki" | "pod-mediated"
```

When a user requests content, the server checks:
1. Is the user a member of any group in `authorised_groups`? (Graph query)
2. Is the user's membership active (not revoked)? (Graph query)
3. If pod-mediated: route through the pod. If direct-pki: return the per-user encrypted copy.

This permission schema lives alongside the content in Memory-FS:

```
data_rooms/{data_room_obj_id}/
  content/{content_obj_id}/
    payload                    # Encrypted blob
    permissions.json           # Schema__Data_Room_Permission
  trust_graph/                 # Symlink or reference to the key graph
  chain/                       # Hash chain for this data room
```

---

## Research Task Prioritisation

The brief lists 10 research tasks. The Architect ranks them by dependency order, alignment with the immediate build priority (key discovery), and risk reduction:

### Tier 1: Immediate (D1) -- Foundation for Key Discovery Build

| # | Task | Brief Priority | Architect Rationale |
|---|------|----------------|---------------------|
| 1 | **Design the trust graph schema in Issues-FS** | D1 | Direct foundation. The key discovery and public registry features need a storage model for keys and their relationships. The schema proposed in this review (Part 1) is the starting point. Even the simple key registry (dev brief) benefits from the graph schema -- a published key is a node in the graph with no edges yet. |

### Tier 2: Next Sprint (D2) -- Core Trust Infrastructure

| # | Task | Brief Priority | Architect Rationale |
|---|------|----------------|---------------------|
| 2 | **Design the key rotation flow** | D2 | Must be designed before key discovery ships, because the discovery UI needs to handle the case where a discovered key has been rotated. The rotation flow affects the API contract for `GET /api/keys/{code}` (should it return all key versions or just the current one?). |
| 3 | **Implement git-style hash chaining for graph commits** | D2 | The key transparency log in the dev brief (the append-only log on the registry page) IS the hash chain. Implementing the chain for key publication events is the first concrete use of the commit model. |
| 4 | **AppSec review: equivocation attacks** | D2 | The hardest open problem. Must be understood (even if not fully solved) before the trust graph is deployed. A deployed trust graph without equivocation detection is a trust graph that can lie. |
| 5 | **AppSec review: challenge-response protocol** | D2 | Lower risk than equivocation (replay attacks are well-understood, nonce management is standard), but must be reviewed before layered identity is implemented. |

### Tier 3: Design Phase (D3) -- After Key Discovery Ships

| # | Task | Brief Priority | Architect Rationale |
|---|------|----------------|---------------------|
| 6 | **Design the challenge-response protocol for layered authentication** | D2 (brief) -> D3 (architect) | The Architect downgrades this to D3. Layered identity is Phase 3 in the progressive disclosure plan. The persona key (which already exists in pki.html) is sufficient for the key discovery build. |
| 7 | **Prototype the data room trust configuration** | D3 | Depends on the trust graph being implemented and the hash chain being operational. This is the composition step. |
| 8 | **Prototype encrypted page delivery** | D3 | The capstone feature. Depends on everything else. |
| 9 | **Research: Signal, Wire, Keybase multi-device key management** | D3 | Informative for the key rotation design but not blocking. Our identity-anchored model is already well-defined. |
| 10 | **Research: Key Transparency (Google's approach)** | D3 | Directly relevant to equivocation detection (task 4). If the AppSec review identifies equivocation as a critical risk, this research becomes urgent. |

### Execution Recommendation

```
WEEK 1 (aligns with key discovery build):
  Task 1: Trust graph schema in Issues-FS     -- Architect delivers schema (this review starts it)
  Task 3: Hash chain for key publication       -- Developer implements alongside registry transparency log
  Task 4: Equivocation threat analysis         -- AppSec begins analysis (does not block build)

WEEK 2 (post key discovery):
  Task 2: Key rotation flow design             -- Architect delivers rotation protocol
  Task 5: Challenge-response review            -- AppSec delivers review

WEEK 3+ (design phase):
  Tasks 6-10: Design and research              -- Architect and AppSec deliver in priority order
```

---

## Recommendations

### R1: Implement Key Discovery First, Trust Graph Second

The dev brief (`v0.4.27__dev-brief__key-discovery-and-public-registry.md`) is the correct immediate priority. It delivers user-visible value (publish a key, look up a key, import a key) without requiring the full trust graph infrastructure. The transparency log on the registry page is the first concrete instance of the hash chain. Ship this, learn from it, then build the full trust graph on top.

### R2: Separate the Hash Chain from the Trust Graph

The hash chain and the trust graph are conceptually linked (every graph mutation is a chained commit) but should be implemented as separate modules:

- **`Chain__Service`**: Manages the append-only commit chain. Accepts commits, computes hashes, stores commits, serves chain segments for verification. This service is generic -- it chains arbitrary commits, not just trust graph operations.
- **`Graph__Service`**: Manages the trust graph (nodes and edges). Calls `Chain__Service` to record every mutation. Provides graph traversal queries (members of a group, groups containing a key, path between two keys).

This separation lets us reuse `Chain__Service` for other append-only logs (the key transparency log, the access audit log, the pod access log) without duplicating the chaining logic.

### R3: Design for Client-Side Verification from Day One

The hash chain is only as valuable as the client's ability to verify it. Every API response that includes trust graph data should include enough information for the client to verify the chain segment:

```json
{
  "members": [...],
  "chain_proof": {
    "from_commit": 42,
    "to_commit": 57,
    "commits": [...],
    "head_hash": "sha256:..."
  }
}
```

The client library (`pki-common.js` from the dev brief) should include a `verifyChainSegment(commits)` function that validates the hash chain. Even if clients do not initially verify (Explorer phase), the data format should support verification so it can be enabled later without API changes.

### R4: Address Equivocation Before Production

Equivocation detection is not required for the Explorer phase (the server is trusted development infrastructure). But it MUST be addressed before the trust graph is used in production. The Architect recommends:

1. **Explorer phase:** Log and expose the chain head hash in the transparency log UI. Users can manually compare chain heads.
2. **Pre-production:** Implement client gossip -- clients include their chain head hash in encrypted messages.
3. **Production:** Deploy an external witness service (Lambda in a separate AWS account).

### R5: Document the Trust Model Explicitly

The brief describes a sophisticated trust model, but it is spread across six sections. The Architect recommends a single-page "Trust Model Summary" document that maps:

- What the server is trusted to do (store encrypted data, attest identity for key rotation, serve the trust graph)
- What the server is NOT trusted to do (see plaintext, forge key relationships without detection)
- What the client is trusted to do (generate keys, encrypt/decrypt, verify chains)
- What the OAuth provider is trusted to do (authenticate identity for key rotation)
- What happens when each component is compromised

This document should be produced by AppSec and reviewed by the Architect. It will be essential for security-conscious customers (the investor use case) and for any future security audit.

### R6: Use the Existing PKI Implementation as the Foundation

The deployed `pki-manager` Web Component (documented in [`v0.4.25__briefing__pki-messaging-architecture.md`](../26-02-20/v0.4.25__briefing__pki-messaging-architecture.md)) already provides:
- RSA-OAEP 4096 key generation and storage in IndexedDB
- ECDSA P-256 signing key generation and storage
- Contact import/export (public key bundles)
- Hybrid encrypt/decrypt with signature verification
- Non-extractable private keys

The trust graph and key discovery features should extend this component, not replace it. The persona key (Part 5, Layer 3) IS the key pair already generated in `pki-manager`. The contact store IS the beginning of the trust graph (local view). The encrypt/decrypt workflow IS the client-side implementation of the trust chain's encryption model.

The `pki-common.js` module proposed in the dev brief (extracted from `pki-manager.js`) should include:
- `verifyChainSegment(commits)` -- hash chain verification
- `lookupKey(code)` -- API call to key registry
- `publishKey(publicKeyBundle)` -- API call to publish key
- `resolveContactFromGraph(groupObjId, memberObjId)` -- trust graph traversal (future)

---

## New Architectural Decisions

| Decision | Description | Options | Recommendation |
|----------|-------------|---------|----------------|
| **AD-25** | Equivocation detection strategy | Client gossip / External witness / Signed tree head / Blockchain anchor | Client gossip (Explorer), external witness (production) |
| **AD-26** | Revocation cache policy | No cache / Short TTL / Push notification | No cache (Explorer), TTL + push (production) |
| **AD-27** | Layered identity implementation order | All at once / Progressive disclosure | Progressive: persona -> device -> admin -> composable |
| **AD-28** | Hash chain implementation | Monolithic (chain + graph together) / Modular (Chain__Service + Graph__Service) | Modular -- separate Chain__Service and Graph__Service |
| **AD-29** | Trust graph atomic writes | Eventual consistency / Serialised writes / Transaction primitive | Serialised writes per group (Explorer), Storage_FS transaction primitive (production) |
| **AD-30** | Encrypted page delivery caching | No CDN cache / Edge encryption / Split encrypted/plaintext | Split: encrypt per-user content, serve shared assets as plaintext |

---

## Cross-References

| Document | Location | Relevance |
|----------|----------|-----------|
| Architecture brief (this review responds to) | [`v0.4.27__architecture__chain-of-trust-and-key-graphs.md`](../../../humans/dinis_cruz/briefs/02/21/v0.4.27__architecture__chain-of-trust-and-key-graphs.md) | Primary input |
| Key discovery dev brief | [`v0.4.27__dev-brief__key-discovery-and-public-registry.md`](../../../humans/dinis_cruz/briefs/02/21/v0.4.27__dev-brief__key-discovery-and-public-registry.md) | Immediate build priority |
| Secure pod architecture | [`v0.4.27__architecture__secure-pod-multi-user-encryption.md`](../../../humans/dinis_cruz/briefs/02/21/v0.4.27__architecture__secure-pod-multi-user-encryption.md) | Future capability, depends on trust graph |
| Service Worker trust anchor | [`v0.4.20__appsec-research__service-worker-trust-anchor.md`](../../../humans/dinis_cruz/briefs/02/20/v0.4.20__appsec-research__service-worker-trust-anchor.md) | Integrity layer for encrypted page delivery |
| PKI messaging architecture (deployed) | [`v0.4.25__briefing__pki-messaging-architecture.md`](../26-02-20/v0.4.25__briefing__pki-messaging-architecture.md) | Existing implementation to build on |
| Browser PKI implementation plan | [`v0.4.17__implementation-plan__browser-pki-key-management.md`](../26-02-20/v0.4.17__implementation-plan__browser-pki-key-management.md) | Phase A/B/C/D roadmap |
| PKI strategy brief | [`v0.4.17__brief__pki-strategy-and-investor-deployment.md`](../../../humans/dinis_cruz/briefs/02/20/v0.4.17__brief__pki-strategy-and-investor-deployment.md) | Strategic context |
| Previous architect response (AD-17 to AD-24) | [`v0.4.12__response-to-briefs__17-18-19-feb.md`](../26-02-19/v0.4.12__response-to-briefs__17-18-19-feb.md) | Carry-forward decisions |
| PQC assessment | [`v0.4.12__response-to-briefs__17-18-19-feb.md` (Section 5)](../26-02-19/v0.4.12__response-to-briefs__17-18-19-feb.md) | AD-21: hybrid PQC when PKI introduced |

---

## Questions for Human

1. **AD-25 (Equivocation):** The equivocation problem is real but the mitigations add complexity. For the Explorer phase, is "log chain head in the transparency UI and let users manually compare" sufficient? Or should we invest in gossip/witness from the start?

2. **Cross-group trust (Q2 above):** Should trust propagate across groups? The data room scenario requires it (investor group, legal firm, and target company need to discover each other's keys through the data room's trust graph). The Architect recommends yes, with explicit cross-group edges that are admin-authorised. Confirm.

3. **Trust group administration (Q1 above):** Single admin per group, or multiple admins? Enterprise deployments need multiple admins. The Architect recommends supporting multiple admins from the start (it is simpler to design for multi-admin than to retrofit it).

4. **Progressive identity disclosure (AD-27):** Confirm that shipping persona key only (what we have now) is acceptable for the key discovery build. Device key, admin key, and composable auth come later.

5. **Chain__Service reuse (R2):** The Architect proposes a generic Chain__Service that can underpin the trust graph chain, the key transparency log, and the pod audit log. Confirm this modular approach is preferred over three separate chain implementations.

---

*Architect review complete. The chain-of-trust architecture is sound and well-aligned with the product trajectory. Six new architectural decisions (AD-25 through AD-30) are recorded. The immediate priority remains key discovery (the dev brief). The trust graph schema, hash chain implementation, and equivocation analysis are the next architectural work items. Awaiting human decisions on cross-group trust, group administration, and equivocation mitigation strategy.*

---

This document is released under the Creative Commons Attribution 4.0 International licence (CC BY 4.0). You are free to share and adapt this material for any purpose, including commercially, as long as you give appropriate credit.
