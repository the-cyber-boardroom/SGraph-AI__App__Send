# Architect Action Plan: Explorer Next Steps

**Version:** v0.3.2
**Date:** 14 February 2026
**Role:** Architect (Explorer Team)
**Builds on:** [v0.3.0 Next Steps from Wardley Briefs](v0.3.0__review__next-steps-from-wardley-briefs.md)
**References:**
- Daily brief: [v0.3.2 daily brief](../../../../team/humans/dinis_cruz/briefs/02/14/v0.3.2__daily-brief__sgraph-send-14-feb-2026.md)
- Wardley Maps: [v0.3.2 Wardley Maps brief](../../../../team/humans/dinis_cruz/briefs/02/14/v0.3.2__briefs__wardley-maps-in-sgraph-project.md)
- Explorer role: [v0.3.2 Explorer role definition](../../../../team/humans/dinis_cruz/briefs/02/14/v0.3.2__role-definition__explorer.md)
- Previous response: [v0.3.0 response to daily brief](v0.3.0__response-to-daily-brief__14-feb.md)
- Admin UI architecture: [v0.3.0 Admin UI component architecture](v0.3.0__response-to-daily-brief__14-feb.md)
- Prior assessment: [v0.2.41 osbot ecosystem architecture assessment](v0.2.41__review__osbot-ecosystem-architecture-assessment.md)

---

## Purpose

The [v0.3.0 next-steps review](v0.3.0__review__next-steps-from-wardley-briefs.md) mapped the Explorer and Villager work items, identified four architectural decisions (AD-1 through AD-4), and produced the evolution map. This action plan converts those items into concrete research directions, design deliverables, and decision checkpoints for the Architect on the Explorer team.

Seven sections follow, each corresponding to a distinct workstream the brief assigns to the Architect.

---

## 1. Design Agency Brief: Technical Context

**Priority:** P1 (time-sensitive -- external partner waiting)
**Collaborators:** Designer (owns the brief), Advocate, Ambassador
**Architect contribution:** Technical context document embedded in the agency brief

### What the Designer Needs from the Architect

The design agency needs to understand how SGraph Send works at a level sufficient to design for it -- without needing to read the codebase. The Architect must produce a technical context section covering:

#### 1.1 System Overview for Non-Engineers

A plain-language explanation of the zero-knowledge architecture:

1. **What the user does:** selects a file, clicks encrypt, copies a link, shares the link
2. **What the browser does:** generates a random AES-256-GCM key, encrypts the file with that key, uploads the encrypted ciphertext to the server, puts the key in the URL fragment (after the `#`)
3. **What the server does:** stores encrypted bytes. It never sees the key, never sees the file name, never sees the plaintext
4. **What the recipient does:** opens the link, the browser extracts the key from the URL fragment, downloads the ciphertext, decrypts in the browser
5. **What this means for the designer:** the "trust story" is architecturally enforced, not just a policy claim. The server _cannot_ read your files. This is the key differentiator from WeTransfer

#### 1.2 Component Map for Design Surfaces

The designer needs to know what surfaces exist and how they relate:

| Surface | URL Pattern | Who Uses It | Current State |
|---------|-------------|-------------|---------------|
| Landing/upload page | `send.sgraph.ai/send/v0/v0.1/v0.1.4/index.html` | Sender (authenticated via token) | Working -- file + text mode, drag-and-drop, encryption, share link |
| Download page | `send.sgraph.ai/send/v0/v0.1/v0.1.4/download.html` | Recipient (no auth needed for download) | Working -- key from URL fragment, decrypt, download |
| Admin console | `admin.send.sgraph.ai/admin/v0/v0.1/v0.1.0/` | Admin (API key auth) | Working -- token CRUD, pulse, system info |

#### 1.3 Constraints the Design Must Respect

| Constraint | Reason | Impact on Design |
|------------|--------|------------------|
| No text baked into images | Multi-language support (i18n already implemented) | All text must be in HTML/CSS, not in graphics |
| CSS custom properties for theming | Five themes planned (Aurora, Glacier, Ember, plus accessibility variants) | Design must work as a _system_ of tokens, not a fixed colour palette |
| No Shadow DOM | IFD surgical override methodology | CSS class prefixes per component, global cascade applies |
| No JavaScript frameworks | Zero external dependencies | Web Components + vanilla JS only |
| URL fragment for key | The `#key` portion never reaches the server | Download page must work with hash-based routing |
| HTTPS required | Web Crypto API needs secure context | No HTTP fallback |

#### 1.4 User Flows as Sequence Diagrams

Two diagrams the agency brief should include (the Architect should produce these):

**Upload flow:**
```
Sender -> Browser: select file
Browser -> Browser: generate AES-256-GCM key
Browser -> Browser: wrap in SGMETA envelope (preserves filename)
Browser -> Browser: encrypt(key, envelope) -> ciphertext
Browser -> Server: POST /transfers/create (file_size, content_type)
Server -> Browser: { transfer_id, upload_url }
Browser -> Server: POST /transfers/upload/{id} (ciphertext bytes)
Browser -> Server: POST /transfers/complete/{id}
Server -> Browser: { download_url, transparency }
Browser -> Sender: display share link = origin/download.html?token=T#transfer_id/key
```

**Download flow:**
```
Recipient -> Browser: open share link
Browser -> Browser: extract transfer_id and key from URL fragment
Browser -> Server: POST /transfers/validate-token/{token}
Browser -> Server: GET /transfers/info/{id}
Browser -> Browser: display transfer info (size, transparency)
Browser -> Server: GET /transfers/download/{id} -> ciphertext bytes
Browser -> Browser: decrypt(key, ciphertext) -> SGMETA envelope
Browser -> Browser: unpack envelope -> original file + filename
Browser -> Recipient: trigger file download with original filename
```

#### 1.5 Deliverable

**File:** `team/roles/architect/reviews/26-02-14/v0.3.2__technical-context__design-agency-brief.md`

A standalone document (max 3 pages equivalent) the Designer can embed directly in the agency brief. No code. No internal jargon. Visual diagrams where possible.

**Status:** Ready to produce. No blockers.

---

## 2. Large File Transfer Architecture

**Priority:** P2 (roadmap -- architecture design now, implementation later)
**Corresponds to:** AD-4 from the [next-steps review](v0.3.0__review__next-steps-from-wardley-briefs.md)
**Evolution stage:** Genesis (per [Wardley Maps brief](../../../../team/humans/dinis_cruz/briefs/02/14/v0.3.2__briefs__wardley-maps-in-sgraph-project.md))

### 2.1 Current Limitations

The existing upload flow (as implemented in `send-upload.js` and `Routes__Transfers.py`) works as follows:

1. The entire file is read into memory as an `ArrayBuffer` via `FileReader.readAsArrayBuffer()`
2. The file is wrapped in the SGMETA envelope (adds filename metadata)
3. The entire envelope is encrypted in one call: `SendCrypto.encryptFile(key, plaintext)` which calls `crypto.subtle.encrypt()` on the full buffer
4. The entire encrypted blob is uploaded as the body of a single `POST /transfers/upload/{id}` request
5. The server receives the full body via `await request.body()` and writes it to storage in one `file__save()` call

**This breaks for large files because:**
- `FileReader.readAsArrayBuffer()` loads the entire file into browser memory
- `crypto.subtle.encrypt()` processes the entire buffer at once (doubles memory: plaintext + ciphertext)
- A single HTTP POST has practical size limits (Lambda payload limit: 6 MB for synchronous invoke, though Lambda URL functions support streaming up to ~20 MB before timeout pressure)
- No retry capability -- if the upload fails at 95%, the entire file must be re-uploaded
- No progress indication beyond the coarse "encrypting" / "uploading" states

### 2.2 Key Design Decision: Chunk Before or After Encryption?

This is the fundamental architectural question. Two options:

#### Option A: Chunk-then-Encrypt (Encrypt Each Chunk Independently)

```
Original file -> split into N chunks -> encrypt each chunk with same key + unique IV -> upload each chunk
```

**Advantages:**
- Each chunk is a self-contained encrypted unit
- Per-chunk retry is straightforward -- re-encrypt and re-upload just that chunk
- Server can verify each chunk independently (chunk hash)
- Memory usage: one chunk in memory at a time (both plaintext and ciphertext)
- Compatible with `ReadableStream` / streaming file reads

**Disadvantages:**
- More complex reassembly on download (must decrypt each chunk in order)
- Chunk boundary information is visible to the server (number of chunks, chunk sizes)
- Each chunk has its own 12-byte IV overhead (negligible for reasonable chunk sizes)
- SGMETA envelope must be in the first chunk or handled separately

**Chunk integrity model:**
```
For chunk i:
  IV_i = crypto.getRandomValues(12 bytes)
  ciphertext_i = AES-256-GCM(key, IV_i, plaintext_chunk_i)
  chunk_hash_i = SHA-256(ciphertext_i)
  upload chunk_i with chunk_hash_i
```

#### Option B: Encrypt-then-Chunk (Encrypt Whole File, Split Ciphertext)

```
Original file -> encrypt entire file -> split ciphertext into N chunks -> upload each chunk
```

**Advantages:**
- Encryption is identical to current flow (single AES-256-GCM operation)
- Server sees only opaque ciphertext chunks -- identical to current security model
- Reassembly is simple concatenation

**Disadvantages:**
- Encryption still requires the entire file in memory (defeats the purpose for very large files)
- Per-chunk retry is simple (chunks are just byte ranges of ciphertext) but the initial encryption is the bottleneck
- No streaming encryption possible

#### Recommendation: Option A (Chunk-then-Encrypt)

**Rationale:** The primary motivation for large file support is files that are too large to fit comfortably in browser memory. Option B does not solve this. Option A enables streaming: read a chunk from disk, encrypt it, upload it, release the memory, repeat. This is the only approach that scales to multi-GB files.

### 2.3 Proposed Architecture

#### Client-Side (Browser)

```
┌─────────────────────────────────────────────────────────┐
│  ChunkedUploader                                         │
│                                                          │
│  1. Read file metadata, compute total chunks             │
│  2. POST /transfers/create-chunked                       │
│     { file_size_bytes, chunk_size, chunk_count }         │
│  3. For each chunk i = 0..N-1:                           │
│     a. Read chunk_i from File (ReadableStream or slice)  │
│     b. If i == 0: prepend SGMETA envelope header         │
│     c. Encrypt chunk_i: AES-256-GCM(key, IV_i, data)    │
│     d. Compute chunk_hash_i = SHA-256(encrypted_chunk_i) │
│     e. POST /transfers/upload-chunk/{id}/{i}             │
│        Body: encrypted bytes                             │
│        Header: X-Chunk-Hash: chunk_hash_i                │
│     f. On failure: retry up to 3 times with backoff      │
│     g. On success: emit progress event                   │
│  4. POST /transfers/complete/{id}                        │
│     { chunk_hashes: [hash_0, ..., hash_N-1] }           │
│  5. Server verifies all chunks present and hashes match  │
│                                                          │
│  Progress: (completed_chunks / total_chunks) * 100       │
└─────────────────────────────────────────────────────────┘
```

#### Server-Side

```
Storage layout for chunked transfer:
  transfers/{id}/meta.json          (metadata including chunk_count, chunk_size)
  transfers/{id}/chunks/000         (encrypted chunk 0)
  transfers/{id}/chunks/001         (encrypted chunk 1)
  ...
  transfers/{id}/chunks/NNN         (encrypted chunk N-1)
```

New endpoints (Explorer additions to `Routes__Transfers`):

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/transfers/create-chunked` | POST | Create a chunked transfer record |
| `/transfers/upload-chunk/{id}/{chunk_index}` | POST | Upload a single encrypted chunk |
| `/transfers/complete/{id}` | POST | Complete transfer (existing, extended for chunk verification) |
| `/transfers/download-chunk/{id}/{chunk_index}` | GET | Download a single chunk (for chunked download) |
| `/transfers/download/{id}` | GET | Download full file (server reassembles chunks into stream) |

#### Memory-FS Compatibility

The current `Storage_FS` interface (`file__save`, `file__bytes`, `file__exists`) works per-chunk because each chunk is a separate file. No changes to the `Storage_FS` abstraction are needed.

For S3 backend specifically (`Storage_FS__S3`): each chunk maps to a separate S3 object. This is simpler than S3 multipart upload and avoids the multipart API complexity. The trade-off is that downloading a full file requires reading N objects -- acceptable for initial implementation, optimisable later by the Villager team.

**Decision: Do NOT use S3 multipart upload in the Explorer phase.** Use one S3 object per chunk via the existing `Storage_FS` interface. S3 multipart is an optimisation the Villager team can add when productising.

### 2.4 Chunk Size Selection

| Chunk Size | 100 MB File | 1 GB File | 10 GB File |
|------------|-------------|-----------|------------|
| 1 MB | 100 chunks | 1,000 chunks | 10,000 chunks |
| 5 MB | 20 chunks | 200 chunks | 2,000 chunks |
| 10 MB | 10 chunks | 100 chunks | 1,000 chunks |
| 25 MB | 4 chunks | 40 chunks | 400 chunks |

**Recommendation:** Default chunk size of 5 MB. Configurable by the client. 5 MB is small enough to retry quickly on failure, large enough to limit HTTP overhead for multi-GB files, and fits comfortably within Lambda URL function timeout budgets.

### 2.5 Integrity Verification

End-to-end integrity check flow:

```
Sender browser:
  original_file_hash = SHA-256(original plaintext file)
  (included in SGMETA envelope metadata)

Per chunk (sender):
  chunk_hash_i = SHA-256(encrypted_chunk_i)
  (sent with upload, verified by server)

Reassembly (recipient browser):
  download all chunks -> decrypt each -> concatenate -> extract SGMETA
  decrypted_file_hash = SHA-256(decrypted plaintext)
  verify: decrypted_file_hash === original_file_hash from SGMETA
```

The server verifies chunk integrity (encrypted data integrity). The recipient verifies file integrity (plaintext data integrity via the hash embedded in the encrypted SGMETA envelope). The server cannot forge the plaintext hash because it is encrypted.

### 2.6 Deliverable

**File:** `team/roles/architect/reviews/26-02-14/v0.3.2__design__large-file-transfer-architecture.md`

A full design document with API contracts, data model changes, client-side component design, and test strategy. This action plan section is the preliminary design; the full document expands each area.

**Status:** Preliminary design complete (above). Full document is next action.

---

## 3. External Partner Claude Bot Research

**Priority:** P2
**Corresponds to:** E6 from the [next-steps review](v0.3.0__review__next-steps-from-wardley-briefs.md)

### 3.1 Problem Statement

The design agency (and future external partners) will have questions about the project: "what's the colour palette?", "how does the encryption work?", "what are the accessibility requirements?" Currently, these questions require a human to relay context. The brief asks: can we give external partners a Claude bot that has project context?

### 3.2 Options Assessed

#### Option A: Claude Project with Uploaded Context

**How it works:** Create a Claude.ai project, upload key documents (the design agency brief, role definitions, specs, architecture docs) as project knowledge. Share the project link with the external partner.

**Strengths:**
- Zero engineering effort -- Claude.ai supports projects natively
- Context persists across conversations
- Access control: project is shared by invitation
- The partner gets a conversational interface to the project docs

**Weaknesses:**
- Static context -- documents must be manually re-uploaded when they change
- No direct access to the codebase or live system state
- Limited to what was uploaded (partner cannot ask "what's in the latest commit?")
- Claude.ai subscription required per user

**Access scoping:** Upload only the documents relevant to the partner's role. For the design agency: the agency brief, the technical context, the IFD guide, the theme system spec, the accessibility requirements. Exclude: code, deployment configs, tokens, admin credentials.

#### Option B: Claude Code (MCP) with Repository Access

**How it works:** Give the partner a Claude Code session connected to the repository via MCP (Model Context Protocol). The bot can read files, search the codebase, and answer questions with live context.

**Strengths:**
- Live context -- always up to date with the latest repo state
- Can search, cross-reference, and synthesise across files
- Powerful for deep technical questions

**Weaknesses:**
- Requires the partner to use Claude Code (terminal-based or IDE integration)
- Harder to scope access -- the bot can see the full repo
- Risk of exposing internal decisions, team dynamics, security architecture details
- Requires setup on the partner's machine or a hosted environment

**Access scoping:** Would require a read-only MCP server with path-level access control (only expose `library/`, `team/roles/designer/`, the agency brief, and UI assets). This does not exist as a standard feature today.

#### Option C: Custom Claude Bot via API with RAG

**How it works:** Build a custom application that uses the Anthropic API. Load project documents into a retrieval system (embeddings + vector store or simple keyword search). The bot answers questions by retrieving relevant document sections and passing them to Claude as context.

**Strengths:**
- Full control over what context the bot can see
- Can be deployed as a web app -- partner just opens a URL
- Can be updated automatically when documents change (git hook triggers re-indexing)
- Professional experience for external partners

**Weaknesses:**
- Requires engineering effort to build and maintain
- Adds infrastructure (API costs, hosting, vector store)
- Custom code to maintain

**Access scoping:** The retrieval index includes only approved documents. Granular control.

#### Option D: Claude Bot via Shared Team Workspace (Claude for Work)

**How it works:** Use Claude's team/enterprise features to create a workspace with the partner, with project knowledge attached.

**Strengths:**
- Managed by Anthropic -- no custom infrastructure
- Team features handle access control
- Context can be curated per workspace

**Weaknesses:**
- Requires enterprise plan features
- Partner needs a Claude account on the same team
- May not be available at current scale/plan

### 3.3 Recommendation

**Phase 1 (immediate, for the design agency):** Option A. Create a Claude.ai project with the agency brief, technical context document, theme specifications, and accessibility requirements uploaded as knowledge. Share with the design agency contact. Zero engineering effort, deployable today.

**Phase 2 (future, for multiple external partners):** Option C. Build a lightweight RAG-based Claude bot deployed as a web application. Use the project's own file-sharing infrastructure to deliver it (meta-use of SGraph Send). This becomes an Explorer workstream when we have more than one external partner.

### 3.4 Context Loading Strategy (for Option A)

Documents to upload for the design agency Claude project:

| Document | Purpose |
|----------|---------|
| Design agency brief (when complete) | Primary context |
| Technical context for designers (Section 1 deliverable above) | How the system works |
| IFD guide (`library/guides/development/ifd/v1.2.1__ifd__intro-and-how-to-use.md`) | How versioning works |
| Theme system spec (CSS variables from admin UI architecture) | Design system tokens |
| Accessibility requirements (from the brief) | Multi-theme, high-contrast, colour-blind |
| Current screenshots of working UI | Visual reference |

**Do NOT upload:** codebase, deployment configs, admin credentials, team internal briefs, security architecture details, role debriefs.

### 3.5 Deliverable

**File:** `team/roles/architect/reviews/26-02-14/v0.3.2__research__external-partner-claude-bot.md`

A research brief covering the four options with recommendation, suitable for Dinis to review and decide.

**Status:** Research complete (above). Formal brief is next action.

---

## 4. Slack/WhatsApp Bot Integration Research

**Priority:** P2
**Corresponds to:** E7 from the [next-steps review](v0.3.0__review__next-steps-from-wardley-briefs.md)

### 4.1 Current State of Maturity

#### Slack Bot Integration with Claude

| Platform/Approach | Maturity | Notes |
|-------------------|----------|-------|
| **Anthropic Claude for Slack** (official) | Production | Official Slack app. Claude responds in channels/DMs. No custom knowledge base -- uses general Claude training. Not suitable for project-specific context. |
| **Custom Slack bot via Anthropic API** | Well-established pattern | Build a Slack bot (Bolt SDK or AWS Lambda + API Gateway) that receives messages, calls Claude API with project context injected as system prompt, replies in Slack. Full control over context. |
| **MCP-connected Slack bot** | Emerging | A Slack bot that uses MCP to connect Claude to the project repo. Early-stage tooling; MCP servers for Slack are experimental. |
| **Third-party (e.g., Dust, Stack AI, Relevance AI)** | Production | Platforms that let you build Slack bots with RAG over uploaded documents. Managed infrastructure but vendor dependency. |

#### WhatsApp Bot Integration with Claude

| Platform/Approach | Maturity | Notes |
|-------------------|----------|-------|
| **WhatsApp Business API + Claude API** | Production (WhatsApp side), requires custom glue | WhatsApp Business API (via Meta's Cloud API or BSPs like Twilio, MessageBird) provides webhook-based message delivery. Connect to Claude API for response generation. Requires Meta Business verification. |
| **Twilio WhatsApp Sandbox** | Production | Twilio provides a WhatsApp sandbox for development. Messages route to a webhook (Lambda or server). Webhook calls Claude API with context. Quick to prototype. |
| **Third-party platforms** | Production | Platforms like Botpress, Voiceflow, or Manychat support WhatsApp + AI model integration. Managed but less control. |

### 4.2 What It Would Take

#### Slack Bot (Custom, Recommended Path)

**Architecture:**
```
Slack workspace
    |
    v (Slack Events API / Socket Mode)
Lambda function (or Fargate container)
    |
    +-- Extract message text
    +-- Load project context (from S3 or repo)
    +-- Call Anthropic API: system_prompt = project_context, user_message = slack_message
    +-- Post response back to Slack channel
```

**Effort estimate:** 2-3 sessions for Explorer team (Architect + Dev)
- Session 1: Slack app setup, event subscription, Lambda scaffold
- Session 2: Claude API integration with project context injection
- Session 3: Context management (what docs to include, refresh strategy)

**Infrastructure:**
- Slack workspace (existing or new)
- Slack app with Bot Token + Event Subscriptions
- Lambda function (fits our existing Lambda infrastructure)
- Anthropic API key (with usage monitoring)
- S3 bucket for context documents (or inline in system prompt)

**Limitations:**
- Slack message size limit: 40,000 characters (sufficient for most responses)
- Claude API token limit determines context window (200K for Claude 3)
- No interactive file sharing through Slack (but could share SGraph Send links)

#### WhatsApp Bot (Twilio Path)

**Architecture:**
```
WhatsApp (user sends message)
    |
    v (Twilio webhook)
Lambda function
    |
    +-- Parse incoming message
    +-- Load project context
    +-- Call Anthropic API
    +-- Send response via Twilio WhatsApp API
    v
WhatsApp (user receives response)
```

**Effort estimate:** 3-4 sessions for Explorer team
- Session 1: Twilio account setup, WhatsApp sandbox, webhook Lambda
- Session 2: Claude API integration (same as Slack, shared module)
- Session 3: WhatsApp-specific UX (message formatting, media handling)
- Session 4: Testing with real devices

**Infrastructure:**
- Twilio account (WhatsApp sandbox for dev, Business API for production)
- Meta Business verification (for production WhatsApp -- takes days/weeks)
- Lambda function (shared infrastructure with Slack bot)
- Same Anthropic API key and context management

**Limitations:**
- WhatsApp message size limit: 4,096 characters (much more restrictive than Slack)
- Media sharing possible but adds complexity
- Production WhatsApp requires Meta Business verification process
- Per-message costs via Twilio

### 4.3 Recommendation

**Build Slack first.** Lower friction (no Meta verification), larger message size limit, better developer tooling, and our primary team communication channel. The Claude API integration layer (context loading, prompt engineering, response formatting) is shared between Slack and WhatsApp -- build it once for Slack, then add WhatsApp as a second channel.

**Shared module architecture:**
```
sgraph_ai_app_send/
  bot/
    context_loader.py       (loads project docs from repo/S3)
    claude_client.py        (Anthropic API wrapper with context injection)
    response_formatter.py   (format for target platform)
    channels/
      slack.py              (Slack-specific message handling)
      whatsapp.py           (WhatsApp-specific message handling)
```

### 4.4 Deliverable

**File:** `team/roles/architect/reviews/26-02-14/v0.3.2__research__slack-whatsapp-bot-integration.md`

A research brief with architecture diagrams, effort estimates, and recommendation. Suitable for Dinis to decide whether to prioritise.

**Status:** Research complete (above). Formal brief is next action.

---

## 5. Unencrypted Mode Evaluation

**Priority:** P3
**Corresponds to:** E8 from the [next-steps review](v0.3.0__review__next-steps-from-wardley-briefs.md)

### 5.1 Current Encryption Coupling

The encryption is tightly coupled in the current architecture, but at predictable points:

**Client side (`crypto.js` and `send-upload.js`):**
1. `SendCrypto.generateKey()` -- generates AES-256-GCM key
2. `SendCrypto.encryptFile(key, plaintext)` -- encrypts the full buffer
3. `SendCrypto.exportKey(key)` -- exports key to base64url for the share link
4. Key goes into URL fragment: `download.html#transfer_id/key`

**Client side (`send-download.js`):**
1. Key extracted from URL fragment
2. `SendCrypto.importKey(keyString)` -- reconstructs the CryptoKey
3. `SendCrypto.decryptFile(key, ciphertext)` -- decrypts the buffer

**Server side:** The server is _already encryption-agnostic_. `Transfer__Service` stores and retrieves opaque bytes. It has no knowledge of whether those bytes are encrypted or plaintext. The `content_type_hint` is metadata passed through but never acted on.

### 5.2 Architecture Assessment: Making Encryption Pluggable

The good news: the server needs zero changes. The abstraction is already correct -- the server stores bytes, the client decides what those bytes contain.

The change is entirely client-side:

#### Proposed: Transfer Mode Enum

```javascript
const TransferMode = {
    ENCRYPTED: 'encrypted',    // Default. Current behaviour.
    PLAINTEXT: 'plaintext'     // New. Skip encryption/decryption.
};
```

#### Upload Flow Changes

```javascript
// In send-upload.js startUpload():
if (this.transferMode === TransferMode.ENCRYPTED) {
    // Current flow: generate key, encrypt, upload ciphertext
    const key       = await SendCrypto.generateKey();
    const keyString = await SendCrypto.exportKey(key);
    const encrypted = await SendCrypto.encryptFile(key, plaintext);
    payload = encrypted;
    shareUrl = buildUrl(transferId, keyString);   // key in fragment
} else {
    // New flow: upload plaintext directly, no key
    payload = plaintext;
    shareUrl = buildUrl(transferId);              // no key in fragment
}
```

#### Download Flow Changes

```javascript
// In send-download.js:
if (keyString) {
    // Key present in URL -> encrypted mode
    const key = await SendCrypto.importKey(keyString);
    const decrypted = await SendCrypto.decryptFile(key, ciphertext);
    deliverFile(decrypted);
} else {
    // No key in URL -> plaintext mode (data is not encrypted)
    deliverFile(downloadedBytes);
}
```

#### Server Metadata Extension

Add a `transfer_mode` field to the transfer metadata:

```python
meta = dict(
    transfer_id     = transfer_id,
    transfer_mode   = 'encrypted',    # or 'plaintext'
    # ... existing fields ...
)
```

This is informational -- the server does not change behaviour based on it. It exists for:
- Transparency logging ("this transfer was sent without encryption")
- Admin visibility ("how many unencrypted transfers are there?")
- Recipient UI ("this file was sent without encryption -- the server could see its contents")

### 5.3 Security Guardrails

To preserve the default-secure posture:

| Guardrail | Implementation |
|-----------|----------------|
| **Encrypted by default** | `TransferMode.ENCRYPTED` is the default. Plaintext mode requires explicit user action. |
| **Visual warning on upload** | If plaintext mode selected, show a clear warning: "This file will be stored without encryption. The server can see its contents." |
| **Visual indicator on download** | If no key in URL, show: "This file was sent without encryption." Different visual treatment than encrypted transfers. |
| **No silent degradation** | If encryption fails, do NOT fall back to plaintext. Show an error. Plaintext is a deliberate choice, not a fallback. |
| **Audit trail** | `transfer_mode` in metadata enables tracking of unencrypted transfers for compliance and monitoring. |
| **Admin visibility** | Admin pulse/analytics should show encrypted vs. plaintext transfer ratios. |

### 5.4 Impact on Value Proposition

This needs Advocate and Ambassador input, but from an architecture perspective:

- The default is always encrypted. The architecture enforces this.
- Plaintext mode is an explicit opt-in with visible warnings.
- The share URL structure differs (no key fragment) -- recipients can see at a glance whether a transfer is encrypted.
- The underlying system remains zero-knowledge for encrypted transfers. Plaintext mode is a separate, clearly labelled path.

### 5.5 Deliverable

No separate document needed at P3. This section serves as the architecture assessment. If Dinis decides to proceed, the Architect produces a full design document.

**Status:** Assessment complete. Awaiting Advocate/AppSec review and Dinis decision.

---

## 6. Handover Brief Preparation

**Corresponds to:** V1 from the [next-steps review](v0.3.0__review__next-steps-from-wardley-briefs.md) and AD-2 (handover brief format)

### 6.1 Components Ready for Handover

Per the [Wardley Maps evolution map](v0.3.0__review__next-steps-from-wardley-briefs.md), five components are at Custom-Built stage and ready for the Villager team:

| Component | Current Version | Key Files | Test Coverage |
|-----------|----------------|-----------|---------------|
| **Browser-side encryption** | v0.1.0 (crypto.js) | `sgraph_ai_app_send__ui__user/v0/v0.1/v0.1.0/js/crypto.js` | Unit tests for encrypt/decrypt round-trip |
| **File upload/download flow** | v0.1.4 (send-upload, send-download) | `send-upload.js`, `send-download.js`, `Routes__Transfers.py`, `Transfer__Service.py` | Full flow tests (create, upload, complete, info, download) |
| **S3 storage backend** | v0.3.x | `Storage_FS__S3.py`, `Send__Config.py`, `Enum__Storage__Mode.py` | Unit tests + LocalStack integration |
| **Token/invitation system** | v0.3.x | `lambda__admin/` (token CRUD, usage tracking, revocation) | Full CRUD tests |
| **Link sharing** | v0.1.4 | URL fragment scheme, hash routing, token parameter | Covered by upload flow tests |

### 6.2 Handover Brief Format

Using the format proposed in AD-2 of the [next-steps review](v0.3.0__review__next-steps-from-wardley-briefs.md):

```
team/roles/explorer/handovers/v0.3.2__handover__{component}.md

Sections:
1. Component overview (what it does, user-facing behaviour)
2. Architecture (how it works, dependencies, data flows)
3. Known limitations and edge cases
4. Performance characteristics (what's fast, what's slow, what hasn't been tested)
5. Test coverage (what's tested, what isn't)
6. Configuration and environment variables
7. Maturity assessment (why it's ready for productisation)
```

### 6.3 What the Architect Produces

The Architect writes sections 2, 3, 4, and 7 for each component. Sections 1, 5, and 6 come from Dev and QA.

**Handover documents to produce:**

1. `v0.3.2__handover__browser-encryption.md`
2. `v0.3.2__handover__file-transfer-flow.md`
3. `v0.3.2__handover__s3-storage-backend.md`
4. `v0.3.2__handover__token-system.md`
5. `v0.3.2__handover__link-sharing.md`

**Status:** Format agreed. Directory `team/roles/explorer/handovers/` needs creation. Content production is next action -- dependent on AD-2 approval from Dinis.

### 6.4 Known Limitations to Document

Issues the Architect has identified that must be in the handover briefs:

| Component | Limitation | Impact |
|-----------|-----------|--------|
| Encryption | Entire file loaded into memory | Fails for files > ~500 MB in typical browsers |
| Encryption | Single IV per file (not per chunk) | Secure but limits future streaming decryption |
| Upload flow | No retry on failure | Single-shot upload; partial failure = full restart |
| Upload flow | Raw dicts instead of Type_Safe throughout service layer | Technical debt (see `Transfer__Service.py` todos) |
| S3 backend | No multipart upload | Single PUT per file; S3 limit is 5 GB per PUT |
| Token system | In-memory default (no persistence across Lambda cold starts in dev) | Production must use S3 or cache backend |
| Link sharing | Key in URL fragment visible in browser history | By design (zero-knowledge) but users may not understand |

---

## 7. Architectural Decisions Pending

Four decisions from the [next-steps review](v0.3.0__review__next-steps-from-wardley-briefs.md) require Dinis's input:

### AD-1: Environment Separation Strategy

**Question:** How do we separate Explorer and Villager AWS infrastructure?
**Options:** (A) Separate AWS accounts, (B) Same account with naming conventions, (C) Same account with separate stacks
**Architect recommendation:** Option B for now
**Impact:** Blocks Villager team setup
**Decision needed from:** Dinis / DevOps

### AD-2: Handover Brief Format

**Question:** What format do Explorer-to-Villager handover briefs follow?
**Proposed format:** Seven-section document (see Section 6.2 above)
**Impact:** Blocks handover document production
**Decision needed from:** Explorer and Villager meta-roles (Dinis to approve)

### AD-3: Branching Strategy for Two Teams

**Question:** How do Explorer and Villager branches coexist?
**Options:** (A) Explorer on `dev`, Villager on `release/*` branches, (B) Explorer on `dev`, Villager on `main`, (C) Separate repos
**Architect recommendation:** Option A
**Impact:** Blocks Villager CI/CD pipeline setup
**Decision needed from:** Dinis / DevOps

### AD-4: Large File Transfer Architecture

**Question:** Chunk before or after encryption? S3 multipart or per-chunk objects? Chunk size?
**Architect recommendation:** Chunk-then-encrypt, per-chunk S3 objects via Storage_FS, 5 MB default chunk size (see Section 2)
**Impact:** Blocks large file transfer design document
**Decision needed from:** Dinis (priority and approach approval)

### New Decisions Identified in This Session

#### AD-5: Unencrypted Mode

**Question:** Should SGraph Send offer an explicit unencrypted transfer mode?
**Architect assessment:** Architecturally feasible with minimal server changes (see Section 5). Risk is to value proposition.
**Decision needed from:** Dinis, with input from Advocate (user perspective) and AppSec (security implications)

#### AD-6: External Partner Communication Channel

**Question:** How should external partners (starting with design agency) interact with project knowledge?
**Architect recommendation:** Phase 1: Claude.ai project with uploaded docs. Phase 2: Custom RAG bot (see Section 3).
**Decision needed from:** Dinis (approach and timing)

---

## Summary: Deliverables and Sequence

| # | Deliverable | Status | Blocked By | Next Action |
|---|-------------|--------|------------|-------------|
| D1 | Technical context for design agency brief | Ready to produce | Nothing | Write `v0.3.2__technical-context__design-agency-brief.md` |
| D2 | Large file transfer design document | Preliminary design complete | AD-4 (approach approval) | Expand Section 2 into full design doc after AD-4 decision |
| D3 | External partner Claude bot research brief | Research complete | AD-6 (approach approval) | Formalise Section 3 into research brief |
| D4 | Slack/WhatsApp bot research brief | Research complete | Nothing | Formalise Section 4 into research brief |
| D5 | Unencrypted mode architecture assessment | Complete (Section 5) | AD-5 (go/no-go decision) | Awaiting Advocate + AppSec + Dinis |
| D6 | Five handover briefs (Architect sections) | Format proposed | AD-2 (format approval) | Create `team/roles/explorer/handovers/` and write docs after AD-2 |
| D7 | AD decision requests to Dinis | Complete (Section 7) | Dinis review | Dinis to review AD-1 through AD-6 |

**Recommended sequence:**
1. **Now:** D1 (design agency brief is P1 and unblocked)
2. **Now:** D4 (Slack/WhatsApp research is unblocked)
3. **Now:** D7 (submit decisions to Dinis)
4. **After AD-2:** D6 (handover briefs)
5. **After AD-4:** D2 (large file transfer full design)
6. **After AD-6:** D3 (Claude bot formal brief)
7. **After AD-5:** D5 (unencrypted mode, if approved)

---

*Architect action plan complete. This document supersedes the next-steps listing in [v0.3.0 review](v0.3.0__review__next-steps-from-wardley-briefs.md) with concrete designs, research findings, and sequenced deliverables.*
