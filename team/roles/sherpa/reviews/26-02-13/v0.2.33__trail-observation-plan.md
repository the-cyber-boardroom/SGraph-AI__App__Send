# Trail Observation Plan

**Version:** v0.2.33
**Date:** 13 February 2026
**Role:** Sherpa
**Session:** `claude/read-secure-send-brief-Mz6yN`
**Status:** First activation -- defining what telemetry is needed before friendlies programme launches

---

## 1. Observation Philosophy

Trails never lie. Users do not always know why they struggled, but their behaviour tells the truth. The Sherpa's trail observation is not about surveillance -- it is about understanding the terrain through the footprints left behind.

**Principles for SGraph Send trail observation:**

1. **Server-side only.** All trail data comes from server-side events (CloudFront logs, Lambda execution, application events). No client-side analytics. No cookies. No JavaScript tracking. This aligns with the zero-cookie policy (Decision D025) and eliminates the need for consent flows.
2. **IP addresses are hashed.** All IP-based data uses SHA-256 with a daily salt (stored as `ip_hash`). We observe patterns, not individuals.
3. **Trails are structured data.** Every observation is linked to a flow stage, a product version, and a timestamp. Unstructured logs have no analytical value.
4. **Cache service is the backbone.** All trail data flows through the cache service (Decision D026) using the LETS pipeline (Decision D027). Raw events are saved immediately; aggregations are computed on demand and cached.

---

## 2. Telemetry Requirements by Journey Stage

### Sender Trail

| Stage | Event | Data Points | Priority |
|-------|-------|-------------|----------|
| **S1: Land** | `page.load.upload` | ip_hash, user_agent, referrer, viewport_width, viewport_height, locale, timestamp, product_version | P1 |
| **S2: Authenticate** | `gate.token.submit` | ip_hash, token_hash (not the token itself), success (boolean), timestamp | P1 |
| **S2: Authenticate** | `gate.token.error` | ip_hash, error_type, retry_count, timestamp | P1 |
| **S3: Choose Mode** | `upload.mode.select` | ip_hash, mode (file/text), timestamp | P2 |
| **S4: Select Content** | `upload.file.select` | ip_hash, method (drag/click/test-file), file_size_bytes, content_type, timestamp | P1 |
| **S4: Select Content** | `upload.text.input` | ip_hash, char_count, timestamp | P2 |
| **S5: Encrypt & Upload** | `transfer.encrypt.start` | ip_hash, transfer_id, file_size_bytes, content_type, timestamp | P1 |
| **S5: Encrypt & Upload** | `transfer.encrypt.complete` | ip_hash, transfer_id, duration_ms, timestamp | P1 |
| **S5: Encrypt & Upload** | `transfer.upload.start` | ip_hash, transfer_id, timestamp | P1 |
| **S5: Encrypt & Upload** | `transfer.upload.complete` | ip_hash, transfer_id, duration_ms, timestamp | P1 |
| **S5: Encrypt & Upload** | `transfer.upload.error` | ip_hash, transfer_id, error_type, error_message, timestamp | P1 |
| **S6: Share** | `transfer.complete` | ip_hash, transfer_id, is_text, timestamp | P1 |
| **S6: Share** | `share.copy.combined` | ip_hash, transfer_id, timestamp | P1 |
| **S6: Share** | `share.copy.link_only` | ip_hash, transfer_id, timestamp | P2 |
| **S6: Share** | `share.copy.key` | ip_hash, transfer_id, timestamp | P2 |
| **S6: Share** | `share.toggle.separate_key` | ip_hash, transfer_id, show (boolean), timestamp | P2 |
| **S6: Share** | `share.email.copy_text` | ip_hash, transfer_id, timestamp | P1 (when implemented) |
| **S6: Share** | `share.email.gmail_link` | ip_hash, transfer_id, timestamp | P1 (when implemented) |

### Recipient Trail

| Stage | Event | Data Points | Priority |
|-------|-------|-------------|----------|
| **R2: Open Link** | `page.load.download` | ip_hash, transfer_id, key_present (boolean), user_agent, referrer, viewport_width, timestamp, product_version | P1 |
| **R3: Decrypt & Download** | `transfer.decrypt.start` | ip_hash, transfer_id, timestamp | P1 |
| **R3: Decrypt & Download** | `transfer.decrypt.complete` | ip_hash, transfer_id, is_text, duration_ms, timestamp | P1 |
| **R3: Decrypt & Download** | `transfer.decrypt.error` | ip_hash, transfer_id, error_type (wrong_key, network, other), timestamp | P1 |
| **R4: Verify & Use** | `text.copy` | ip_hash, transfer_id, timestamp | P2 |
| **R4: Verify & Use** | `text.download_as_file` | ip_hash, transfer_id, timestamp | P2 |

### Token Trail

| Stage | Event | Data Points | Priority |
|-------|-------|-------------|----------|
| **Token activation** | `token.activate` | ip_hash, token_hash, timestamp, referrer | P1 |
| **Token usage** | `token.use` | ip_hash, token_hash, usage_count, usage_limit, timestamp | P1 |
| **Token exhaustion** | `token.exhausted` | token_hash, usage_count, usage_limit, timestamp | P1 |

### System Trail (not user-facing, but needed for side-effect detection)

| Event | Data Points | Priority |
|-------|-------------|----------|
| `health.check` | endpoint, status_code, response_time_ms, timestamp | P1 |
| `error.unhandled` | error_type, error_message, stack_trace_hash, timestamp | P1 |
| `deployment.version` | version, environment, timestamp | P1 |

---

## 3. Metrics to Track

### Primary Metrics (establish baselines before friendlies programme)

| Metric | Definition | How to compute | Target (initial) |
|--------|-----------|----------------|------------------|
| **Completion rate (sender)** | % of page loads that result in a completed transfer | `transfer.complete` / `page.load.upload` | Establish baseline |
| **Completion rate (recipient)** | % of download page loads that result in a successful decrypt | `transfer.decrypt.complete` / `page.load.download` | Establish baseline |
| **Time to upload** | Median time from page load to transfer complete | `transfer.complete.timestamp - page.load.upload.timestamp` | Establish baseline |
| **Time to download** | Median time from page load to decrypt complete | `transfer.decrypt.complete.timestamp - page.load.download.timestamp` | Establish baseline |
| **Gate pass rate** | % of token submissions that succeed on first attempt | `gate.token.submit[success=true, retry_count=0]` / `gate.token.submit` | >90% |
| **Decrypt error rate** | % of decrypt attempts that fail | `transfer.decrypt.error` / `transfer.decrypt.start` | <10% |
| **Key present rate** | % of download page loads where the key was in the URL hash | `page.load.download[key_present=true]` / `page.load.download` | >95% (if hash-fragment URLs are working) |

### Abandonment Metrics

| Metric | Definition | Signal |
|--------|-----------|--------|
| **S1 bounce** | Loaded upload page but never selected a file or entered text | `page.load.upload` with no subsequent `upload.file.select` or `upload.text.input` |
| **S2 gate fail** | Entered token but it failed, and user did not retry | `gate.token.error` with no subsequent `gate.token.submit` |
| **S5 upload abandon** | Started encrypt/upload but it failed, and user did not retry | `transfer.upload.error` with no subsequent `transfer.encrypt.start` |
| **S6 share abandon** | Transfer completed but no copy action taken | `transfer.complete` with no subsequent `share.copy.*` |
| **R2 no-key abandon** | Loaded download page without key, never entered one | `page.load.download[key_present=false]` with no subsequent `transfer.decrypt.start` |
| **R3 wrong-key abandon** | Attempted decrypt with wrong key, never retried | `transfer.decrypt.error[error_type=wrong_key]` with no subsequent `transfer.decrypt.start` |

### Time-Between-Steps Metrics

| Transition | What it reveals |
|-----------|----------------|
| `page.load.upload` to `upload.file.select` | Time to understand the interface. Long = confusion. |
| `upload.file.select` to `transfer.encrypt.start` | Time to decide to upload. Long = hesitation/trust issue. |
| `transfer.complete` to `share.copy.combined` | Time to share. Long = figuring out what to do with the link. |
| `page.load.download` to `transfer.decrypt.start` | Time to act on download page. Long = confusion or missing key. |
| `transfer.complete` to first `page.load.download` | Time between sender sharing and recipient opening. Reveals sharing channel latency. |

---

## 4. Cache Service Integration

The cache service (Decision D026) with its LETS pipeline (Decision D027) is the backbone for all trail data.

### Trail Data Schema

Each trail event is stored as a file in the cache service under the transfer's cache entry:

```
cache/{transfer_cache_id}/
    events/
        {timestamp}_{event_type}.json     # Raw event file
    aggregations/
        latest/
            event_summary.json            # Latest aggregation
        2026/02/13/14/
            event_summary.json            # Hourly aggregation
```

### Global Analytics Schema

Site-wide trail aggregations use the site analytics cache namespace (Schema A from Architect):

```
cache/site-analytics/
    raw/
        2026/02/13/14/30/
            {timestamp}_{event_type}.json   # Raw events (30-min buckets)
    aggregations/
        latest/
            trail_summary.json              # Current pulse
            abandonment_rates.json          # Current abandonment rates
            time_between_steps.json         # Current timing data
        2026/02/13/
            trail_summary.json              # Daily aggregation
            abandonment_rates.json
```

### LETS Pipeline for Trail Data

1. **Load:** Every server-side request handler writes a raw trail event file to the cache service (immediate, synchronous with the request).
2. **Extract:** On-demand query reads raw events for a time window.
3. **Transform:** Compute aggregations (completion rates, abandonment rates, time-between-steps, error frequencies).
4. **Save:** Write the aggregation to both the temporal path and the latest path. Next query only processes events since the last aggregation.

### What the Cache Service Enables for the Sherpa

| Capability | How |
|-----------|-----|
| **Real-time pulse** | Read `latest/trail_summary.json` -- shows current active users, in-flight transfers, error rate |
| **Abandonment analysis** | Read `latest/abandonment_rates.json` -- shows where users drop off |
| **Side effect detection** | Compare `aggregations/{today}/trail_summary.json` with `aggregations/{yesterday}/trail_summary.json` after a release |
| **Per-transfer deep dive** | Read `cache/{transfer_cache_id}/events/` -- all events for a specific transfer, for debugging user issues |
| **Temporal analysis** | Read hourly aggregations to see when usage peaks, when errors cluster, when abandonment spikes |

---

## 5. Baseline Metrics: What to Establish Before Friendlies

Before the first cohort of friendlies begins, we need baselines for every primary metric. Without baselines, we cannot measure improvement.

### Phase 1: Infrastructure (before any friendlies)

| Task | Owner | Status |
|------|-------|--------|
| Enable CloudFront access logs with IP masking | DevOps + DPO | Pending (Decision D018, RF-22) |
| Implement raw trail event recording in Lambda handlers | Dev | Pending |
| Implement cache service integration for trail storage | Dev | Pending (Architect schema delivered) |
| Verify trail events are being written for all flow stages | QA | Pending |
| Create Sherpa trail observation dashboard (read-only) | Dev | Pending |

### Phase 2: Baseline Capture (first 5-10 friendlies)

| Task | Owner | Status |
|------|-------|--------|
| Run 5-10 guided transfers with beta users | Sherpa | Pending |
| Record baseline: completion rate (sender) | Sherpa | Pending |
| Record baseline: completion rate (recipient) | Sherpa | Pending |
| Record baseline: time to upload (median) | Sherpa | Pending |
| Record baseline: time to download (median) | Sherpa | Pending |
| Record baseline: decrypt error rate | Sherpa | Pending |
| Record baseline: key present rate | Sherpa | Pending |
| Record baseline: abandonment rates at each stage | Sherpa | Pending |
| Produce first trail observation report | Sherpa | Pending |

### Phase 3: Side Effect Detection Framework

| Task | Owner | Status |
|------|-------|--------|
| Define pre/post-release comparison methodology | Sherpa + QA | Pending |
| Create automated comparison script (today vs yesterday aggregations) | Dev | Pending |
| Define alerting thresholds (e.g. >10% abandonment rate increase) | Sherpa + Conductor | Pending |
| Test framework with a known-safe release | QA | Pending |

---

## 6. Integration with DevOps

### Observability Infrastructure Needed

| Component | Purpose | Priority | Status |
|-----------|---------|----------|--------|
| **CloudFront access logs** | Page load events, referrer, user-agent, IP (hashed) | P1 | Pending -- DPO must sign off IP masking (RF-22) |
| **Lambda execution logs** | Request timing, errors, transfer lifecycle events | P1 | Partially available (CloudWatch) |
| **Application event recording** | Trail events written by request handlers | P1 | Not yet implemented |
| **Cache service** | Storage and aggregation backbone | P1 | Schema delivered, implementation pending |
| **Trail observation dashboard** | Sherpa's read-only view of trail data | P2 | Not yet implemented |
| **Alerting** | Automated notification when metrics change significantly | P3 | Not yet designed |

### Coordination Points with DevOps

1. **CloudFront log format:** The Sherpa needs specific fields in the logs: timestamp, edge location, response status, bytes transferred, time-to-first-byte, referrer, user-agent. DevOps should confirm these are available in the standard CloudFront log format.
2. **IP masking pipeline:** Logs must be processed to hash IP addresses before they reach the trail observation layer. The DPO must approve the hashing scheme (SHA-256 with daily salt) before logging is enabled.
3. **Log retention:** Raw trail events should be retained for at least 90 days. Aggregations should be retained indefinitely (they are small). DevOps should configure S3 lifecycle policies accordingly.
4. **Cache service deployment:** The cache service must be deployed and accessible from both Lambda functions (user and admin) before trail recording can begin.
5. **Dashboard access:** The Sherpa trail dashboard should be part of the admin UI (Decision D032 -- admin UI first for modular architecture).

---

## 7. What the Sherpa Will Produce After Each Release

After every release that touches user-facing code, the Sherpa will produce a **trail observation report** containing:

1. **Pre/post comparison:** Completion rates, abandonment rates, error rates, timing -- before and after.
2. **Anomaly detection:** Any metric that changed by more than 10% (or crossed an absolute threshold).
3. **Flow stage analysis:** Which stages were affected? Were there unexpected cross-flow impacts (e.g. sender-side change affecting recipient experience)?
4. **Sample trails:** 3-5 representative trails from the release period, annotated with observations.
5. **Recommendations:** Friction points revealed by the trail data, with proposed resolutions and routing to the appropriate roles.

Reports will be filed at: `team/roles/sherpa/reviews/{YY-MM-DD}/v{version}__trail-observation-report__{release-description}.md`

---

## 8. Trail Observation Readiness Checklist

| # | Requirement | Status | Blocker |
|---|-------------|--------|---------|
| 1 | Cache service core implemented | Pending | Architect schema delivered; Dev implementation needed |
| 2 | Raw trail events recorded for all sender flow stages | Pending | Dev implementation needed |
| 3 | Raw trail events recorded for all recipient flow stages | Pending | Dev implementation needed |
| 4 | Token trail events recorded | Pending | Token system implementation needed |
| 5 | CloudFront logs enabled with IP masking | Pending | DPO sign-off needed (RF-22) |
| 6 | LETS aggregation pipeline implemented | Pending | Dev implementation needed |
| 7 | Trail observation dashboard accessible in admin UI | Pending | Admin UI modular architecture needed |
| 8 | Baseline metrics captured from initial friendlies | Pending | All above must be complete first |
| 9 | Side effect detection framework tested | Pending | Baseline must exist first |
| 10 | Sherpa can produce first trail observation report | Pending | All above must be complete first |

**Estimated readiness:** Once the cache service core and trail event recording are implemented (Dev tasks D-01 through D-06 in the Dev implementation plan), the Sherpa can begin capturing baselines.

---

*SGraph Send Sherpa -- Trail Observation Plan*
*First activation -- infrastructure requirements defined*
