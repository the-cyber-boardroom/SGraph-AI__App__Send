# v0.2.24 — DevOps Response to Daily Brief (13 Feb 2026)

**Version:** v0.2.24
**Date:** 2026-02-13
**Role:** DevOps
**Context:** Response to `team/humans/dinis_cruz/briefs/02/13/v0.2.16__daily-brief__sgraph-send-13-feb-2026.md`
**User amendments:** Rate limiting deferred (needs visualisation first); CORS already handled by osbot-fast-api.

---

## 1. AWS Observability Settings — Comprehensive Brief (P1)

### Current State

| Service | Logging Enabled? | Notes |
|---------|-----------------|-------|
| Lambda (User) | **Yes** — CloudWatch Logs | Default. Execution logs, errors, cold starts |
| Lambda (Admin) | **Yes** — CloudWatch Logs | Default. Same as above |
| CloudFront | **Unknown** — likely disabled | Access logs need explicit S3 bucket configuration |
| S3 (transfer storage) | **Unknown** — likely disabled | Server access logging or CloudTrail data events needed |
| Lambda Function URLs | **Partial** — no WAF support | Function URLs don't support WAF. No request-level logging beyond Lambda itself |

### What Should Be Enabled

#### Tier 0: Already Active (no cost, no action)
- **Lambda CloudWatch Logs** — already enabled by default. Every invocation logged.
- **CloudWatch Metrics** — Lambda invocation count, duration, errors, throttles. Built-in.
- **CORS** — already handled by `osbot-fast-api` (per user confirmation). Verify headers in smoke test.

#### Tier 1: Enable Now (low cost, high value)

| Setting | Service | What It Gives Us | Estimated Cost |
|---------|---------|-------------------|---------------|
| **CloudFront Access Logs** | CloudFront → S3 | Every HTTP request: IP, path, status, user-agent, latency | S3 storage only (~$0.02/GB) |
| **S3 Server Access Logs** | S3 → S3 (separate bucket) | Every S3 operation: GET, PUT, DELETE on transfer bucket | S3 storage only (~$0.02/GB) |
| **CloudTrail (management events)** | CloudTrail | API calls to AWS services: who did what, when | Free (first trail, management events) |
| **Lambda Insights** | CloudWatch | Enhanced metrics: memory usage, CPU, network, cold start duration | ~$0.01 per function per hour |

**Action items:**
1. Create logging S3 bucket: `sgraph-send-logs-{env}` (separate from transfer storage — per AppSec)
2. Enable CloudFront access logging → logs bucket
3. Enable S3 server access logging → logs bucket (different prefix)
4. Enable CloudTrail (if not already active)
5. Consider Lambda Insights for performance visibility

#### Tier 2: Enable Before Public Launch (medium cost)

| Setting | Service | What It Gives Us | Estimated Cost |
|---------|---------|-------------------|---------------|
| **CloudTrail Data Events** | CloudTrail | Every S3 GetObject/PutObject logged | ~$0.10 per 100K events |
| **CloudWatch Alarms** | CloudWatch | Alert on error rate spikes, latency, 5xx codes | ~$0.10/alarm/month |
| **X-Ray Tracing** | Lambda + CloudFront | End-to-end request tracing across services | ~$5/million traces |

#### Tier 3: Deferred (per user directive)

| Setting | Why Deferred |
|---------|-------------|
| **WAF** | Lambda Function URLs don't support WAF directly. Would need API Gateway or CloudFront in front. Defer. |
| **Rate Limiting** | Needs traffic visualisation first (per user). Enable after observability pipeline shows patterns. |
| **GuardDuty** | Threat detection. Valuable but not needed for beta with known users. |

### Cost Estimate (Tier 1, Monthly, Beta Traffic)

Assuming ~100 users, ~1000 transfers/month:
- CloudFront logs: < $0.01/month
- S3 access logs: < $0.01/month
- CloudTrail (management): Free
- Lambda Insights: ~$0.50/month
- **Total: < $1/month**

---

## 2. Collector Pipeline Architecture (P2)

### Design: Collect → Store → Visualise

```
┌─────────────────────────────────────┐
│         DATA SOURCES                │
├──────────┬──────────┬───────────────┤
│ CloudWatch│ S3 Logs  │ App Events   │
│ Logs     │          │              │
│ (Lambda) │(CloudFront│(Transfer     │
│          │ + S3)    │ lifecycle)   │
└────┬─────┴────┬─────┴──────┬───────┘
     │          │            │
     ▼          ▼            ▼
┌─────────────────────────────────────┐
│         COLLECTORS                  │
│  (Lambda functions, scheduled)      │
│  - Track high-water mark per source │
│  - Incremental fetch (no duplicates)│
│  - Transform to common format       │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│         S3 DATA LAKE                │
│  sgraph-send-datalake-{env}/        │
│  ├── cloudwatch/                    │
│  │   ├── lambda-user/YYYY/MM/DD/    │
│  │   └── lambda-admin/YYYY/MM/DD/   │
│  ├── cloudfront/YYYY/MM/DD/         │
│  ├── s3-access/YYYY/MM/DD/          │
│  ├── app-events/YYYY/MM/DD/         │
│  ├── google-analytics/YYYY/MM/DD/   │
│  └── _metadata/                     │
│      └── high-water-marks.json      │
└──────────────┬──────────────────────┘
               │
               ▼
┌─────────────────────────────────────┐
│         VISUALISATION               │
│  (Admin UI dashboards)              │
│  - Transfer volume over time        │
│  - Error rates                      │
│  - Latency percentiles              │
│  - User activation funnel           │
│  - Token usage tracking             │
└─────────────────────────────────────┘
```

### High-Water Mark Pattern

Each collector tracks its last fetch position in `_metadata/high-water-marks.json`:

```json
{
  "cloudwatch_lambda_user": {
    "last_timestamp": "2026-02-13T10:30:00Z",
    "last_log_stream": "2026/02/13/[$LATEST]abc123"
  },
  "cloudfront_access_logs": {
    "last_file_processed": "E1234.2026-02-13-10.abc123.gz"
  },
  "app_events": {
    "last_event_id": "evt_00001234"
  }
}
```

### Collector Implementation (using osbot-aws, not boto3)

Each collector follows Load → Extract → Save:
1. **Load:** Read high-water mark for this source
2. **Extract:** Fetch new data since high-water mark (using osbot-aws)
3. **Save:** Write to S3 data lake in date-partitioned path, update high-water mark

### Google Analytics Collection (P3)

GA4 data can be pulled via the Google Analytics Data API (GA4 property `G-GQTMWE0LHP`):
- Requires service account with GA read access
- Pull daily reports: page views, sessions, user locations, devices
- Store as JSON in `google-analytics/YYYY/MM/DD/report.json`
- **Note:** Requires Google Cloud service account setup — separate workstream

---

## 3. CORS Verification

CORS is handled by `osbot-fast-api`'s `Serverless__Fast_API` base class. To verify:
- Add CORS header check to existing smoke tests
- Verify `Access-Control-Allow-Origin` includes `send.sgraph.ai`
- Verify preflight (`OPTIONS`) requests return correct headers

This is a verification task, not a build task. Low effort.

---

## 4. Rate Limiting — DEFERRED

Per user directive: defer until observability pipeline provides traffic visualisation. The correct sequence is:
1. Enable logging (Tier 1 above)
2. Build collector pipeline
3. Visualise traffic patterns
4. Set meaningful rate limits based on actual data

---

## Summary: DevOps Actions

| # | Action | Priority | Blocks |
|---|---|---|---|
| 1 | Create logging S3 bucket (`sgraph-send-logs-{env}`) | P1 | All logging |
| 2 | Enable CloudFront access logs | P1 | Traffic visibility |
| 3 | Enable S3 server access logs | P1 | Storage visibility |
| 4 | Verify CloudTrail is active | P1 | Audit trail |
| 5 | Consider Lambda Insights | P1 | Performance visibility |
| 6 | Add CORS header check to smoke tests | P2 | Verification |
| 7 | Build first collector (CloudWatch logs) | P2 | Data lake |
| 8 | Create S3 data lake bucket structure | P2 | All collectors |
| 9 | Google Analytics API setup | P3 | GA data collection |
| 10 | Rate limiting | Deferred | Needs visualisation first |
