# v0.4.4 -- DPO Review: Log Retention and Archival for the SA Pipeline

**Version:** v0.4.4
**Date:** 2026-02-16
**Role:** DPO (Data Protection Officer)
**Context:** Review of log retention and archival design for the Server Analytics (SA) pipeline
**Sources:**
- `team/humans/dinis_cruz/briefs/02/16/v0.4.4__daily-brief__villager-team-16-feb-2026.md` (SA pipeline design)
- `team/humans/dinis_cruz/briefs/02/15/aws-setup/v0.3.6__aws-observability-brief.md` (observability configuration)
- `team/humans/dinis_cruz/briefs/02/15/aws-setup/v0.3.6__devops__aws-observability-setup-guide.md` (field-level configuration)
**Continues from:**
- `team/roles/dpo/reviews/26-02-16/v0.4.4__addendum__cloudfront-ip-verification-procedure.md` (IP verification and retention guidance)

---

## 1. Scope

This review covers the data protection implications of the SA pipeline's log retention and archival design across ALL data sources, not just CloudFront. The pipeline processes data from 15 AWS data sources (configured in v0.3.6), aggregates it through the LETS transformation stages, and archives it to Glacier.

The CloudFront-specific retention and IP verification requirements are detailed in the companion document (`v0.4.4__addendum__cloudfront-ip-verification-procedure.md`). This review takes a broader view across the entire SA pipeline.

---

## 2. Data Sources and Personal Data Classification

### 2.1 Complete Data Source Inventory

The v0.3.6 observability setup configures 15 data sources. Each needs a personal data classification.

| # | Data Source | Personal Data Present | Classification | Notes |
|---|-----------|----------------------|----------------|-------|
| 1 | CloudFront Real-Time Logs | Pseudonymising (user-agent, referrer) | **LOW RISK** | IP fields excluded. User-agent and referrer are pseudonymising at most. |
| 2 | CloudFront Additional Metrics | None | **NO RISK** | Aggregate metrics (request counts, error rates). No per-request data. |
| 3 | CloudFront Response Headers | None | **NO RISK** | Outbound header configuration. No personal data. |
| 4 | WAF (if enabled) | **YES -- IP addresses** | **HIGH RISK** | WAF sampled requests display full request headers including IP for 3 hours. Not currently enabled. DPO review required before activation. |
| 5 | X-Ray Tracing | None | **NO RISK** | Request IDs and timing. No personal data. |
| 6 | Lambda Insights | None | **NO RISK** | System metrics (CPU, memory, duration). |
| 7 | CloudWatch Logs | Pseudonymised (ip_hash) | **LOW RISK** | Application logs contain IP hashes (SHA-256 with daily salt). Hashed IPs are pseudonymised personal data under GDPR. |
| 8 | CloudTrail Data Events | None (Lambda/CF IPs, not user IPs) | **NO RISK** | Captures which AWS services called which APIs. User IPs not present. |
| 9 | S3 Access Logging | None | **NO RISK** | Requester is the Lambda execution environment, not end users. |
| 10 | S3 Request Metrics | None | **NO RISK** | Aggregate request/error counts. |
| 11 | S3 Storage Lens | None | **NO RISK** | Storage metrics. |
| 12 | AWS Budgets | None | **NO RISK** | Cost data. |
| 13 | Cost Anomaly Detection | None | **NO RISK** | Cost patterns. |
| 14 | Lambda Concurrency Limits | None | **NO RISK** | Operational configuration. |
| 15 | Contributor Insights | Depends on source | **CONDITIONAL** | Reads from Lambda log groups. If logs contain ip_hash, Contributor Insights surfaces it. Risk is inherited from source #7. |

### 2.2 Summary

**Data sources with personal data:** 2 of 15 (CloudFront Real-Time Logs, CloudWatch Logs)
**Data sources conditionally personal:** 1 (Contributor Insights, inherited from CloudWatch)
**Data sources with no personal data:** 11 of 15
**Data sources not enabled:** 1 (WAF -- HIGH RISK if enabled)

This is a good ratio. The DPO's previous involvement in the observability design means 73% of data sources have zero personal data concern.

---

## 3. Retention Period Recommendations

### 3.1 Retention Framework

The SA pipeline has five data stages. Retention applies differently at each stage because the data characteristics change through transformation.

**Principle:** Each transformation reduces personal data risk. Raw data (closest to the source) has the highest risk and should have the shortest retention. Aggregated data (statistical summaries) has the lowest risk and can have the longest retention.

### 3.2 Recommended Retention Periods by Data Stage

| Stage | Description | Personal Data Risk | Recommended Retention | Rationale |
|-------|-------------|-------------------|----------------------|-----------|
| **Raw (S3)** | Unprocessed log files as delivered by AWS services | Highest | **7 days** | Purpose: input to the pipeline. Once processed, raw files have no further purpose. 7-day buffer for reprocessing failures. |
| **Typed JSON (cache, raw/)** | Parsed per-record JSON | High (per-record granularity) | **30 days** | Purpose: debugging and pipeline verification. Per-record data enables individual request identification. 30 days provides adequate debugging window. |
| **Consolidated (cache, consolidated/)** | Grouped, deduplicated summaries | Medium (groups, not individuals) | **90 days** | Purpose: operational analytics. Individual requests are grouped (same URL + method + status = one count). Residual identification risk from user-agent values. |
| **Temporal Aggregations** | Time-bucketed statistics | Low to None | **See sub-table** | Statistical summaries. Individual requests indistinguishable. |
| **Archived Raw (Glacier)** | Original raw files in cold storage | Highest (same as raw) | **1 year** | Purpose: reprocessing and forensic investigation. After 1 year, operational value is minimal and retention becomes disproportionate. |

**Temporal Aggregation Sub-Table:**

| Granularity | Retention | Rationale |
|-------------|-----------|-----------|
| 30-minute | 30 days | High granularity, useful for recent operational analysis only. |
| Hourly | 90 days | Useful for daily pattern analysis over recent months. |
| Daily | 1 year | Useful for seasonal trend analysis. Low personal data risk. |
| Monthly | Indefinite | Purely statistical. No personal data risk. Valuable for long-term business intelligence. |

### 3.3 Why These Periods and Not Others

**Why not shorter?**

- Shorter retention (e.g., 24-hour raw, 7-day typed JSON) would satisfy the storage limitation principle but create operational problems: pipeline failures could not be debugged, reprocessing windows would be too narrow, and trend analysis would be limited.
- The personal data in the retained logs is pseudonymising (user-agent strings, referrer headers, IP hashes). The identification risk is low. Proportionality allows longer retention for low-risk data.

**Why not longer?**

- Raw and typed JSON data contain per-request records. These are the most granular and have the highest (though still low) personal data risk. Extending retention beyond 30 days for typed JSON or 7 days for raw data is disproportionate to the operational need.
- Glacier archival beyond 1 year is cost-effective (Glacier is cheap) but not justified by operational need. The DPO's role is to ensure that "it is cheap to store" is not used as justification for indefinite retention. Cost is not a lawful basis.

**Why indefinite for monthly aggregations?**

- Monthly aggregations are statistical summaries: "In January 2026, there were N requests, M unique user-agents, K distinct URLs." No individual request is identifiable. No personal data is distinguishable. These are the same category as published statistics.
- Deleting monthly aggregations would destroy business intelligence with no privacy benefit.

---

## 4. Lawful Basis Options

The SA pipeline processes data from CloudFront logs (pseudonymising) and CloudWatch logs (pseudonymised IP hashes). A lawful basis must be documented for this processing.

### 4.1 Option A: Legitimate Interests (Article 6(1)(f)) -- RECOMMENDED

**Purpose:** Processing log data for network security, operational monitoring, and service improvement.

**Legitimate Interests Assessment (summary):**

1. **Purpose test (is there a legitimate interest?):** Yes. Network security monitoring, service uptime assurance, error detection, and usage pattern analysis are recognised legitimate interests.

2. **Necessity test (is the processing necessary?):** Yes. The specific fields retained (URL paths, status codes, response times, user-agents, IP hashes) are the minimum needed for effective operational monitoring. IP addresses have been excluded at the collection point. File names are never captured. The processing is proportionate.

3. **Balancing test (do data subjects' rights override?):**
   - Data subjects reasonably expect a web service to monitor its own traffic.
   - The data is operational metadata, not behavioural profiles.
   - No automated decision-making affects individuals.
   - IP addresses have been excluded -- the strongest PII is absent.
   - IP hashes use daily salt, making re-identification impractical without the salt value.
   - User-agent strings are pseudonymising at most and are aggregated during consolidation.
   - **Safeguards:** IP exclusion, IP hashing, defined retention periods, access controls, no profiling.
   - **Conclusion:** Data subjects' rights do not override. Processing proceeds under legitimate interests.

**Advantages:** Straightforward, well-established for security and operational monitoring. Does not require explicit consent from each user.

**Disadvantages:** Requires maintaining a documented LIA that can be presented to a supervisory authority on request. Data subjects have the right to object under Article 21, though this right can be overridden if there are compelling legitimate grounds.

### 4.2 Option B: Performance of a Contract (Article 6(1)(b))

**Purpose:** Processing necessary for the performance of the file transfer service that the user has engaged with.

**Assessment:** This basis is weaker for log retention specifically. Processing the user's file transfer (encryption, storage, delivery) is clearly contractual. Retaining and analysing log data for operational monitoring is a secondary purpose that goes beyond the contract's direct performance.

**DPO recommendation:** Do not use this basis for log retention. Reserve it for the core transfer processing.

### 4.3 Option C: Legal Obligation (Article 6(1)(c))

**Purpose:** Processing required to comply with a legal obligation.

**Assessment:** There is no specific UK or EU law that requires SGraph to retain CloudFront log data. PECR and the UK Data Protection Act do not mandate retention of operational logs for a file transfer service.

**However:** If operating in a regulated sector or if law enforcement requests data, there may be future legal obligations. This is not a current basis but should be noted as a potential future basis that would override the defined retention periods.

**DPO recommendation:** Do not use this basis currently. If a legal obligation arises (e.g., law enforcement preservation request), document it as a specific exception.

### 4.4 Option D: Consent (Article 6(1)(a))

**Purpose:** Processing with the user's explicit consent.

**Assessment:** Technically possible but impractical and unnecessary for operational log data. Consent must be freely given, specific, informed, and unambiguous. Asking users to consent to operational log processing adds friction, creates withdrawal risk (if consent is withdrawn, we must stop processing their logs), and is disproportionate for data that has minimal personal data content.

**DPO recommendation:** Do not use consent for log retention. It is the wrong tool for this purpose.

### 4.5 DPO Recommendation

**Use Legitimate Interests (Option A)** as the lawful basis for SA pipeline log processing and retention. Produce a formal, standalone Legitimate Interests Assessment document that can be provided to the ICO or to data subjects who exercise their right to object.

**Decision required from human:** Confirm Legitimate Interests as the lawful basis, or instruct the DPO to document an alternative basis.

---

## 5. Deletion Triggers and Procedures

### 5.1 Automated Deletion

Wherever possible, deletion should be automated to prevent human error (forgetting to delete) and ensure consistency.

| Data Stage | Deletion Mechanism | Implementation |
|-----------|-------------------|----------------|
| **Raw logs (S3)** | S3 lifecycle policy | Configure a lifecycle rule on the live logging bucket: expire objects after 7 days. Objects are automatically deleted by S3. |
| **Typed JSON (cache)** | Cache service TTL or scheduled Lambda | Implement a TTL mechanism in the cache service that marks `raw/` entries as expired after 30 days. A scheduled Lambda deletes expired entries. |
| **Consolidated (cache)** | Cache service TTL or scheduled Lambda | Same mechanism, 90-day TTL for `consolidated/` entries. |
| **Temporal aggregations** | Cache service TTL (hourly/daily) or none (monthly) | 30-minute entries: 30-day TTL. Hourly: 90-day TTL. Daily: 1-year TTL. Monthly: no automatic deletion. |
| **Archived raw logs (Glacier)** | S3 lifecycle policy | Configure a lifecycle rule on the archive bucket: expire Glacier objects after 365 days. |

### 5.2 Deletion Verification

Deletion must be verified, not assumed. The same principle as IP verification applies: the DPO requires evidence that deletion is occurring, not just that it is configured.

**Verification procedure:**

1. **Monthly audit:** Count objects in each S3 bucket and cache service prefix that are older than their retention period. The count should be zero.
2. **Lifecycle policy verification:** Quarterly review of S3 lifecycle policies to confirm they have not been changed or removed.
3. **Cache service TTL verification:** Quarterly review of the cache service's TTL implementation to confirm it is functioning.
4. **Audit log:** Each deletion run should log: what was deleted, when, how many objects/entries, and whether it completed successfully.

### 5.3 Manual Deletion Triggers

In addition to automated deletion, the following events should trigger manual review of retained data:

| Trigger | Action | Owner |
|---------|--------|-------|
| **Data subject access request (DSAR)** | Determine if any retained log data relates to the data subject. If so, provide it. | DPO |
| **Data subject erasure request** | Determine if any retained log data relates to the data subject. If IP addresses are not captured, identification of a specific data subject's log entries is impractical -- document this as the response. | DPO |
| **Security incident** | Extend retention of relevant log data for the duration of the investigation. Notify the DPO. Override automated deletion for affected data. | AppSec/CISO + DPO |
| **Legal hold** | Preserve all data within scope of the hold. Override automated deletion. Notify the DPO. | Legal + DPO |
| **End of service** | Delete all log data within 30 days of service termination, unless a legal hold or other legal obligation requires retention. | DPO + DevOps |

### 5.4 The DSAR Problem

A data subject who requests access to their personal data under Article 15 presents a practical challenge: **how do we identify their data in our logs when we do not have their IP address?**

**Answer:** We cannot. And this is by design. The IP exclusion means we cannot link a specific request to a specific data subject. The IP hashing means we can confirm that a hash exists but cannot reverse it to identify the original IP.

**Procedure for DSARs:**

1. If the data subject provides their IP address, we can hash it with the relevant daily salt and search for matching `ip_hash` values in CloudWatch logs. If found, we can provide the associated log entries. However, CloudWatch log retention is 30 days, so older entries will have been deleted.
2. For CloudFront Real-Time Logs, we have no IP address at all. We cannot identify a specific data subject's requests. This is a feature of the privacy-by-design architecture, not a deficiency.
3. The response to a DSAR in this context: "We have designed our logging to minimise personal data collection. We do not retain IP addresses in our CloudFront logs. We retain IP hashes in our application logs for 30 days. If you provide your IP address, we can search for matching hashes within the 30-day retention window."

This is a strong data protection position. The ICO would view the inability to identify a data subject's log entries as evidence of effective data minimisation, not as a failure to comply with the access right.

---

## 6. Data Flow Map for the SA Pipeline

For the ROPA (Record of Processing Activities) and to satisfy Article 30 requirements, the SA pipeline needs a data flow map. Here is the DPO's view of the data flows with personal data annotations.

```
AWS Services (15 data sources)
    |
    |--- CloudFront Real-Time Logs [pseudonymising: user-agent, referrer]
    |       |
    |       v
    |    Firehose --> S3 Live Bucket (raw, 7-day retention)
    |       |
    |       v
    |    LETS Pipeline:
    |       Parse --> Typed JSON (cache, 30-day retention) [still per-request]
    |       Consolidate --> Grouped data (cache, 90-day retention) [grouped, lower risk]
    |       Aggregate --> Time buckets (cache, variable retention) [statistical, minimal risk]
    |       Archive --> Glacier (1-year retention) [same risk as raw]
    |
    |--- CloudWatch Logs [pseudonymised: ip_hash]
    |       |
    |       v
    |    CloudWatch Log Group (30-day retention, configured in v0.3.6)
    |       |
    |       v
    |    [Future: LETS Pipeline for CloudWatch]
    |
    |--- All other sources [NO personal data]
            |
            v
         Various S3 buckets and CloudWatch metrics (no DPO concern)
```

### 6.1 DPO Observations on the Data Flow

1. **Personal data narrows through the pipeline.** Raw logs (Stage 1) have the most per-request detail. Consolidated data (Stage 2) groups requests. Aggregated data (Stage 3) is statistical. This is good data protection design -- each transformation reduces personal data risk.

2. **The Glacier archive is a copy of raw data with the same risk profile.** Archiving to Glacier does not transform the data -- it is the same raw log files in a different storage class. Retention and deletion must be treated identically to the live bucket, except for the longer retention period.

3. **Two independent personal data flows.** CloudFront logs (user-agent, referrer) and CloudWatch logs (ip_hash) are independent data flows. They are not combined in the current design. Combining them (e.g., correlating CloudFront request timing with CloudWatch ip_hash timing) would increase identification risk and would require a DPO review before implementation.

4. **The digital twin (infrastructure state data) has no personal data.** Route 53, CloudFront, Lambda, S3, and Firehose configurations do not contain user personal data. The digital twin is purely infrastructure metadata.

---

## 7. Updated Action Tracker

### 7.1 Actions Closed by This Review

| # | Action | Resolution |
|---|--------|------------|
| -- | Review log retention considerations for SA pipeline | **CLOSED.** This review document defines retention periods, lawful basis, and deletion procedures. Decisions remain with the human. |

### 7.2 Actions Updated

| # | Action | Previous Status | Updated Status | Notes |
|---|--------|----------------|----------------|-------|
| 5 | Review server-side analytics data map | OPEN, P1 | **PARTIALLY CLOSED** | Data flow map provided in Section 6. Full ROPA entry still needed when pipeline is operational. |
| 7 | Document lawful basis for server-side analytics (LIA) | OPEN, P1 | **PARTIALLY CLOSED** | LIA outline provided in Section 4.1. Formal standalone LIA document still needed. |

### 7.3 New Actions

| # | Action | Priority | Owner | Rationale |
|---|--------|----------|-------|-----------|
| N10 | **Produce formal standalone LIA document** for SA pipeline log processing | P1 | DPO | Required for Article 6(1)(f) compliance. Outline provided here; formal document needed. |
| N11 | **Implement S3 lifecycle policies** for retention automation | P1 | DevOps | 7-day live bucket, 1-year archive bucket. Must be in place before pipeline goes live. |
| N12 | **Implement cache service TTL mechanism** for retention automation | P2 | Dev | 30-day raw, 90-day consolidated, variable aggregation retention. |
| N13 | **Implement deletion verification audit** (monthly object count check) | P2 | DevOps/QA | Verification that deletion is occurring, not just configured. |
| N14 | **DPO review before CloudFront + CloudWatch data correlation** | P3 | DPO | If the pipeline ever combines these two data flows, increased identification risk requires DPO review. |
| N15 | **DPO review before WAF activation** | P2 | DPO/DevOps | WAF sampled requests show full headers including IP for 3 hours. DPO must review before WAF is enabled. |

### 7.4 Consolidated Full Action List (as of 16 Feb)

| # | Action | Priority | Owner | Status |
|---|--------|----------|-------|--------|
| 2 | Draft privacy policy | P1 | DPO/Journalist | OPEN |
| 3 | Document lawful basis for IP hash storage (LIA) | P1 | DPO | OPEN -- subsumable into N10 |
| 4 | Review LaunchList DPA terms | P1 | DPO | OPEN |
| N5 | Ensure transfer manifest excludes plaintext file names | P1 | DPO/Architect | OPEN |
| 6b | Review Villager production CloudFront config | P1 | DPO/DevOps | OPEN |
| 8 | Approve privacy policy before publication | P1 | DPO/Journalist | BLOCKED by #2 |
| N1 | DPO review of Villager production data handling | P1 | DPO/DevOps | OPEN |
| N10 | Produce formal standalone LIA for SA pipeline | P1 | DPO | NEW |
| N11 | Implement S3 lifecycle policies for retention | P1 | DevOps | NEW |
| 5 | Review server-side analytics data map (ROPA) | P1 | DPO/Architect | PARTIALLY CLOSED |
| 7 | Document lawful basis for server-side analytics | P1 | DPO | PARTIALLY CLOSED |
| 9 | Update data processor register | P2 | DPO | OPEN |
| 10 | Review transparency panel disclosures | P2 | DPO/Dev | OPEN |
| 11 | Review event data exposure in UI | P2 | DPO | OPEN |
| N2 | Review unencrypted mode DPIA if feature progresses | P2 | DPO/AppSec | OPEN |
| N3 | Ensure design agency materials are free of personal data | P2 | DPO/Designer | OPEN |
| N6 | Review feedback collection privacy compliance | P2 | DPO/Advocate | OPEN |
| N7 | Extend zero-storage mode to IndexedDB/OPFS | P2 | DPO/Dev | OPEN |
| N8 | Governance: no CloudFront IP fields without DPO review | P2 | DPO/DevOps | OPEN |
| N12 | Implement cache service TTL for retention | P2 | Dev | NEW |
| N13 | Implement deletion verification audit | P2 | DevOps/QA | NEW |
| N15 | DPO review before WAF activation | P2 | DPO/DevOps | NEW |
| N4 | Monitor MCP endpoint for personal data scope | P3 | DPO | OPEN |
| N9 | Review STUN/TURN data processing if WebRTC implemented | P3 | DPO/Architect | OPEN |
| N14 | DPO review before CF + CW data correlation | P3 | DPO | NEW |

**Open action count:** 24 (11 P1, 11 P2, 3 P3).

---

## 8. Summary

The SA pipeline's log retention and archival design has been reviewed from a data protection perspective. Key findings:

1. **Only 2 of 15 data sources contain personal data.** This is a direct result of previous DPO involvement in the observability design. The majority of the pipeline handles non-personal operational data.

2. **Retention periods are defined.** Raw data (7 days), typed JSON (30 days), consolidated (90 days), archived raw (1 year), temporal aggregations (30 days to indefinite, decreasing granularity). These balance operational need against the storage limitation principle.

3. **Legitimate Interests is the recommended lawful basis.** The processing is proportionate, expected by data subjects, and the most sensitive data (IP addresses) has already been excluded or hashed.

4. **Automated deletion is mandatory.** S3 lifecycle policies and cache service TTLs must be implemented. Manual deletion is unreliable and creates compliance risk.

5. **The DSAR position is strong.** The inability to identify a specific data subject's CloudFront log entries is evidence of effective data minimisation, not a compliance failure.

6. **Two risks to monitor:** (a) WAF activation would introduce IP addresses into the pipeline and requires DPO review, (b) correlating CloudFront and CloudWatch data flows would increase identification risk and requires DPO review.

**Decisions for the human:**
1. Confirm Legitimate Interests as the lawful basis for SA pipeline processing.
2. Confirm or adjust the recommended retention periods.
3. Confirm whether S3 lifecycle policies or scheduled Lambdas should implement automated deletion.

---

*This review completes the DPO's v0.4.4 assessment of the SA pipeline's data protection posture. The pipeline design is privacy-aware by default -- a direct outcome of embedding the DPO in the team from the start. The open items are procedural (documenting the LIA, implementing retention automation, verifying deletion) rather than architectural. No fundamental redesign is needed.*
