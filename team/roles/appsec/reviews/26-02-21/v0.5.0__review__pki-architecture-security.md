# AppSec Review: PKI Architecture Security -- Key Discovery, Chain of Trust, and Secure Pod

**Version:** v0.5.0
**Date:** 21 February 2026
**Role:** AppSec (Application Security)
**Team:** Explorer
**Classification:** Internal -- Security Sensitive
**Threat model baseline:** [v0.2.15 threat model](../26-02-12/v0.2.15__threat-model__sgraph-send.md)
**Previous AppSec review:** [v0.3.2 action plan](../26-02-14/v0.3.2__action-plan__explorer-next-steps.md)
**Service Worker research:** [v0.4.20 trust anchor](../../../../humans/dinis_cruz/briefs/02/20/v0.4.20__appsec-research__service-worker-trust-anchor.md)

**Briefs reviewed:**
1. [v0.4.27 Key Discovery and Public Registry](../../../../humans/dinis_cruz/briefs/02/21/v0.4.27__dev-brief__key-discovery-and-public-registry.md)
2. [v0.4.27 Chain of Trust and Key Graphs](../../../../humans/dinis_cruz/briefs/02/21/v0.4.27__architecture__chain-of-trust-and-key-graphs.md)
3. [v0.4.27 Secure Pod -- Multi-User Revocable Encryption](../../../../humans/dinis_cruz/briefs/02/21/v0.4.27__architecture__secure-pod-multi-user-encryption.md)

---

## Executive Summary

Three briefs collectively define SG/Send's PKI architecture: a public key registry with short-code discovery (immediate build), a hash-chained trust graph with layered identity and key rotation (design phase), and a secure pod for multi-user revocable encryption (future research). Together they transform SG/Send from a symmetric-key file transfer tool into a full PKI platform.

This review identifies **4 Critical**, **7 High**, **9 Medium**, and **5 Low** risk findings across the three briefs. The most important findings are:

1. **POST /api/keys has no authentication** -- anyone can publish any key, enabling key squatting and impersonation (Critical)
2. **Equivocation attack on the hash chain** -- a single-server architecture cannot prevent the server from showing different chains to different clients (Critical)
3. **Group admin compromise propagates trust to all members** -- one compromised admin key poisons the entire trust group (Critical)
4. **Pod compromise with server access is total compromise** -- the brief acknowledges this correctly, but the blast radius of a combined pod+server breach is the entire content store (Critical)

The key discovery API is the immediate build priority and has the most actionable findings. The chain-of-trust and secure pod findings are architectural guidance for design-phase decisions.

---

## Part 1: Key Discovery and Public Registry

### 1.1 Threat Model

**Scope:** 4 new API endpoints (`POST /api/keys`, `GET /api/keys/{code}`, `DELETE /api/keys/{code}`, `GET /api/keys`), the key lookup page, the key registry page, and the certificate transparency log.

**Assets at risk:**
- Public keys (public data, but the association between a code and a key is metadata)
- The lookup code namespace (finite, enumerable)
- The transparency log integrity (append-only property)
- The registry as a whole (denial of service via flooding)

**Threat actors:**
- Anonymous attacker (no authentication on most endpoints)
- Malicious key publisher (squatting, impersonation)
- Server operator (equivocation, selective serving)

### 1.2 Findings

#### KD-1: POST /api/keys Has No Authentication (CRITICAL)

**Risk:** Critical
**Category:** Authentication

The brief specifies `POST /api/keys` as the endpoint to publish a public key. No authentication is mentioned. If this endpoint is unauthenticated:

1. **Key squatting:** An attacker publishes thousands of keys, exhausting the lookup code namespace.
2. **Key impersonation:** An attacker publishes a key for a lookup code that a legitimate user might later want. The code is already taken.
3. **Registry pollution:** An attacker floods the registry with garbage keys, making the registry page unusable.
4. **Resource exhaustion:** Each published key consumes server storage and a transparency log entry.

**Recommendation:**
- `POST /api/keys` MUST require authentication. At minimum, require the admin API key. For multi-user deployments, require an authenticated session (OAuth/Cognito).
- Rate limit key publication: maximum N keys per authenticated identity per hour.
- Consider requiring proof-of-possession: the client must sign a challenge with the private key corresponding to the public key being published. This proves the publisher actually holds the private key, preventing publication of arbitrary keys.

#### KD-2: DELETE /api/keys/{code} Authentication Not Specified (HIGH)

**Risk:** High
**Category:** Authentication

The brief mentions `DELETE /api/keys/{code}` "requires authentication" but does not specify what authentication. Questions:

1. Who can delete a key? Only the publisher? Any admin? Anyone with the API key?
2. How does the server verify the requester is the key's owner? The server does not know who published a key (no identity binding in the current model).
3. If deletion is admin-only, what happens in a multi-user deployment where users publish their own keys?

**Recommendation:**
- Require proof-of-possession for deletion: the client must sign a server-issued challenge with the private key corresponding to the published public key. This proves ownership without storing identity on the server.
- Alternatively, issue a deletion token at publication time (returned alongside the lookup code). Store the hash of the deletion token. To delete, present the token.
- Admin override: allow admin API key to delete any key (for abuse cases).

#### KD-3: Lookup Code Enumeration (MEDIUM)

**Risk:** Medium
**Category:** Information Disclosure

The brief recommends 6-8 alphanumeric character lookup codes. The keyspace:

| Length | Characters | Keyspace | Time to enumerate at 100 req/s |
|--------|-----------|----------|-------------------------------|
| 6 | 36 (a-z, 0-9) | 2.18 billion | 252 days |
| 6 | 62 (a-z, A-Z, 0-9) | 56.8 billion | 18 years |
| 8 | 36 | 2.82 trillion | 895 years |
| 8 | 62 | 218 trillion | 69,000 years |

With rate limiting, brute-force enumeration of the full keyspace is infeasible for 8-character codes. However, the real risk is not full enumeration but **targeted discovery**: an attacker probing specific codes to find published keys.

**The metadata risk:** Public keys are public data. But discovering that a specific lookup code resolves to a specific key fingerprint reveals that someone published a key on this server. For private deployments (investor data rooms), the mere existence of published keys is sensitive metadata -- it reveals who is using the platform.

**Recommendation:**
- Use 8 characters minimum with mixed case (62-character alphabet). This gives 218 trillion combinations.
- Rate limit `GET /api/keys/{code}` to 10 requests per minute per source IP.
- Return identical response timing for found/not-found cases (constant-time response to prevent timing side-channels).
- Consider: for private deployments, `GET /api/keys/{code}` could require the admin API key, making the lookup code a second factor rather than the sole access mechanism.

#### KD-4: GET /api/keys Registry Enumeration (MEDIUM)

**Risk:** Medium
**Category:** Information Disclosure

`GET /api/keys` returns all published keys. This is the registry page data source.

**Concern:** On private deployments, listing all published keys reveals the full set of users/entities using the platform. This is a membership oracle.

**Recommendation:**
- `GET /api/keys` (list all) MUST require authentication (admin API key at minimum).
- For private deployments, consider removing the list endpoint entirely and requiring lookup by code only.
- If the registry page is needed, authenticate it separately from the individual lookup.

#### KD-5: Rate Limiting Requirements (HIGH)

**Risk:** High
**Category:** Availability / Denial of Service

No rate limiting is specified for any of the 4 endpoints. Without rate limiting:

- `POST /api/keys`: Registry flooding (KD-1 amplified)
- `GET /api/keys/{code}`: Enumeration attacks (KD-3)
- `GET /api/keys`: Repeated full-registry pulls (bandwidth DoS)
- `DELETE /api/keys/{code}`: Mass deletion if auth is weak

**Recommendation:**

| Endpoint | Rate Limit | Scope |
|----------|-----------|-------|
| `POST /api/keys` | 5/hour | Per authenticated identity |
| `GET /api/keys/{code}` | 30/minute | Per source IP |
| `GET /api/keys` | 5/minute | Per source IP |
| `DELETE /api/keys/{code}` | 10/hour | Per authenticated identity |

These are starting points. Adjust based on observed usage patterns after deployment.

#### KD-6: CORS and Origin Restrictions (MEDIUM)

**Risk:** Medium
**Category:** Access Control

The key discovery endpoints are on the admin panel (`/admin/`). The brief does not specify CORS policy for the API endpoints.

**Concern:** If `POST /api/keys` accepts cross-origin requests, an attacker could trick authenticated users into publishing keys or deleting keys via CSRF.

**Recommendation:**
- All `/api/keys` endpoints must return `Access-Control-Allow-Origin` restricted to the deployment's own origin.
- `POST` and `DELETE` endpoints must validate the `Origin` header server-side.
- Consider requiring a CSRF token for state-changing operations (POST, DELETE), especially if cookie-based auth is used in future.
- If these endpoints are admin-only (API key auth via header), CORS is less critical -- API keys in headers are not sent automatically by browsers. But defence in depth still warrants origin restrictions.

#### KD-7: Transparency Log as Security Control (MEDIUM)

**Risk:** Medium (if relied upon without client-side verification)
**Category:** Integrity

The brief describes a certificate transparency log with hash-chained entries. This is an excellent security control **if clients verify it**. Without client-side verification, the log is just an audit trail that the server can unilaterally modify.

**Concerns:**
1. The log is maintained by the server. A compromised server can rewrite the entire log.
2. The "hash of all entries" shown in the UI is computed by the server. Clients cannot verify it without replaying the entire log.
3. The brief does not describe how clients detect log tampering.

**Recommendation:**
- **Phase 1 (immediate build):** Implement the transparency log as an append-only audit trail. This provides value against accidental corruption and insider audit.
- **Phase 2 (chain-of-trust integration):** Implement client-side log verification. The client downloads the full log (or a Merkle proof), independently computes the hash chain, and verifies the server's claimed head hash. This is how Certificate Transparency works -- the monitor role is essential.
- **Phase 3:** Publish the log head hash to an external witness (a separate server, a blockchain, a gossip protocol) so clients can detect equivocation (server showing different logs to different clients).
- Document clearly in the UI: "This log is server-maintained. For full tamper detection, verify the hash chain independently."

#### KD-8: Friendly Token Stored as Hash vs Plaintext (LOW)

**Risk:** Low
**Category:** Metadata Protection

The brief discusses three approaches for the lookup code: hashed name, Obj_Id, or hybrid (short opaque code). The hybrid approach stores the short code directly on the server.

**Analysis:** The hybrid approach is sound. The short code (`DC-7X4F`) is not a meaningful name -- it is an opaque token. Storing it directly is acceptable because:
- It reveals nothing about the user's identity or purpose.
- It is functionally equivalent to an Obj_Id, just shorter and more human-friendly.
- Hashing a 6-8 character code provides no security benefit -- the keyspace is small enough to rainbow table.

**Recommendation:** Proceed with the hybrid approach. The short code is metadata, but it is opaque metadata. No additional protection needed beyond the existing "no plaintext strings" policy.

### 1.3 Key Discovery -- Risk Summary

| ID | Finding | Risk | Status |
|----|---------|------|--------|
| KD-1 | POST /api/keys has no authentication | Critical | MUST FIX before build |
| KD-2 | DELETE authentication not specified | High | MUST FIX before build |
| KD-3 | Lookup code enumeration | Medium | SHOULD FIX (rate limiting) |
| KD-4 | Registry list exposes membership | Medium | SHOULD FIX (auth on list) |
| KD-5 | No rate limiting on any endpoint | High | MUST FIX before deployment |
| KD-6 | CORS/origin restrictions not specified | Medium | SHOULD FIX |
| KD-7 | Transparency log not client-verifiable | Medium | Phased approach acceptable |
| KD-8 | Hybrid lookup code approach | Low | Acceptable as designed |

---

## Part 2: Chain of Trust and Key Graphs

### 2.1 Threat Model

**Scope:** Trust graph data model, git-style hash chaining, challenge-response authentication, key rotation with identity binding, layered key identity (4 layers), PKI-encrypted web delivery.

**Assets at risk:**
- The trust graph integrity (who trusts whom)
- Key-to-identity bindings (which keys belong to which identities)
- The hash chain (tamper-evident history)
- Identity provider trust (OAuth/Cognito as anchor)
- Private keys in browsers (IndexedDB, non-extractable)

**Threat actors:**
- Compromised group admin (insider threat)
- Compromised server (equivocation, graph manipulation)
- Compromised identity provider (OAuth/Cognito breach)
- Man-in-the-middle (challenge-response interception)
- Revoked user (attempting continued access)

### 2.2 Findings

#### CT-1: Equivocation Attack on the Hash Chain (CRITICAL)

**Risk:** Critical
**Category:** Integrity

The brief describes git-style hash chaining for tamper evidence and mentions "fork detection" where clients comparing chains detect equivocation. This is the correct theoretical approach but has a fundamental implementation challenge: **how do clients compare chains?**

In a single-server architecture, the server controls what each client sees. The server can:

1. Maintain two parallel chains -- one "clean" chain for honest clients, one "modified" chain that includes an attacker's key.
2. Serve the modified chain only to the target victim.
3. The victim cannot detect this because they have no way to compare their view with other clients' views.

This is the **equivocation attack** -- the core unsolved problem in single-server transparency logs. Google's Key Transparency, CONIKS, and Certificate Transparency all address this with **gossip protocols** or **external witnesses**.

**Analysis:** The brief correctly identifies this as a research task (AppSec review item, D2 priority). The architecture as described is vulnerable to equivocation by a compromised or malicious server.

**Recommendation:**
- **Phase 1 (acceptable for initial deployment):** Implement the hash chain as described. A honest server with hash chaining provides tamper evidence against accidental corruption, partial compromise, and after-the-fact forensics. This is a significant improvement over no chaining.
- **Phase 2 (required for high-security deployments):** Implement one or more of:
  - **Signed Tree Heads (STH):** The server periodically publishes the chain head hash to an external service (separate domain, different infrastructure). Clients fetch and compare.
  - **Client gossip:** Clients exchange chain head hashes out of band (or via a separate gossip endpoint). Divergent heads indicate equivocation.
  - **Third-party auditor:** An external service periodically fetches the full chain and publishes its computed head hash. Clients verify against the auditor.
- **Document the limitation clearly:** Users should know that hash chaining provides tamper evidence but not equivocation resistance without external witnesses.

#### CT-2: Group Admin Compromise Propagates Trust (CRITICAL)

**Risk:** Critical
**Category:** Trust Propagation

The trust graph model allows a group admin to `ADD_MEMBER` any key to a trust group. The commit is signed by the admin's private key. If an admin's key is compromised, the attacker can:

1. Add their own key to the trust group.
2. The commit is validly signed (the attacker has the admin key).
3. All clients querying the trust group now receive the attacker's key as a trusted member.
4. Anyone encrypting for "all members of Company-X" now encrypts for the attacker.

**Blast radius:** One compromised admin key compromises the trust of every user in every group that admin manages.

**Analysis:** This is inherent to any trust delegation model (PGP web of trust, X.509 intermediate CAs, corporate directory services). The brief's architecture is not uniquely vulnerable -- it has the same trust propagation properties as every similar system. The question is what mitigations are available.

**Recommendation:**
- **Multi-admin approval:** For `ADD_MEMBER` operations, require signatures from K-of-N group admins (threshold signing). A single compromised admin cannot unilaterally add members.
- **Member addition notification:** When a new member is added to a group, all existing members receive a notification (via the transparency log or a push mechanism). Members can flag unexpected additions.
- **Admin key ceremony:** Admin keys should be generated and stored with higher ceremony than regular user keys. Consider requiring admin keys to be non-exportable WebCrypto keys stored in a separate browser profile, or backed by hardware (WebAuthn/FIDO2).
- **Time-delayed addition:** New member additions could have a grace period (e.g., 24 hours) during which existing members can object before the trust relationship becomes active.
- **Scope limitation:** An admin's authority should be scoped to specific groups. Compromise of Company-X's admin does not affect Company-Y's trust graph.

#### CT-3: Challenge-Response Replay Attacks and Nonce Management (HIGH)

**Risk:** High
**Category:** Authentication

The brief describes challenge-response authentication:
```
Server -> Client: { challenge: "random-nonce-abc123", request: "identify-persona" }
Client -> Server: { challenge: "random-nonce-abc123", response: sign(challenge, private_key) }
```

This is a well-understood pattern (SSH, WebAuthn). The security depends entirely on nonce management.

**Attack scenarios:**
1. **Replay attack:** If the server reuses nonces or accepts stale nonces, an attacker who intercepts one challenge-response can replay it.
2. **Pre-play attack:** If the nonce is predictable, an attacker pre-computes responses for future challenges.
3. **Cross-context replay:** If the same nonce format is used across different operations (identify-persona, admin-action), a challenge-response for one context might be valid for another.

**Recommendation:**
- **Nonce requirements:**
  - Cryptographically random: minimum 128 bits (16 bytes), generated via `secrets.token_hex(16)` or equivalent.
  - Single-use: the server must store issued nonces and reject any nonce that has been used.
  - Time-bounded: nonces expire after a short window (60 seconds recommended, 300 seconds maximum).
  - Context-bound: the signed payload must include the operation type (e.g., `sign("identify-persona:" + nonce + ":" + timestamp, key)`), not just the nonce. This prevents cross-context replay.
- **Server-side nonce storage:**
  - Store issued nonces in a set with TTL.
  - On verification: check nonce exists, has not expired, has not been used, then mark as used.
  - Clean up expired nonces periodically.
- **Channel binding:** Consider binding the challenge to the TLS session (channel binding) to prevent MitM interception of challenges. WebAuthn does this; the brief's protocol should consider it.

#### CT-4: Identity Binding Security -- OAuth/Cognito as Trust Anchor (HIGH)

**Risk:** High
**Category:** Identity / Trust

The brief establishes OAuth/Cognito as the persistent identity anchor for key rotation:

> "The identity (OAuth, Cognito, email address) is the persistent anchor. Keys are ephemeral. Identity endures."

This means the security of the entire key rotation mechanism depends on the security of the identity provider. If the IdP is compromised:

1. An attacker authenticates as any user.
2. The attacker generates a new key pair.
3. The attacker publishes the new key, triggering `ROTATE_KEY`.
4. The server attests the rotation (it sees a valid OAuth token).
5. All contacts receive the attacker's key as the user's "new" key.
6. The real user's key is effectively revoked.

**Analysis:** This is the identity provider compromise scenario. It is not unique to this architecture -- any system that uses OAuth for key binding has this property. The question is what detection and recovery mechanisms exist.

**Recommendation:**
- **Key rotation notification:** When a key rotation occurs (especially server-attested via identity provider), notify all contacts who hold the old key. The notification should include both fingerprints and the attestation source. This gives users a chance to verify out-of-band.
- **Rotation cooldown:** After a key rotation, impose a cooldown period before the new key is fully trusted. During cooldown, senders see a warning: "This user's key was recently rotated. Verify the new fingerprint before sending sensitive content."
- **Multi-factor key binding:** For high-security contexts, require more than OAuth for key rotation. For example: OAuth + challenge-response from the old key (if available) + out-of-band confirmation.
- **IdP compromise detection:** Monitor for anomalous rotation patterns (e.g., a user who has never rotated suddenly rotates, or multiple users rotate simultaneously). These are indicators of IdP compromise.
- **Recovery path:** Document the recovery procedure for IdP compromise. Users must be able to re-establish trust without relying on the compromised IdP.

#### CT-5: Layered Key Model -- Over-Engineering Risk (LOW)

**Risk:** Low (architectural, not a vulnerability)
**Category:** Design

The brief defines 4 key layers: API Key, Device/Session Key, Persona Key, Admin Key. Each can be challenged independently. Composable authentication requires multiple layers for sensitive operations.

**Analysis:** This is a sound design, well-precedented (SSH has host keys + user keys + agent keys; TLS has server cert + client cert; WebAuthn has device key + user key). Four layers is not over-engineered -- each serves a distinct purpose:

| Layer | Distinct Purpose | Alternative Without It |
|-------|-----------------|----------------------|
| API Key | Platform access gate | Open access -- anyone can call API |
| Device/Session Key | Binds to specific browser instance | No device binding -- stolen API key works anywhere |
| Persona Key | User identity + confidentiality | No user-level crypto -- server must trust identity claims |
| Admin Key | Elevated privilege separation | Admin ops rely on API key alone |

**Concern:** Complexity in implementation. Each layer adds authentication state, key management, and failure modes. The risk is not over-engineering in design but under-engineering in implementation -- shipping 4 layers that are individually weak is worse than 2 layers that are robust.

**Recommendation:**
- **Prioritise Persona Key and API Key for initial implementation.** These provide the most value (identity and access control).
- **Add Device/Session Key when multi-device is implemented.** Until then, it adds complexity without value.
- **Add Admin Key when admin operations require elevated privilege.** Currently, the API key serves this role.
- **Each layer should be independently testable** -- unit tests that verify each challenge-response in isolation.

#### CT-6: Trust Graph Revocation Timing (MEDIUM)

**Risk:** Medium
**Category:** Revocation

The brief describes "natural revocation through graph maintenance" -- removing an edge from the trust graph is revocation. Clients check the trust graph before encrypting.

**Concern:** Revocation depends on the client querying the server. If a client caches trust graph state locally (for offline use or performance), the cache may contain stale trust data. A revoked user's key remains trusted in the cache until it refreshes.

**Attack scenario:**
1. Eve is revoked from Company-X at time T.
2. Alice's client cached Company-X's trust graph at T-1 hour.
3. Alice encrypts a message for Company-X members at T+5 minutes (using cached graph).
4. Eve receives the encrypted message because Alice's cache has not yet refreshed.

**Recommendation:**
- **Maximum cache TTL for trust graph queries:** Recommend 5 minutes for active sessions, 0 (no cache) for high-security contexts.
- **Push-based revocation notification:** When a member is revoked, the server should notify active clients (via WebSocket or polling) to invalidate their trust graph cache.
- **Cache invalidation on encrypt:** Before encrypting for a group, the client should always re-query the trust graph if the cache is older than the configured TTL.
- **Document the revocation latency:** Users should understand that revocation is not instant from the perspective of all senders.

#### CT-7: PKI-Encrypted Web Delivery -- Code Integrity Bootstrap (HIGH)

**Risk:** High
**Category:** Integrity

The brief describes encrypting HTML/JS/CSS per-user via their public key, with the Service Worker decrypting before rendering. This is a powerful capability, but it has a critical dependency: **the Service Worker itself must be delivered securely on first visit.**

The Service Worker is the trust root for all subsequent encrypted page delivery. If an attacker compromises the initial Service Worker delivery (via TLS interception, compromised CDN, or DNS hijack on first visit), they can install a malicious Service Worker that:

1. Accepts attacker-controlled signing keys as trusted.
2. Exfiltrates decrypted page content.
3. Silently proxies all user interactions to the attacker.

This is the **TOFU (Trust On First Use) problem**, acknowledged in the Service Worker trust anchor brief (v0.4.20).

**Recommendation:**
- This risk is inherent to any web-delivered code. The Service Worker trust anchor architecture (v0.4.20) addresses it as well as possible within the browser security model.
- **For high-security deployments:** Consider distributing the Service Worker hash out-of-band (e.g., on a business card, in a signed email, via a separate domain) so users can verify the initial installation.
- **Code pinning after first use:** Once the Service Worker is installed, it should pin its own hash and reject any update that does not match a signed update manifest. This is described in v0.4.20 and should be cross-referenced here.
- **Separate this from the immediate key discovery build.** PKI-encrypted web delivery is a Phase 3 capability. Do not let it block the immediate priority.

#### CT-8: Hash Chain Signing -- Key Continuity vs Authority (MEDIUM)

**Risk:** Medium
**Category:** Integrity / Non-Repudiation

The brief specifies three signing authorities for commits:
- Group admin signs `ADD_MEMBER` / `REVOKE_MEMBER`
- Server signs its own key rotation (old key signs new)
- Identity provider attestation signs user key rotation

**Concern:** Mixing signing authorities in the same chain creates complexity in verification. A verifier must know which signing key is authoritative for which commit type. If this mapping is not strictly enforced:

1. A server could sign an `ADD_MEMBER` commit (bypassing admin authorisation).
2. An admin could sign a `ROTATE_KEY` commit for a user (bypassing identity verification).

**Recommendation:**
- **Strictly define which key types may sign which commit types.** Enforce this in the verification logic, not just by convention.
- Proposed enforcement matrix:

| Commit Type | Authorised Signer | Reject If Signed By |
|-------------|-------------------|---------------------|
| `CREATE_GROUP` | Server key | Admin key, user key |
| `ADD_MEMBER` | Group admin key | Server key (unless admin-delegated), user key |
| `REVOKE_MEMBER` | Group admin key | Server key (unless emergency), user key |
| `ROTATE_KEY` (user) | IdP attestation + server co-signature | Admin key alone |
| `ROTATE_KEY` (server) | Old server key | Admin key, user key |

- **Co-signatures for critical operations:** `ROTATE_KEY` for a user should require both IdP attestation AND server co-signature. This prevents a compromised IdP alone from executing a key rotation -- the server must also agree.

### 2.3 Chain of Trust -- Risk Summary

| ID | Finding | Risk | Status |
|----|---------|------|--------|
| CT-1 | Equivocation attack on hash chain | Critical | Architectural -- phased mitigation |
| CT-2 | Group admin compromise propagates trust | Critical | Architectural -- threshold signing recommended |
| CT-3 | Challenge-response replay / nonce management | High | MUST ADDRESS in protocol design |
| CT-4 | OAuth/Cognito compromise enables key takeover | High | MUST ADDRESS -- rotation notification + cooldown |
| CT-5 | 4-layer key model complexity | Low | Acceptable -- implement incrementally |
| CT-6 | Trust graph revocation cache staleness | Medium | SHOULD ADDRESS -- TTL + push notification |
| CT-7 | PKI-encrypted web delivery TOFU bootstrap | High | Acknowledged -- addressed by v0.4.20 |
| CT-8 | Hash chain signing authority confusion | Medium | SHOULD ADDRESS -- enforcement matrix |

---

## Part 3: Secure Pod

### 3.1 Threat Model

**Scope:** The secure pod as an intermediary decryption/re-encryption enclave for multi-user revocable access to encrypted content.

**Assets at risk:**
- The pod's private key (decrypts all stored content)
- Plaintext content (momentarily visible inside the pod during re-encryption)
- The access log (definitive record of who saw what)
- The trust graph authorisation decisions (pod relies on server for these)

**Threat actors:**
- External attacker (targeting pod for key extraction)
- Compromised server operator (manipulating authorisation decisions)
- Compromised pod operator (extracting the pod key)
- Revoked user (attempting continued access)
- Insider with combined server + pod access

### 3.2 Findings

#### SP-1: Pod as Single Point of Failure (HIGH)

**Risk:** High
**Category:** Availability

The pod is required for every content access. If the pod is unavailable, no user can decrypt any content. The brief acknowledges this: "if the pod is down, no one can decrypt anything."

**Analysis:** This is simultaneously a security feature (no offline access without authorisation check) and an availability risk. For enterprise data rooms with regulatory deadlines, pod unavailability could have business-critical consequences.

**Scenarios:**
1. Pod hardware failure -- all access blocked until replacement.
2. Pod key rotation in progress -- access interrupted during re-encryption.
3. DDoS against pod -- all users denied access.
4. Pod maintenance window -- planned downtime = planned no-access.

**Recommendation:**
- **Pod redundancy:** Deploy multiple pod instances sharing the same key (or using a distributed key scheme like Shamir's Secret Sharing where K-of-N pod instances can reconstruct the key).
- **Pod health monitoring with automatic failover:** If the primary pod is unresponsive, traffic routes to a standby pod.
- **Degraded mode consideration:** For non-sensitive content categories, consider allowing cached access (previously-decrypted content served from local cache) during pod outages. This trades security for availability in a controlled way. Document the trade-off and let the deployment admin configure the policy.
- **SLA definition:** For enterprise customers, define pod availability SLAs. 99.9% availability (8.7 hours downtime/year) requires redundancy. 99.99% (52 minutes/year) requires active-active multi-pod.

#### SP-2: Pod Compromise Blast Radius -- Validating the Brief's Claims (HIGH)

**Risk:** High
**Category:** Confidentiality

The brief makes specific claims about blast radius. AppSec evaluation of each:

**Claim 1: "Server compromised alone = nothing exposed (all blobs encrypted with pod's key)"**
- **AppSec assessment: VALIDATED.** If the server stores only ciphertext encrypted with the pod's public key, and the pod's private key is not on the server, then a server-only compromise exposes only ciphertext. This is correct.
- **Caveat:** The trust graph and access log are on the server. A server compromise exposes the metadata of who is authorised for what and who accessed what. This is sensitive metadata even without content.

**Claim 2: "User's private key stolen = only documents that user actually opened"**
- **AppSec assessment: VALIDATED with caveat.** The user received per-request re-encrypted copies. Their private key decrypts only those copies, not the stored blobs. Correct.
- **Caveat:** The user also has the unique symmetric keys from each request. If the re-encrypted copies are stored anywhere (browser cache, disk, network log), the unique keys decrypt them. The blast radius is bounded by the user's access history, but the attacker may find cached copies beyond just the "current session."

**Claim 3: "Pod compromised alone = bounded by detection speed + download rate"**
- **AppSec assessment: PARTIALLY VALIDATED.** The reasoning is correct: pod key alone is insufficient without the ciphertext, which is on the server. The attacker must also obtain the ciphertext. However:
  - If the pod has network access to the server (which it must, to receive encrypted blobs for re-encryption), a compromised pod can fetch blobs from the server directly. The pod is an authorised client of the server's storage API.
  - The blast radius is then bounded by: how fast the compromised pod can fetch and decrypt blobs before detection.
  - The brief's claim holds **only if** the pod does not cache blobs and each blob must be individually requested from the server.
- **Recommendation:** The pod MUST NOT cache encrypted blobs. Each re-encryption request must involve a fresh fetch from the server. This ensures that pod compromise requires ongoing server interaction, which is detectable.

**Claim 4: "Server + pod compromised = total compromise"**
- **AppSec assessment: VALIDATED.** This is correct and unavoidable. If the attacker has both the ciphertext (server) and the decryption key (pod), everything is exposed. This is the fundamental limit of any encryption system -- the entity that holds the key and the ciphertext can read the plaintext.

#### SP-3: Micro-Payment Budget as Security Control (MEDIUM)

**Risk:** Medium (novel control, needs validation)
**Category:** Detection / Rate Limiting

The brief proposes that each pod has a micro-payment budget (daily/hourly/per-transaction). A compromised pod burning through its budget triggers a circuit breaker.

**AppSec assessment: This is a genuinely novel and interesting security control.** It creates an economic constraint on compromise severity that complements traditional rate limiting.

**Strengths:**
- Provides a hard upper bound on decryption throughput per time period.
- Budget exhaustion is a clear, unambiguous alarm signal (unlike heuristic-based anomaly detection).
- The budget can be tuned per-deployment based on expected usage patterns.
- Even an attacker who fully compromises the pod cannot bypass the budget without also compromising the budget enforcement mechanism.

**Weaknesses and concerns:**
1. **Where is the budget enforced?** If the budget is enforced by the pod itself, a compromised pod can disable its own budget. The budget enforcement must be external to the pod.
2. **Budget enforcement authority:** The budget should be enforced by the server (which controls whether to send blobs to the pod) or by a separate budget service. The pod requests a "budget token" for each operation; the budget service tracks spending.
3. **Budget calibration:** Setting the budget too high provides no protection. Setting it too low causes false alarms and legitimate access failures. The budget must be calibrated from baseline usage data.
4. **Burst vs sustained:** Normal usage may have bursts (e.g., a new team member onboarding and downloading 50 documents in an hour). The budget must accommodate legitimate bursts without triggering false alarms.
5. **Budget as availability attack:** An attacker who knows the budget limit could intentionally trigger budget exhaustion (e.g., by making many legitimate-looking requests via compromised user accounts), denying access to all users.

**Recommendation:**
- **External budget enforcement.** The budget MUST NOT be self-enforced by the pod. The server (or a separate service) must gate blob delivery to the pod based on the budget.
- **Layered budgets:** Implement per-user budgets AND per-pod budgets. A compromised user account should not be able to exhaust the entire pod budget.
- **Adaptive baseline:** After initial deployment, establish a usage baseline and set budget alerts at 2x and 5x the baseline. Hard circuit breaker at 10x.
- **Manual override:** An out-of-band mechanism for an admin to temporarily raise the budget (for legitimate high-volume scenarios like onboarding).
- **This is worth developing further.** The concept of cryptoeconomic rate limiting on compromise severity is sound and could be a differentiating security feature for the platform.

#### SP-4: Client-Side Pod Option (MEDIUM)

**Risk:** Medium
**Category:** Trust Model

The brief lists "client-side pod (sender's browser)" as an implementation option: the sender keeps the pod role and re-encrypts on access requests.

**Security implications:**
1. **The sender must remain online** for any recipient to access content. If the sender closes their browser, no one can access the content.
2. **The sender has full control** -- they can selectively deny access, modify content before re-encryption, or log access without the server's knowledge.
3. **No independent audit trail** -- the server cannot verify that the sender is honestly serving content.
4. **Sender compromise = pod compromise** -- the sender's browser is the pod. All client-side attacks (malware, extensions, physical access) are pod compromise attacks.
5. **No attestation** -- unlike a Nitro Enclave or HSM, there is no way to verify that the sender's browser is running expected code.

**Assessment:** The client-side pod fundamentally changes the trust model from "trust the pod infrastructure" to "trust the sender." This is appropriate for some use cases (personal sharing, where the sender IS the authority) but inappropriate for enterprise data rooms (where the sender should not be able to selectively deny access or tamper with content).

**Recommendation:**
- Label the client-side pod clearly as "Sender-Controlled Mode" and document the trust model difference.
- For enterprise deployments, mandate infrastructure-based pods (Nitro Enclave, separate AWS account, or HSM).
- For personal/casual use, the client-side pod is acceptable as a zero-infrastructure option.

#### SP-5: Pod Unavailability -- Availability vs Security Trade-Off (MEDIUM)

**Risk:** Medium
**Category:** Availability / Design

What happens when the pod is unavailable?

**Option A: Strict (security-first):** All access denied. Users wait for pod recovery. Zero risk of unauthorised access during outage.

**Option B: Degraded (availability-first):** Fall back to direct PKI mode (Mode 1). Content encrypted for individual user keys is served directly by the server. Revocation enforcement is suspended during fallback.

**Option C: Cached (hybrid):** Users who have previously accessed a document can view it from local cache. New access requests are denied until the pod recovers.

**AppSec assessment:**
- **Option A is the only secure option.** Options B and C both weaken the revocation guarantee that is the entire reason for the pod architecture.
- **Option B is dangerous.** If revocation enforcement is suspended during outages, an attacker can DoS the pod and then access revoked content during the fallback window.
- **Option C leaks information** about what users have previously accessed (their local cache reveals their access history to anyone with device access), but does not weaken revocation for new requests.

**Recommendation:**
- **Default to Option A (strict).** Pod-mediated content requires the pod. No pod = no access.
- **Allow Option C per-deployment** for deployments where availability is more important than revocation enforcement. The admin must explicitly enable this mode and accept the risk.
- **Never implement Option B.** It creates a trivial bypass for revocation (DDoS the pod, access content during fallback).

---

### 3.3 Secure Pod -- Risk Summary

| ID | Finding | Risk | Status |
|----|---------|------|--------|
| SP-1 | Pod as single point of failure | High | Architectural -- redundancy recommended |
| SP-2 | Pod compromise blast radius validation | High | Brief's claims validated with caveats |
| SP-3 | Micro-payment budget as security control | Medium | Novel and promising -- external enforcement required |
| SP-4 | Client-side pod trust model | Medium | Acceptable for personal use, not enterprise |
| SP-5 | Pod unavailability trade-off | Medium | Strict mode (deny access) is the only secure default |

---

## Cross-Cutting Concerns

### CC-1: Incremental Complexity Risk

The three briefs collectively introduce significant cryptographic infrastructure: a key registry, a hash-chained trust graph, layered authentication, challenge-response protocols, identity-anchored key rotation, and an encryption intermediary. Each component is individually sound, but the combined system has interaction effects that must be carefully tested.

**Recommendation:** Build and security-test each layer independently before composing them. Specifically:
1. Key discovery (immediate) -- security test the 4 endpoints in isolation.
2. Hash chain (next) -- security test chain verification, equivocation detection.
3. Challenge-response (next) -- security test nonce management, replay resistance.
4. Trust graph (next) -- security test trust propagation, revocation.
5. Pod (future) -- security test re-encryption, budget enforcement.

Do not attempt to integrate all layers simultaneously.

### CC-2: The Server-Sees-Nothing Principle Under Pressure

The existing SG/Send architecture has a clean "server sees nothing" property. The PKI architecture introduces cases where the server sees more:

| Component | What the Server Now Sees |
|-----------|-------------------------|
| Key registry | Public keys + lookup codes (public data, but association is metadata) |
| Trust graph | Who trusts whom, group membership, revocation history |
| Hash chain | Full history of all trust operations, signed by participants |
| Pod access log | Who accessed what, when, with what unique key |

None of this is plaintext content. The zero-knowledge claim for content remains intact. But the metadata surface area is significantly larger than the current system (which stores only encrypted blobs, transfer IDs, and hashed IPs).

**Recommendation:**
- Update the security claims on the website and documentation. The current claim is "the server stores only encrypted ciphertext." The future claim should be: "the server never sees plaintext content. The server stores public keys, trust graph relationships, and access logs -- but never file content."
- Consider encrypting the trust graph itself (graph topology encrypted with a group key), so the server stores only encrypted graph blobs. This adds complexity but preserves the "server sees nothing" property for the trust structure as well.

### CC-3: Cross-Reference to Previous Action Items

This review introduces new risk findings that interact with previously tracked items:

| New Finding | Related Previous Item | Interaction |
|-------------|----------------------|-------------|
| KD-5 (rate limiting) | v0.2.15 Vuln-4 (no rate limiting) | KD-5 is the same class of risk applied to new endpoints. The original rate limiting gap remains open. |
| CT-3 (nonce management) | v0.2.33 item 21 (constant-time token lookup) | Both relate to timing-based information leakage. Address together. |
| CT-7 (TOFU bootstrap) | v0.4.20 (Service Worker trust anchor) | CT-7 is explicitly addressed by the SW trust anchor architecture. |
| SP-2 (pod blast radius) | v0.2.15 Section 7.1 (malicious content distribution) | The pod introduces a new component whose compromise has platform-wide impact. Add to the existing threat scenarios. |

---

## Risk Register Update

### New Risks from v0.5.0

| Risk ID | Risk | Source | Rating | Owner |
|---------|------|--------|--------|-------|
| **RF-38** | Unauthenticated key publication enables registry flooding | KD-1 | Critical | AppSec, Dev |
| **RF-39** | Equivocation attack on single-server hash chain | CT-1 | Critical | AppSec, Architect |
| **RF-40** | Group admin compromise propagates to all members | CT-2 | Critical | AppSec, Architect |
| **RF-41** | Combined pod+server compromise = total content exposure | SP-2 | Critical | AppSec, Architect |
| **RF-42** | DELETE /api/keys authentication gap | KD-2 | High | AppSec, Dev |
| **RF-43** | No rate limiting on key discovery endpoints | KD-5 | High | AppSec, Dev |
| **RF-44** | Challenge-response nonce mismanagement | CT-3 | High | AppSec, Architect |
| **RF-45** | IdP compromise enables key takeover | CT-4 | High | AppSec, Architect |
| **RF-46** | PKI-encrypted web delivery TOFU dependency | CT-7 | High | AppSec, Architect |
| **RF-47** | Pod single point of failure | SP-1 | High | AppSec, Architect |
| **RF-48** | Pod blast radius -- pod caching blobs extends compromise | SP-2 | High | AppSec, Architect |
| **RF-49** | Lookup code enumeration on private deployments | KD-3 | Medium | AppSec, Dev |
| **RF-50** | Registry list endpoint as membership oracle | KD-4 | Medium | AppSec, Dev |
| **RF-51** | CORS/origin not restricted on key endpoints | KD-6 | Medium | AppSec, Dev |
| **RF-52** | Transparency log not client-verifiable | KD-7 | Medium | AppSec, Dev |
| **RF-53** | Trust graph revocation cache staleness | CT-6 | Medium | AppSec, Architect |
| **RF-54** | Hash chain signing authority not enforced | CT-8 | Medium | AppSec, Architect |
| **RF-55** | Micro-payment budget self-enforcement risk | SP-3 | Medium | AppSec, Architect |
| **RF-56** | Client-side pod trust model mismatch for enterprise | SP-4 | Medium | AppSec, Architect |
| **RF-57** | Pod unavailability degraded mode weakens revocation | SP-5 | Medium | AppSec, Architect |
| **RF-58** | 4-layer key model implementation complexity | CT-5 | Low | AppSec, Dev |
| **RF-59** | Hybrid lookup code metadata (opaque, acceptable) | KD-8 | Low | AppSec |
| **RF-60** | Incremental complexity across all three briefs | CC-1 | Low | AppSec, Architect |
| **RF-61** | Server metadata surface area expansion | CC-2 | Low | AppSec, Architect |
| **RF-62** | Interaction with previously open rate limiting gaps | CC-3 | Low | AppSec |

### Updated Risk Summary

| Priority | Previous (v0.3.2) | New (v0.5.0) | Total |
|----------|-------------------|--------------|-------|
| Critical | 0 | 4 | 4 |
| High | varies | 7 | 7+ |
| Medium | varies | 9 | 9+ |
| Low | varies | 5 | 5+ |
| **New findings this review** | | **25** | |

---

## Recommendations Summary

### Immediate (Key Discovery Build -- MUST DO)

| # | Recommendation | Finding | Priority |
|---|---------------|---------|----------|
| 1 | Authenticate `POST /api/keys` (require API key or OAuth) | KD-1 | P0 |
| 2 | Require proof-of-possession or deletion token for `DELETE /api/keys/{code}` | KD-2 | P0 |
| 3 | Implement rate limiting on all 4 key discovery endpoints | KD-5 | P0 |
| 4 | Authenticate `GET /api/keys` (list all) | KD-4 | P1 |
| 5 | Use 8-char mixed-case lookup codes (62-char alphabet) | KD-3 | P1 |
| 6 | Restrict CORS origins on `/api/keys` endpoints | KD-6 | P1 |
| 7 | Constant-time response for found/not-found lookups | KD-3 | P1 |

### Design Phase (Chain of Trust -- MUST ADDRESS)

| # | Recommendation | Finding | Priority |
|---|---------------|---------|----------|
| 8 | Design external witness mechanism for equivocation resistance | CT-1 | P1 |
| 9 | Design multi-admin threshold signing for `ADD_MEMBER` | CT-2 | P1 |
| 10 | Specify nonce requirements: 128-bit, single-use, time-bounded, context-bound | CT-3 | P0 |
| 11 | Implement key rotation notification + cooldown period | CT-4 | P1 |
| 12 | Define signing authority enforcement matrix for commit types | CT-8 | P1 |
| 13 | Set maximum trust graph cache TTL (5 min active, 0 for high-security) | CT-6 | P2 |
| 14 | Implement key layers incrementally (Persona + API first) | CT-5 | P2 |

### Future (Secure Pod -- SHOULD ADDRESS)

| # | Recommendation | Finding | Priority |
|---|---------------|---------|----------|
| 15 | Design pod redundancy (multi-instance or Shamir key sharing) | SP-1 | P1 |
| 16 | Enforce no-blob-caching in pod (fresh fetch per request) | SP-2 | P0 |
| 17 | Implement budget enforcement external to the pod | SP-3 | P1 |
| 18 | Label client-side pod as "Sender-Controlled Mode" | SP-4 | P2 |
| 19 | Default to strict mode (deny access) when pod unavailable | SP-5 | P1 |
| 20 | Never implement fallback-to-direct-PKI during pod outage | SP-5 | P0 |

---

## Conclusion

The three briefs describe a coherent and well-reasoned PKI architecture. The foundational cryptographic choices are sound -- AES-256-GCM for content, RSA-OAEP for key wrapping, hash chaining for integrity, challenge-response for authentication. The overall design follows established patterns (PGP/GPG web of trust, Certificate Transparency, Signal multi-device, proxy re-encryption).

The critical findings are not architectural flaws but **gaps in the specification** that, if left unaddressed in implementation, become vulnerabilities:

1. **Authentication on the key publishing endpoint** (KD-1) -- a single missing auth check enables registry pollution.
2. **Equivocation resistance** (CT-1) -- the brief correctly identifies this as a research task, and the phased approach is appropriate.
3. **Trust propagation from compromised admins** (CT-2) -- inherent to delegation models, mitigatable with threshold signing.
4. **Pod+server combined compromise** (SP-2) -- acknowledged and correctly analysed in the brief.

The key discovery build is the immediate priority and has the most actionable findings. Recommendations 1-7 should be incorporated into the build specification before development begins.

---

*AppSec review complete. This document covers all security-relevant aspects of the three v0.4.27 briefs dated 21 Feb 2026. Next scheduled review: after the key discovery implementation is complete and the chain-of-trust protocol design is proposed by the Architect.*
