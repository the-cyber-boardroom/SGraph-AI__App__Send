# The Football Team: Why Practice Makes Incidents Look Like Exercises

**version** v0.2.23  
**date** 12 Feb 2026  
**series** Incident Handling (5 of 5)  
**see also** "The P3-as-P1 Philosophy" (1 of 5), "Running P3-as-P1 in Practice" (2 of 5), "Incidents as the Best Time to Fix Things" (3 of 5), "First, Do No Harm" (4 of 5)  

---

## The Best Compliment

Here's a story from running this approach in practice.

After months of running P3-as-P1 exercises — treating minor incidents as full investigations, building runbooks, practising the swarming, fine-tuning the communication, mapping the gaps — we had a real P1. A genuinely dangerous incident where, through a series of events, malware could have run and installed across the system. Potentially catastrophic.

The team swarmed. Multiple parts of the business coordinated. Within half an hour, most of it was under control. Within an hour, the whole thing was wrapped up. Within four hours, the incident was fully resolved, documented, and closed.

Some of the colleagues who observed the response thought it was an exercise. They genuinely didn't believe it was a real incident. "There's no way this could have been handled like that if it was real."

That was the best compliment the team ever received. It meant the operational capability was so efficient, so rehearsed, so well-coordinated that a real emergency looked like a drill. The chaos that normally accompanies a P1 — the confusion, the scrambling, the "who's in charge?", the "where's the data?" — simply didn't happen. Everyone knew their role. Everyone knew the process. Everything ran in parallel. The system worked.

That doesn't happen by accident. It happens because the team practised.

## The Football Team Analogy

Imagine a football team that only plays together on match day. The players have never trained together. They've never practised set pieces. They've never worked on positioning, communication, or strategy. They show up, the whistle blows, and they figure it out on the pitch.

That team will lose. Every time. It doesn't matter how talented the individual players are. Without practice, there's no coordination, no muscle memory, no shared understanding of how to move together.

Now imagine a team that trains five days a week. They practise formations. They run drills. They study the opposition. They rehearse set pieces until the movement is automatic. They simulate match conditions. They review footage of their own performance and identify weaknesses.

When match day comes, they don't panic. They execute. Not because the match goes exactly as planned — it never does — but because they've practised the fundamentals so many times that adapting to unexpected situations is natural. The foundation is solid, so the improvisation works.

Security incident response is the same. The P3-as-P1 approach is training. The minor incidents are drills. The tabletop exercises are scrimmages. The runbooks are the playbook. The Issues FS incident database is the match footage you review afterwards.

When the real P1 comes — and it will — the team doesn't need to figure out how to respond. They already know. They've done it dozens of times. The only difference is the stakes.

## Planning for Readjustment

There's a common saying: "no battle plan survives first contact with the enemy." People use it to argue that planning is futile — why bother planning if the plan will break?

That argument is wrong. If your plan breaks on first contact, you had the wrong kind of plan.

A rigid plan that assumes a specific sequence of events will fail the moment reality diverges. But a plan that's designed for flexibility — that builds the infrastructure to react, adapt, and readjust — thrives on contact. Every interaction with the enemy (or the incident, or the unexpected) is new information that feeds into the next decision.

The P3-as-P1 approach doesn't plan specific responses to specific incidents. It builds:

- **Situation awareness capability** — the ability to quickly understand what's happening, across all relevant systems, with current data
- **Swarming capability** — the ability to assemble the right roles quickly, with clear coordination and no single-point-of-failure in the response team
- **Communication capability** — the ability to produce stakeholder-appropriate briefings rapidly, from structured incident data
- **Decision-making capability** — the ability to assess options, simulate consequences, and commit to actions with understood risks
- **Learning capability** — the ability to capture what happened, what worked, what didn't, and feed it back into the system

These aren't plans. They're capabilities. And capabilities survive contact with the enemy because they're not predictions about what will happen — they're the infrastructure to handle whatever does happen.

You don't plan the outcome. You plan the readjustment. You bring the machine to react.

## The Preparation Spectrum

There's a spectrum from fully unprepared to fully automated:

```
UNPREPARED          PRACTISED           OPERATIONALISED       AUTOMATED
────────────────────────────────────────────────────────────────────────

"What do we do?"    "We know what       "The runbook          "The system
                     to do — we've       handles this          handles this
 Confusion.          practised it."      automatically.        automatically
 Scrambling.                             Human reviews         and self-heals.
 Improvisation.     Coordination.        the output."          Human is
 Heroics.           Confidence.                                notified after
                    Speed.              Efficiency.            the fact."
                                        Consistency.
                                                              Resilience.
```

Every incident type starts on the left. The P3-as-P1 approach moves it rightward:

1. **First encounter** (unprepared): we don't know what to do. We figure it out in real time. It's messy. But we capture everything.
2. **Second encounter** (practised): we've seen this before. We have a runbook from last time. We follow it, improve it, and fill the gaps.
3. **Third encounter** (operationalised): the runbook is mature. Most of the response is procedural. Humans make the judgment calls; the process handles the logistics.
4. **Nth encounter** (automated): the response is codified as automation. The system detects, responds, and resolves without human intervention. Humans are notified and review the outcome.

The goal isn't to get everything to "automated" immediately. The goal is to move each incident type one step rightward every time it occurs. Over time, more and more scenarios move to the right end of the spectrum, and the team's capacity is freed up to focus on the genuinely novel threats — the things that are still on the left.

## Creative Storytelling: Making Incidents Engaging

Here's an unconventional idea that works: make incident reports engaging. Not just accurate — engaging.

The cartographer, the historian, and the journalist have a creative opportunity during and after every incident:

### The Journalist: News Stories
Write the incident report as a news story, not a dry post-mortem. "At 14:32 on Tuesday, the sherpa's trail data flagged an unusual access pattern on the file transfer endpoint. Within 15 minutes, the CISO had declared a P3-as-P1 and the team was assembled..." A narrative draws readers in. People actually read narratives. People skip bullet-pointed post-mortems.

### The Historian: The Timeline as a Story
The timeline isn't just a list of timestamps. It's the story of the response — who did what, when they did it, what they found, how it changed the picture. Annotate the timeline with the decision points: "At this moment, we had two options. We chose X because Y. If we'd chosen the other option, Z would have happened."

### The Cartographer: Visual Incident Maps
The blast radius, the dependency graph, the attack path, the response flow — all of these can be visualised. A visual incident map that shows how the incident propagated through the system, where it was detected, and where it was contained tells the story faster than any written report.

### Interactive Incident Replays
Because the incident lives in an Issues FS database, it can be replayed. Imagine an interactive walkthrough where someone can step through the incident chronologically, seeing each action, each finding, each decision point, with the ability to explore "what if we'd done this instead?" branches.

This isn't just nice to have. It's a training tool. New team members (or new agents) can learn from historical incidents by walking through them interactively. The institutional knowledge isn't locked in someone's head or buried in a document — it's a replayable, explorable experience.

### Why This Matters

The learning from incidents only works if people engage with the material. A dry post-mortem that nobody reads produces no learning. A compelling narrative that draws people in, with visual maps and interactive replays, produces deep learning that sticks.

And it builds culture. When incident reports are engaging, people look forward to them. The team develops a shared language around incidents. Stories get referenced in future discussions: "Remember the time we found that CloudFront misconfiguration? This feels similar." The incidents become part of the team's identity.

## The End State

Everything in this five-part series builds toward the same end state:

We want a system that can detect bad activities by itself. That can protect itself. That can self-heal. Not because it's magical — but because we've built such comprehensive visibility on the happy path, such thorough understanding of how the system should behave, that when it doesn't behave that way, we detect it immediately.

We get there by:

1. **Practising the response** — P3-as-P1 exercises build the team's muscle memory, reveal gaps, and produce improvement backlogs (docs 1–2)
2. **Fixing things during incidents** — the 5x multiplier means incident time is the most productive time for infrastructure improvement (doc 3)
3. **Simulating before acting** — pre-action modelling and what-if scenarios prevent self-inflicted escalation (doc 4)
4. **Communicating effectively** — personalised stakeholder briefings from structured data keep everyone informed without overwhelming anyone (doc 4)
5. **Mapping to frameworks organically** — each incident expands the framework coverage by one real, evidence-backed cluster (doc 4)
6. **Moving incidents rightward on the preparation spectrum** — from unprepared to practised to operationalised to automated (doc 5)
7. **Making the learning stick** — creative storytelling, visual maps, and interactive replays ensure the team actually absorbs the lessons (doc 5)

The vulnerabilities will come. The risks are real. Things will go wrong. The question is never "will something happen?" — it's "how fast can we detect it? How fast can we contain it? How fast can we get the first responders there? And how fast can we move this incident type from 'surprise' to 'automated response'?"

That's what we're building. Not a perfect system — a prepared one.

---

## The Series Summary

| Doc | Title | Core Message | Primary Audience |
|-----|-------|-------------|-----------------|
| 1 | The P3-as-P1 Philosophy | "What could have happened" matters more than "what happened" | CISO, GRC, Leadership |
| 2 | Running P3-as-P1 in Practice | How to operationally run a minor incident at major-incident process level | All roles (the playbook) |
| 3 | Incidents as the Best Time to Fix Things | The 5x productivity multiplier and why incidents are improvement engines | Conductor, DevOps, All roles |
| 4 | First, Do No Harm | Simulation, multi-audience communication, escalation, and framework integration | CISO, Journalist, GRC, Conductor |
| 5 | The Football Team | Why practice makes real incidents look like exercises | All roles (the cultural capstone) |

---

## For the Agents

- **CISO**: you own this entire series. It's your operational philosophy, your playbook, and your cultural programme. Internalise it. Ensure every other role has read and understood the parts relevant to them. After the first few P3-as-P1 exercises, write a retrospective on how the approach is working and what needs adjustment.
- **Conductor**: the preparation spectrum is your planning tool. For every incident type the team encounters, track where it sits on the spectrum (unprepared → practised → operationalised → automated). Your goal is rightward movement. Report on spectrum progress regularly.
- **Journalist**: you have the most creative brief in this series. Incident reports as news stories. Timelines as narratives. Interactive replays. Visual maps. Make the learning engaging. Make people want to read the incident reports. This is how you build a culture that takes incidents seriously without making them feel like punishment.
- **Historian**: you own the institutional memory of incidents. The incident register, the cross-incident patterns, the evolution of the team's capability over time. When someone asks "are we getting better at this?", you should be able to show the data: response times trending down, gaps-found trending down, automation-coverage trending up.
- **Cartographer**: incident visualisations are your creative canvas. Blast radius maps, attack path diagrams, response flow charts, dependency impact visualisations. Each incident should produce at least one visual that tells the story faster than words can.
- **Librarian**: build the incident library. Index by trigger type, by severity, by roles involved, by framework connections, by gaps found. Make historical incidents findable and referenceable. When the CISO says "have we seen this before?", you should have the answer — and the link to the full incident database — within seconds.
- **QA**: every incident produces tests. The test suite, over time, becomes a regression safety net built from real incidents. Track the growth: how many tests were created from incidents versus from normal development? The incident-derived tests are almost always higher value because they test real failure modes.
- **DevOps**: you are the primary engine of the rightward movement on the preparation spectrum. When something moves from "practised" to "operationalised," it's because you automated the runbook. When it moves from "operationalised" to "automated," it's because you built the self-healing capability. Track how many incident types you've automated responses for.
- **All roles**: the cultural shift is this: "how come this was possible?" is always a valid question. You don't need to be a security expert to notice something odd. You don't need permission to raise a weak signal. If something surprises you — if the system does something you didn't expect, if a change has an effect you didn't predict, if you can do something you shouldn't be able to do — say so. That's the raw material that makes the whole system work.
