# Architecture Brief: Chain of Trust, Key Graphs, and Layered Identity

**version** v0.4.27  
**date** 21 Feb 2026  
**from** Human (project lead)  
**to** Architect (lead), AppSec, Developer  
**type** Architecture brief — PKI trust model design  

---

## What This Document Covers

The admin PKI key management is built and deployed. Key discovery and the public registry are defined (see dev brief). This document addresses the deeper architectural questions:

1. How do key graphs enable chain-of-trust discovery?
2. How does key rotation work when private keys live in browsers?
3. How do layered identities (session, device, persona, admin) compose?
4. How does revocation work naturally through trust graph maintenance?
5. How does git-style hash chaining guarantee integrity of the trust graph?
6. How does PKI-encrypted page delivery create personalised, authenticated web experiences?

---

## Foundational Principle: Only Encrypted Blobs and Tokens

Everything stored on the server is either:

- **Encrypted content** — PKI-encrypted blobs the server cannot read
- **Tokens** — Obj_Ids (8-hex, e.g., `a3f7c891`) or full GUIDs/UUIDs
- **Public keys** — public by definition, safe to store and serve

**No strings.** No folder names, no user names, no labels, no metadata in plaintext. A folder is an Obj_Id. A user is an Obj_Id. A relationship is an edge between two Obj_Ids. This eliminates:

- Metadata leakage (the server reveals no semantic information)
- Injection attacks (there are no strings to inject into — the server processes only tokens and encrypted blobs)
- Traffic analysis (an observer sees Obj_Ids and ciphertext, nothing else)

Human-readable names exist only on the client side (in IndexedDB) or as encrypted metadata within PKI-encrypted blobs that only authorised key holders can decrypt.

---

## Part 1: The Key Graph — Chain of Trust

### The Problem

Alice gives you her public key on a business card. Now you want to send encrypted messages to Alice's five colleagues. You don't have their keys. You don't have their business cards. How do you get their keys securely?

### The Solution: Trust Propagation Through the Key Graph

The server maintains a **graph of keys and trust relationships**:

```
Company-X (Obj_Id: a3f7c891)
├── has-member → Alice  (Obj_Id: b4e2d903, public_key: ...)
├── has-member → Bob    (Obj_Id: c5f3e014, public_key: ...)
├── has-member → Carol  (Obj_Id: d6g4f125, public_key: ...)
├── has-member → Dave   (Obj_Id: e7h5g236, public_key: ...)
└── has-member → Eve    (Obj_Id: f8i6h347, public_key: ...)
```

The graph is stored as Obj_Ids and edges. No names. The company node is an Obj_Id. Each member is an Obj_Id. The edges are typed relationships (`has-member`). Public keys are attached to the member nodes.

**The trust chain:**

```
1. You have Alice's public key (obtained out-of-band, verified)
2. Alice's key is associated with Company-X in the graph
3. You query: "Give me all keys in the same trust group as Alice's key"
4. Server returns: Bob, Carol, Dave, Eve's public keys
5. Each key in the response is SIGNED by the server's key
   (which you already trust — it was pinned on first visit)
6. You now have all five keys, obtained through one trusted relationship
```

**From one trusted key, you can discover the entire trust graph.**

### Trust Graph as Issues-FS Graph

This IS a graph — store it in Issues-FS / Memory-FS natively. The key graph is just another graph in the system, with nodes (keys/identities) and edges (trust relationships):

```
Node: { obj_id: "b4e2d903", type: "public-key", data: { pem: "...", algorithm: "RSA-OAEP" } }
Node: { obj_id: "a3f7c891", type: "trust-group", data: {} }
Edge: { from: "a3f7c891", to: "b4e2d903", type: "has-member", signed_by: "server-key" }
```

All the Issues-FS machinery (traversal, querying, visualisation) works on the key graph. The Cartographer can visualise trust relationships. The AppSec can audit them.

---

## Part 2: Git-Style Hash Chaining for Graph Integrity

### The Concept

Every change to the trust graph is a commit. Every commit is hashed with the previous commit's hash. This creates an append-only, tamper-evident chain — exactly like git, and yes, exactly like a blockchain.

```
Commit 0 (genesis):
  action: "CREATE_GROUP"
  data: { group_obj_id: "a3f7c891" }
  hash: sha256(action + data + "0000...0000")
  → hash: "1a2b3c4d..."

Commit 1:
  action: "ADD_MEMBER"
  data: { group: "a3f7c891", member: "b4e2d903", public_key_fingerprint: "sha256:3a7f..." }
  previous_hash: "1a2b3c4d..."
  hash: sha256(action + data + "1a2b3c4d...")
  → hash: "5e6f7g8h..."

Commit 2:
  action: "ADD_MEMBER"
  data: { group: "a3f7c891", member: "c5f3e014", public_key_fingerprint: "sha256:8b2e..." }
  previous_hash: "5e6f7g8h..."
  hash: sha256(action + data + "5e6f7g8h...")
  → hash: "9i0j1k2l..."

Commit 3:
  action: "ROTATE_KEY"
  data: { member: "b4e2d903", old_fingerprint: "sha256:3a7f...", new_fingerprint: "sha256:7d4e..." }
  previous_hash: "9i0j1k2l..."
  hash: sha256(action + data + "9i0j1k2l...")
  → hash: "3m4n5o6p..."
```

### What This Gives Us

| Property | How Hash Chaining Provides It |
|---|---|
| **Tamper evidence** | If any historical commit is modified, all subsequent hashes break. Anyone can verify the chain. |
| **Append-only history** | You can add commits but never remove or modify them. Deletion is a new commit ("REVOKE_MEMBER"), not removal of the add commit. |
| **Auditability** | The complete history of every key addition, rotation, and revocation is preserved and verifiable. |
| **Client verification** | Clients can independently compute hashes and verify the chain. If the server serves a tampered chain, clients detect it. |
| **Fork detection** | If the server shows different chains to different clients (equivocation), clients comparing chains will detect the fork — same as detecting a git force-push. |

### Signing Each Commit

Each commit is also **signed by the entity making the change**:

- Group admin adds a member → commit signed by admin's private key
- Server rotates its own key → commit signed by old key (key continuity)
- User rotates their key → commit signed by identity provider (OAuth/Cognito) attestation

This means the chain isn't just tamper-evident — it's **attributable**. You can trace every change to the entity that authorised it.

---

## Part 3: Key Rotation — Identity as the Anchor

### The Problem

Private keys live in the browser (IndexedDB, non-extractable). Browsers get cleared. Devices get lost. Users switch machines. The private key WILL be lost. When it is, the user needs a new key pair — but everyone who has their old public key needs to know about the new one.

### The Solution: Identity-Anchored Key Rotation

The **identity** (OAuth, Cognito, email address) is the persistent anchor. Keys are ephemeral. Identity endures.

```
Identity: dinis@sgraph.ai (authenticated via Cognito/OAuth)
  ├── Public Key v1 (created 2026-02-19, ACTIVE)
  ├── Public Key v2 (created 2026-03-15, ACTIVE — new device)
  └── Public Key v3 (future)
```

The identity can have **multiple active public keys** simultaneously (one per device/browser). The server maintains the mapping: identity → list of active public keys.

### Rotation Workflow

```
1. User loses their private key (cleared browser data, new device, etc.)
2. User authenticates to the server (OAuth/Cognito — identity is intact)
3. User generates a new key pair on their new browser
4. User publishes the new public key
5. Server creates a ROTATE_KEY commit in the hash chain:
   - Signed by the server's key (server attests the identity authenticated)
   - References the old key fingerprint and the new key fingerprint
   - The identity binding (OAuth subject ID) is the bridge
6. Clients who query for this identity's key get the new one
7. The old key remains in history (old encrypted content still references it)
```

### Automatic Key Update for Contacts

When a client wants to send a message to a contact:

```
1. Client checks: "Do I have a public key for contact X?"
2. Client queries server: "What's the current key for contact X?"
3. Server responds with the current key
4. If different from stored key:
   Client: "The key for this contact has changed. 
            Old fingerprint: sha256:3a7f...
            New fingerprint: sha256:7d4e...
            This change was recorded in the trust chain on 15 Mar 2026.
            [Accept new key]  [Reject — verify out of band]"
5. User accepts → local contact updated
```

For high-security contexts (investor data rooms), the user should verify out of band. For casual use, auto-accept with a notification is sufficient. The user chooses their security posture.

### Multiple Active Keys (Multi-Device)

A user with two browsers has two key pairs. Both are valid. Both are published. When someone sends them a message, they can encrypt for ALL active keys (the message is encrypted once per active key — standard multi-recipient PKI):

```
Encrypted message contains:
  ├── AES key wrapped with Public Key v1 (desktop browser)
  └── AES key wrapped with Public Key v2 (mobile browser)

Either device can decrypt the AES key → decrypt the message.
```

This is how PGP handles subkeys and how Signal handles multi-device. It's well-understood.

---

## Part 4: Trust Graphs as Natural Revocation

### The Insight

Traditional PKI uses Certificate Revocation Lists (CRLs) or OCSP — centralised lists of "these certificates are no longer valid." They're clunky, often unchecked, and have latency problems.

The key graph provides **natural revocation through graph maintenance**.

### How It Works

A company maintains its trust graph: Company-X has members Alice, Bob, Carol, Dave, Eve.

```
Company-X
├── Alice ✓ (active)
├── Bob ✓ (active)
├── Carol ✓ (active)
├── Dave ✓ (active)
└── Eve ✓ (active)
```

Eve leaves the company. The admin removes her from the trust graph:

```
Commit N:
  action: "REVOKE_MEMBER"
  data: { group: "a3f7c891", member: "f8i6h347", reason: "departed" }
  signed_by: admin_key
  previous_hash: "..."
```

The graph becomes:

```
Company-X
├── Alice ✓ (active)
├── Bob ✓ (active)
├── Carol ✓ (active)
├── Dave ✓ (active)
└── Eve ✗ (revoked — commit N)
```

**What happens on the client side:**

```
1. Client wants to send a message to Eve
2. Client queries: "Is Eve's key still in Company-X's trust graph?"
3. Server: "No — Eve's key was revoked at commit N"
4. Client: "⚠ This key has been revoked. The trust relationship 
            that validated this key no longer exists."
5. Client REFUSES to encrypt for Eve's key
```

The client doesn't need a separate CRL or OCSP check. It just checks the trust graph. If the key isn't in the graph, it's not trusted. **Revocation is the absence of trust, not the presence of a revocation entry.**

### The Same Model Works for Personal Trust

It's not just companies. Personal webs of trust evolve naturally:

```
My Trust Graph (personal):
├── Alice (met at dinner, exchanged keys)
├── Bob (Alice introduced, trust inherited)
├── Carol (colleague, key exchanged at office)
└── Dave (removed — we no longer work together)
```

Trust relationships change over time. People join your network. People leave. The graph reflects reality. Revocation is just removing an edge — a natural operation, not a special mechanism.

### Employee Lifecycle as Automatic Revocation

For enterprise deployments, this is transformative. The trust graph is maintained as part of normal HR operations:

| Event | Graph Operation | Effect |
|---|---|---|
| Employee hired | `ADD_MEMBER` commit | Their key is trusted by all company contacts |
| Employee changes role | `UPDATE_ROLE` commit | Access scope changes (data room permissions) |
| Employee leaves | `REVOKE_MEMBER` commit | Their key is instantly distrusted by all clients |
| Contractor engaged | `ADD_MEMBER` with expiry | Trust is time-bounded |
| Contractor term ends | `REVOKE_MEMBER` or auto-expiry | Trust disappears automatically |

The admin doesn't think about "revoking certificates." They think about "this person left the company." The revocation is a natural consequence of the graph update.

---

## Part 5: Layered Key Identity

### The Key Hierarchy

Every client session involves multiple layers of identity, each with its own key:

```
Layer 1: API Key
  What: the access token (what we have now)
  Purpose: gates access to the platform
  Lifetime: long-lived, revocable
  
Layer 2: Device/Session Key
  What: an ephemeral key pair generated per browser session
  Purpose: identifies THIS browser instance, makes replay attacks harder
  Lifetime: session or short-lived, auto-rotated
  
Layer 3: Persona Key
  What: the user's identity key pair (stored in IndexedDB)
  Purpose: confidentiality (encrypt to this key) and authenticity (signed by this key)
  Lifetime: persistent until rotated (browser data cleared, new device)
  A user can have MULTIPLE personas (investor persona, personal persona, etc.)
  
Layer 4: Admin Key
  What: an elevated-privilege key installed out-of-band
  Purpose: authorises administrative operations
  Lifetime: persistent, manually managed, high-ceremony rotation
```

### Challenge-Response Authentication

The server can authenticate any layer by issuing a challenge:

```
Server → Client: { challenge: "random-nonce-abc123", request: "identify-persona" }
Client → Server: { 
  challenge: "random-nonce-abc123", 
  response: sign(challenge, persona_private_key),
  public_key_fingerprint: "sha256:3a7f..."
}
Server: verify(response, stored_public_key) → authenticated
```

This is the same pattern as SSH key authentication and WebAuthn/passkeys. Each layer can be challenged independently.

### Composable Authentication

For a sensitive operation (e.g., "delete all files in data room"), the server can require multiple layers:

```
Server: "To perform this action, authenticate with:
         ✓ API Key (already provided)
         ✓ Device key (sign this challenge)
         ✓ Persona key (sign this challenge)
         ✓ Admin key (sign this challenge)"
```

An attacker who compromises one layer (e.g., steals the API key) cannot perform admin operations without also compromising the admin key (installed on a specific browser, out-of-band).

### Multiple Personas per Browser

The investor use case: one person, multiple roles:

```
Browser (IndexedDB):
├── Persona: "Fund Manager" (key pair for investor activities)
├── Persona: "Board Member — Portfolio Co A" (key pair for board comms)
├── Persona: "Board Member — Portfolio Co B" (key pair, separate from Co A)
└── Persona: "Personal" (key pair for personal secure comms)
```

Portfolio Company A's data room trusts the "Board Member — Portfolio Co A" key. Portfolio Company B's data room trusts the "Board Member — Portfolio Co B" key. The two are completely isolated. Compromising one persona doesn't affect the other.

---

## Part 6: PKI-Encrypted Personalised Web Delivery

### Connecting to the Service Worker Trust Anchor

The Service Worker trust anchor architecture (see `v0.4.12__appsec-research__service-worker-trust-anchor.md`) established that we can deliver encrypted page content that only authorised browsers can decrypt. PKI makes this real.

### Personalised Encrypted Websites

If the server knows the user's public key, it can encrypt **the entire web experience** for that specific user:

```
1. User visits a data room URL
2. Service Worker intercepts (trust anchor verified)
3. Service Worker sends the user's public key fingerprint to the server
4. Server encrypts the HTML/JS/CSS response with the user's public key
5. Service Worker decrypts with the user's non-extractable private key
6. Decrypted content rendered in the browser
```

What this means:

- **The HTML is personalised and encrypted.** Two different users visiting the same URL receive different ciphertext. Each can only decrypt their own.
- **The CSS/JS can be personalised.** Different users get different features, different branding, different access levels — all enforced cryptographically, not just by access control logic.
- **The CDN/server sees only ciphertext.** Even if compromised, the attacker gets ciphertext they can't decrypt.
- **Only the target user's browser can render the page.** Not just "access controlled" — cryptographically impossible for anyone else to see the content.

### Use Cases

| Scenario | What Gets Encrypted/Personalised |
|---|---|
| **Investor data room** | Each participant sees only their authorised documents. The HTML itself is different per user. |
| **Board pack distribution** | Each board member gets a personalised view encrypted to their key. |
| **Co-branded deployment** | Partner branding is encrypted for their users only. Competitors can't see each other's deployments even if they share infrastructure. |
| **Admin panel** | Admin interface encrypted to admin keys. Even if someone discovers the admin URL, the page renders as ciphertext without the admin key. |
| **Regulatory compliance** | Demonstrate cryptographic enforcement of access control — not just "we check permissions" but "it's mathematically impossible to access without the key." |

---

## Data Room Architecture (Putting It All Together)

**Note on multi-user encryption**: this section describes the data room structure (trust graphs, content addressing, hash chains). The question of how multiple users access the same encrypted content — specifically, how to maintain zero-knowledge while supporting revocable multi-user access — is addressed in a separate document: `v0.4.12__architecture__secure-pod-multi-user-encryption.md`. That architecture introduces a "secure pod" that re-encrypts content per-request, ensuring revoked users can never access content they didn't previously open. **That capability is future work, dependent on customer demand.** The current priority is the PKI key management and discovery UI.

A data room for an investment deal combines all of the above:

```
Data Room: Deal Alpha (Obj_Id: x1y2z3)
│
├── Trust Graph:
│   ├── Investor Group (trust-group Obj_Id)
│   │   ├── Alice (investor) — public key
│   │   └── Bob (analyst) — public key
│   ├── Legal Firm (trust-group Obj_Id)
│   │   ├── Carol (partner) — public key
│   │   └── Dave (associate) — public key
│   └── Target Company (trust-group Obj_Id)
│       └── Eve (CEO) — public key
│
├── Content (all encrypted, stored as Obj_Id → blob):
│   ├── Obj_Id:001 → encrypted NDA (all parties)
│   ├── Obj_Id:002 → encrypted term sheet (investor + legal only)
│   ├── Obj_Id:003 → encrypted financial model (investor only)
│   └── Obj_Id:004 → encrypted legal opinion (legal only)
│
├── Thread (sequence of encrypted messages between parties):
│   ├── Obj_Id:msg-001 → encrypted by Alice for Eve
│   ├── Obj_Id:msg-002 → encrypted by Eve for Alice
│   └── ...
│
├── Hash Chain:
│   ├── Commit 0: CREATE_DATA_ROOM
│   ├── Commit 1: ADD_TRUST_GROUP "Investor Group"
│   ├── Commit 2: ADD_MEMBER Alice
│   ├── Commit 3: ADD_MEMBER Bob
│   ├── ...
│   └── Commit N: current state
│
└── Service Worker Trust Bundle:
    ├── Server signing key
    ├── Allowed sources: [data-room-server.pub]
    ├── Allowed content types: [documents, messages, metadata]
    └── Reject unsigned: true
```

Every component is addressed by Obj_Id. Every blob is encrypted. Every trust change is hash-chained and signed. The server sees only tokens and ciphertext. The Service Worker enforces content integrity. The PKI enforces confidentiality. The trust graph enforces authorisation.

If Eve leaves the target company mid-deal, her trust graph entry is revoked. Her browser can no longer decrypt new content. Existing content she already decrypted is on her device (we can't unring that bell), but no new content flows to her.

---

## Implementation Dependencies and Current Priorities

```
BUILT AND DEPLOYED:
  ✓ Admin PKI key management (pki.html)
  ✓ Key generation, storage, import/export
  ✓ Encrypt/decrypt working in production

IMMEDIATE PRIORITY (what the team should focus on NOW):
  → Key discovery UI and public registry ← THIS IS THE NEXT BUILD
    (see v0.4.12__dev-brief__key-discovery-and-public-registry.md)

DESIGN WORK (this document):
  → Trust graph data model (Issues-FS native)
  → Hash chain implementation (git-style commit chaining)
  → Challenge-response protocol for layered auth
  → Key rotation flow with identity binding

FUTURE (dependent on customer demand):
  → Secure pod for multi-user revocable encryption
    (see v0.4.12__architecture__secure-pod-multi-user-encryption.md)
  → Service Worker trust anchor (AppSec research brief)
  → Claude skill integration
  → Full data room product
```

---

## Research Tasks

| Task | Owner | Priority |
|---|---|---|
| Design the trust graph schema in Issues-FS (nodes: keys, groups, identities; edges: membership, trust) | Architect | D1 |
| Implement git-style hash chaining for graph commits | Developer, Architect | D2 |
| Design the challenge-response protocol for layered authentication | Architect, AppSec | D2 |
| Design the key rotation flow (identity-anchored, server-attested, hash-chained) | Architect | D2 |
| Prototype the data room trust configuration | Architect | D3 |
| Prototype encrypted page delivery (one page, one user, PKI-encrypted HTML) | Developer | D3 |
| AppSec review: equivocation attacks (server showing different chains to different clients) | AppSec | D2 |
| AppSec review: challenge-response protocol (replay attacks, nonce management) | AppSec | D2 |
| Research: how Signal, Wire, and Keybase handle multi-device key management | Architect | D3 |
| Research: Key Transparency (Google's approach) for our trust graph log | Architect, AppSec | D3 |

---

This document is released under the Creative Commons Attribution 4.0 International licence (CC BY 4.0). You are free to share and adapt this material for any purpose, including commercially, as long as you give appropriate credit.
