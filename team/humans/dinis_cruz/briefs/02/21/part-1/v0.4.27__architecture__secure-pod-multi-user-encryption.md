# Architecture Brief: Secure Pod — Multi-User Revocable Encryption

**version** v0.4.27  
**date** 21 Feb 2026  
**from** Human (project lead) + architecture analysis  
**to** Architect (lead), AppSec, Developer  
**type** Architecture brief — future capability (not for immediate implementation)  
**status** RESEARCH — implementation dependent on customer demand  

---

## Status Note

**This document describes a future architecture.** It solves a genuine hard problem in cryptography (multi-user revocable access to encrypted content without server-side plaintext access), but it is not on the immediate build roadmap.

Implementation will be triggered by customer demand — specifically, enterprise customers who need data rooms with revocable access and provable audit trails. The current PKI work (key management, key discovery, trust graphs) is the foundation this builds on.

---

## The Problem: The Encryption Trilemma

When multiple users need access to the same encrypted content, three properties are in tension:

```
1. ZERO-KNOWLEDGE SERVER    — full server compromise leaks nothing
2. MULTI-USER ACCESS        — N users can decrypt the same content
3. REVOCABLE ACCESS         — a removed user can no longer decrypt, 
                              including content they were authorised for 
                              but never actually opened
```

### Why You Can't Have All Three (Naively)

| Approach | Zero-Knowledge | Multi-User | Revocable | Problem |
|---|---|---|---|---|
| **Per-user PKI wrapping** | ✓ Server never sees plaintext | ✓ Wrap content key per user | ✗ Revoked user still has their wrapped key | Full server dump + stolen private key = all authorised content exposed |
| **Group key with rotation** | ✓ Server never sees plaintext | ✓ One encryption, tiny key wraps | ✗ Partial — only new content protected | Old content still decryptable by revoked user |
| **Server-side re-encryption** | ✗ Server must decrypt to re-encrypt | ✓ Server manages access | ✓ Re-encrypt without revoked user's key | Zero-knowledge broken |

Every naive approach fails on at least one property. The core reason: **if a user ever holds a key that works on stored content, revocation is impossible.** You can't un-know a key. And re-encrypting stored content requires someone to see the plaintext.

### The Fundamental Constraint

Whatever a user has already decrypted and downloaded is gone — we can't control that. A user can screenshot, photograph their screen, or copy-paste. Physical access to decrypted content is uncontrollable.

**The goal is not to control what users have already seen. The goal is to ensure that the maximum damage from any user — including a revoked user with a full server dump — is exactly the set of documents they actually opened.** Not the set they were authorised for. Not the set on the server. Only what they specifically requested and received.

---

## The Solution: The Secure Pod

### Architecture

Introduce a new component — the **pod** — that sits between the server and the user. The pod is a secure enclave whose only job is: decrypt, re-encrypt, forget.

```
┌──────────┐     ┌──────────┐     ┌──────────┐     ┌──────────┐
│  SENDER  │     │  SERVER  │     │   POD    │     │   USER   │
│          │     │          │     │          │     │          │
│ Encrypts │────▶│  Stores  │     │  Holds   │     │ Requests │
│ with pod │     │ encrypted│     │  pod's   │     │  access  │
│ public   │     │  blobs   │     │  private │     │          │
│ key      │     │          │     │  key     │     │          │
└──────────┘     └──────────┘     └──────────┘     └──────────┘
                       │                │                │
                       │   (encrypted)  │                │
                       │───────────────▶│   (request)    │
                       │                │◀───────────────│
                       │                │                │
                       │                │  1. Decrypt    │
                       │                │  2. Re-encrypt │
                       │                │     for user   │
                       │                │  3. Forget     │
                       │                │                │
                       │                │  (re-encrypted)│
                       │                │───────────────▶│
                       │                │                │
                       │                │                │ Decrypt
                       │                │                │ with own
                       │                │                │ private key
```

### The Flows

**Upload:**

```
1. Sender encrypts content with the pod's PUBLIC key
2. Encrypted blob stored on server
3. Server stores: { obj_id, encrypted_blob, metadata_obj_ids }
4. Server cannot read the content (encrypted with pod's key, not server's)
5. Pod's private key exists ONLY inside the pod
```

**Access Request:**

```
1. User: "I want file obj_id:a3f7c891"
2. Server checks trust graph: "Is user X still authorised for this file?"
   │
   ├── NO  → reject. Done. Revocation complete.
   │
   └── YES → proceed:
       3. Server sends encrypted blob to the pod
       4. Server sends user's public key to the pod
       5. Pod decrypts blob with pod's private key → plaintext in enclave memory
       6. Pod generates a UNIQUE symmetric key for THIS request
       7. Pod encrypts plaintext with the unique key
       8. Pod wraps the unique key with user's public key
       9. Pod sends { re_encrypted_content, wrapped_unique_key } to user
      10. Pod FORGETS plaintext, unique key — enclave memory cleared
      11. User unwraps unique key with their private key
      12. User decrypts content
```

**Revocation:**

```
1. Admin removes user from trust graph (REVOKE_MEMBER commit, hash-chained)
2. Next access request from user → step 2 fails → access denied
3. User's previously-received unique keys? Each was per-request, per-document.
   They work only on the specific re-encrypted copy the user received.
   They do NOT work on the blobs stored on the server.
4. Full server dump? Blobs encrypted with pod's key. Pod's key is in the pod.
   Server dump is useless without the pod.
```

### The Key Property

**The user NEVER holds a key that works on stored content.**

The stored blobs are encrypted with the pod's key. The user receives a re-encrypted copy with a unique, one-time key. The one-time key doesn't work on the stored blob. The pod's key never leaves the pod.

This means:
- Full server dump → attacker gets ciphertext encrypted with pod's key → useless
- Full server dump + user's private key → attacker can decrypt previously-received re-encrypted copies (the documents the user actually opened) → but NOT any other document on the server
- Pod compromise → this is the critical threat → attacker with pod's private key can decrypt all stored content → this is why the pod must be a hardened secure enclave

---

## Maximum Damage Model

| Scenario | What's Exposed | Blast Radius |
|---|---|---|
| Server compromised | Nothing (all blobs encrypted with pod's key) | Zero |
| User's private key stolen | Documents that user actually opened (re-encrypted copies) | Exactly the access log for that user |
| Server + user's private key | Same as above — server blobs still encrypted with pod's key | Exactly the access log for that user |
| Pod compromised (alone) | **NOT automatically "all content"** — see analysis below | Bounded by detection speed + attacker download rate |
| Server + pod compromised | All stored content | Total — both ciphertext and key in attacker's hands |

### Pod Compromise Is Not Automatically Game Over

A compromised pod (attacker has the pod's private key) is serious but **containable**, because the pod's key alone is not sufficient — the attacker also needs the encrypted blobs, which are on the server, not in the pod.

To exploit a pod-only compromise, the attacker must:

1. **Obtain the encrypted blobs from the server** — either by also compromising the server (a different, harder attack) or by requesting blobs through normal API channels
2. **Requesting through normal channels is detectable** — every request is logged in the append-only audit trail, anomalous download volume triggers alerts, unusual access patterns (bulk downloads, files outside normal usage, requests at unusual hours) are monitoring signals
3. **Rate limits constrain the attacker** — the pod has operational rate limits. Once micro-payment budgets are implemented (daily/hourly budget per pod), a compromised pod burning through its budget to bulk-decrypt is a screaming alarm signal
4. **Each request is individually logged** — the hash-chained access log records exactly which blobs were accessed during the compromise window, giving a precise blast radius

**Actual blast radius = content the attacker can download and decrypt before we detect and respond.** This is a function of:
- Detection speed (monitoring, anomaly detection, budget alerts)
- Attacker download rate (network throughput, rate limits)
- Response speed (time to isolate the compromised pod)

### Pod Compromise Response Protocol

```
1. DETECT    — anomalous access patterns, budget spike, integrity check failure,
               monitoring alerts
2. ISOLATE   — revoke the compromised pod's network access immediately.
               No new decryption requests can be served.
3. NEW POD   — stand up a new pod with a fresh key pair
4. RE-ENCRYPT — the old pod, in a controlled isolated environment with no
               network access except to the storage layer, re-encrypts all
               stored blobs:
                 decrypt with old pod key → encrypt with new pod's public key
               This is justified here because the pod IS the component that can
               do this. We're not breaking zero-knowledge — we're rotating a
               compromised trust anchor under controlled conditions.
5. DECOMMISSION — destroy the old pod and all its key material
6. AUDIT     — the access log tells us exactly what was accessed during
               the compromise window. This is the definitive blast radius.
7. NOTIFY    — inform affected users (those whose documents were accessed
               during the window) with the precise list of exposed documents
```

This response protocol means pod compromise is an incident with a bounded, auditable blast radius — not an automatic total compromise. The combination of monitoring, rate limiting, budget controls, and rapid response transforms a pod compromise from "game over" to "containable security incident with precise blast radius."

### The Micro-Payment Budget as Security Control

Once the Accountant's micro-payment system is in place, each pod has an allocated budget (daily, hourly, or per-transaction). This serves double duty:

- **Cost control**: prevents runaway infrastructure costs
- **Security control**: a compromised pod attempting bulk decryption burns through its budget rapidly, triggering an automatic circuit breaker before it can access a significant portion of content

The budget becomes a cryptoeconomic rate limit on compromise severity.

---

## The Audit Trail

Every decryption goes through the pod. The pod logs every request. The log is the definitive record of exposure:

```
Access Log (append-only, hash-chained):

  2026-02-20 10:00  User:b4e2d903  File:obj_id_001  GRANTED  unique_key_fingerprint:x1y2
  2026-02-20 10:05  User:b4e2d903  File:obj_id_002  GRANTED  unique_key_fingerprint:z3w4
  2026-02-20 10:10  User:f8i6h347  File:obj_id_001  DENIED   reason:revoked
  2026-02-20 10:15  User:c5f3e014  File:obj_id_003  GRANTED  unique_key_fingerprint:a5b6
```

If a breach investigation asks "what did User X have access to?" — the answer is the log. It's exhaustive. There is no other path to content.

For compliance and regulatory contexts (financial services, legal, healthcare), this is powerful: **cryptographically provable audit trail of exactly who accessed exactly what, and cryptographic proof that revoked users cannot access content they never opened.**

---

## Two Operation Modes

The platform offers two encryption modes. The user (or admin) chooses based on their needs:

### Mode 1: Direct PKI (No Pod)

```
Sender encrypts with recipient's public key → recipient decrypts with private key
```

- Zero-knowledge: ✓ (server never sees plaintext)
- Multi-user: ✗ (one recipient per encryption)
- Revocable: N/A (single recipient, revocation = remove from trust graph)
- Pod required: No
- Use case: one-to-one secure transfers, personal messages, simple file sharing

**This is the current model. It works. It stays.**

### Mode 2: Pod-Mediated (Multi-User, Revocable)

```
Sender encrypts with pod's public key → pod re-encrypts per-user on access
```

- Zero-knowledge (server): ✓ (server never sees plaintext)
- Zero-knowledge (pod): ✗ (pod sees plaintext momentarily during re-encryption)
- Multi-user: ✓ (any number of authorised users)
- Revocable: ✓ (revoke from trust graph → immediate effect)
- Pod required: Yes
- Use case: data rooms, team collaboration, regulatory-compliant document sharing

**This is the future capability described in this document.**

### Why Two Modes

Mode 1 is simpler, has fewer components, and is fully zero-knowledge (no intermediary sees plaintext). For most use cases, it's the right choice.

Mode 2 is for scenarios where multi-user access and revocability are requirements — specifically enterprise data rooms and regulated industries where "prove who saw what" is a compliance requirement.

The user/admin selects the mode when creating a data room or initiating a transfer. The platform clearly communicates the security properties of each mode.

---

## Pod Implementation Options (Future Research)

When customer demand triggers implementation, these are the options to evaluate:

| Implementation | Where It Runs | Trust Model | Complexity | Attestation |
|---|---|---|---|---|
| **AWS Nitro Enclave** | Hardware-isolated enclave inside EC2 | AWS attestation — verifiable that enclave runs only expected code, no SSH, no persistent storage | Medium | Cryptographic attestation document |
| **Separate AWS account** | Lambda/container in a dedicated, locked-down AWS account | Network isolation — content server account cannot access pod account's key storage | Low | AWS organizational controls |
| **Hardware Security Module** | AWS CloudHSM or dedicated hardware | FIPS 140-2/3 validated, tamper-resistant, keys never leave hardware | High | FIPS certification |
| **Client-side pod (sender's browser)** | The sender keeps the pod role — their browser re-encrypts on access requests | No server trust needed, fully decentralised | Low | No hardware attestation — trust the sender |
| **Third-party enclave** (Azure Confidential Computing, GCP Confidential VMs) | Cloud-provider hardware enclaves | Cross-cloud attestation | High | Provider-specific |

For the investor demo (if/when needed), "separate AWS account with strict IAM" is the pragmatic starting point. For enterprise production, Nitro Enclaves or HSM.

---

## Relationship to Other Documents

| Document | Relationship |
|---|---|
| **Admin PKI key management** (dev brief) | Foundation — key generation and storage that this builds on. |
| **Key discovery and public registry** (dev brief) | Foundation — how users find each other's keys. |
| **Chain of trust and key graphs** (architecture) | The trust graph that the pod queries for authorisation decisions. The revocation mechanism that makes pod-mediated access work. |
| **Service Worker trust anchor** (AppSec research) | The client-side integrity layer. When combined with pod-mediated encryption, provides both content integrity (Service Worker) and content confidentiality (pod re-encryption). |
| **Investor PKI and Claude integration** (business incident) | The business driver. The investor's data room use case is what this architecture serves. |

---

## What This Does NOT Solve

Being explicit about limitations:

| Limitation | Why |
|---|---|
| **Already-decrypted content** | Once a user decrypts and downloads a document, we can't revoke that. Screenshots, copy-paste, photos of screens — physical access is uncontrollable. The pod architecture limits exposure to documents actually accessed, but can't un-access them. |
| **Pod compromise** | If the pod's private key is extracted, the attacker can potentially decrypt stored content — but ONLY content they can also obtain from the server. Pod-only compromise is containable: detection, rate limiting, budget controls, and rapid key rotation bound the blast radius. The pod is still the most critical component and must be hardened, but compromise is an incident not a catastrophe. See "Maximum Damage Model" above for the full analysis and response protocol. |
| **Online requirement** | The pod must be available for every access request. If the pod is down, no one can decrypt anything. This is a feature (no offline access without authorisation check) and a risk (availability dependency). |
| **Latency** | Every access request involves: server → pod (decrypt, re-encrypt) → user. Adds latency compared to direct PKI. For large files, this could be noticeable. |
| **Cost** | Running a secure enclave (Nitro, HSM) has ongoing infrastructure cost. Needs to be factored into pricing for pod-mediated data rooms. |

---

## Implementation Roadmap (When Triggered by Customer Demand)

| Phase | What | Depends On |
|---|---|---|
| 1 | Design pod API (decrypt + re-encrypt interface) | Key management MVP (done), trust graph (in progress) |
| 2 | Prototype with separate AWS account (Lambda in isolated account) | Phase 1 |
| 3 | Integrate with trust graph for authorisation checks | Chain-of-trust architecture |
| 4 | Implement audit trail (hash-chained access log) | Phase 2 |
| 5 | Evaluate Nitro Enclaves for production hardening | Phase 2 working |
| 6 | Security review: pod threat model, attestation, key management | Phase 3 |
| 7 | Client-side mode selector (Mode 1: Direct PKI / Mode 2: Pod-Mediated) | Phase 2 + UI work |

---

This document is released under the Creative Commons Attribution 4.0 International licence (CC BY 4.0). You are free to share and adapt this material for any purpose, including commercially, as long as you give appropriate credit.
