# Architecture: GitHub-as-Store and Ephemeral Compute

**version** v0.5.10  
**date** 21 Feb 2026  
**from** Human (project lead)  
**to** Architect (lead), Developer, DevOps  
**type** Architecture brief — data room infrastructure  

---

## Two Storage Classes

All data in the system belongs to one of two classes:

| Property | Persistent (GitHub) | Ephemeral (S3) |
|---|---|---|
| **What's stored** | Configuration, directory, branding, logos, menu structures, persona definitions, persistent documents | Encrypted file transfers, messages, temporary content |
| **Durability** | Permanent — version-controlled, auditable, recoverable | Disposable — always has a TTL (hour, day, week, month, delete-on-read) |
| **Encryption at rest** | Cleartext in GitHub (owner's choice to make repo public or private). Private keys stored in GitHub Secrets, never in the repo. | Always encrypted. All patterns from PKI architecture apply. |
| **Encryption in SG/Send** | All GitHub data is encrypted when synced to S3/SG/Send | Already encrypted at upload |
| **Source of truth** | GitHub IS the source of truth | S3 is a cache. If deleted, no loss — content was ephemeral by design. |
| **Version control** | Full git history — every change tracked, attributable, reversible | No versioning. Content appears and expires. |
| **Who can edit** | Repo owners (via git), CI/CD pipelines, future: SG/Send UI with write-back | Users via SG/Send UI (upload, send message) |

### Why GitHub

S3 should not be considered a trusted, durable data store for configuration and structure. S3 buckets can be deleted, misconfigured, or compromised. GitHub solves this:

- **Version control**: every change is a commit with attribution and history
- **Collaboration**: multiple people can edit configuration (PRs, reviews)
- **CI/CD**: GitHub Actions can trigger sync to S3 on every commit
- **Portability**: not locked to AWS. The repo works with any deployment target.
- **Familiarity**: companies already use GitHub. Moving from email to GitHub as a data store is a massive upgrade in auditability and control.
- **Works with GitLab, Bitbucket, etc.**: the pattern isn't GitHub-specific. Any git host works.

### Key Principle

When data moves from GitHub to S3, it is **always encrypted.** The GitHub repo may contain cleartext (configs, directory JSON, images), but the moment that data enters SG/Send's storage layer, it's encrypted. The repo owner controls whether the repo itself is public or private — that's their choice, orthogonal to our encryption.

---

## Data Room Repo Structure

Each data room is a GitHub repository:

```
data-room-investor-x/
├── config.json              ← data room configuration (name, branding, settings)
├── branding/
│   ├── logo.png             ← customer logo
│   ├── favicon.ico
│   └── theme.json           ← colours, fonts
├── directory/
│   ├── dinis-cruz.json       ← persona definition + public key reference
│   ├── alice-investor.json
│   └── bob-analyst.json
├── keys/
│   ├── dinis-cruz-boardroom.pub    ← public keys (safe to store in repo)
│   ├── alice-investor.pub
│   └── bob-analyst.pub
├── documents/                ← persistent documents (stored cleartext in repo,
│   ├── nda-template.pdf        encrypted when synced to SG/Send)
│   └── welcome-pack.md
├── menu.json                 ← navigation structure for the data room UI
└── .github/
    └── workflows/
        └── sync-to-sgsend.yml  ← GitHub Action: on push, encrypt + sync to S3
```

**Private keys are NEVER in the repo.** They go in GitHub Secrets (for CI/CD use) or exist only in browsers (for user PKI keys).

---

## The Sync Pipeline: GitHub → S3

```
Developer/Admin commits to repo
    │
    ▼
GitHub Action triggers (sync-to-sgsend.yml)
    │
    ├── Reads repo contents
    ├── Uses SG/Send CLI to encrypt and upload
    │   (CLI has an identity — its own key pair, stored in GitHub Secrets)
    ├── CLI encrypts each file using data room's encryption key
    ├── CLI uploads encrypted files to S3 via SG/Send API
    ├── CLI updates index files (Obj_Id references, directory mappings)
    │
    ▼
S3 now contains encrypted, up-to-date copy of repo contents
Data room instance serves from S3 (or local copy of S3 data)
```

### The SG/Send CLI

The CLI is the same tool needed for Claude integration (v0.4.12). It's a command-line tool that:

- Authenticates to SG/Send with an API key / identity
- Encrypts files using specified keys (symmetric or PKI)
- Uploads encrypted content via the SG/Send API
- Downloads and decrypts content
- Syncs a directory of files (for the GitHub → S3 pipeline)

The CLI is invoked by GitHub Actions, by Claude/LLM skills, and by developers directly.

---

## Ephemeral Compute: EC2 On-Demand Data Rooms

### The Concept

Data rooms don't run 24/7. They spin up when someone accesses them and shut down when idle. The infrastructure exists only when it's being used. Cost when idle: zero (just DNS + S3 storage).

### The Architecture

```
                    ┌─────────────┐
                    │  CloudFront │
                    │  / Route53  │
                    │             │
                    │  investor-x │
                    │  .send      │
                    │  .sgraph.ai │
                    └──────┬──────┘
                           │
                    ┌──────┴──────┐
                    │   Is EC2    │
                    │  instance   │
                    │   alive?    │
                    └──────┬──────┘
                     │           │
                    YES          NO
                     │           │
                     ▼           ▼
              ┌──────────┐  ┌──────────────┐
              │  Route   │  │   Lambda     │
              │  traffic │  │  Orchestrator│
              │  to EC2  │  │              │
              │  instance│  │  1. Show     │
              └──────────┘  │     holding  │
                            │     page     │
                            │  2. Boot EC2 │
                            │     from AMI │
                            │  3. Push     │
                            │     config   │
                            │  4. Route    │
                            │     traffic  │
                            └──────────────┘
```

### The Boot Sequence (Lambda Orchestrator)

The Lambda function is a state machine. Each request from the holding page checks the current state and advances:

```
State 1: NO_INSTANCE
  │
  ├── Action: Create EC2 instance from AMI
  ├── Action: Generate admin access token
  ├── Action: Pass admin token as environment variable
  ├── Response: Show holding page — "Booting your data room..."
  │
  ▼
State 2: BOOTING (EC2 starting, ~30-50 seconds)
  │
  ├── Action: Poll EC2 instance health check
  ├── Response: Show holding page — "Starting up..." (auto-refresh)
  │
  ▼
State 3: RUNNING_VANILLA (EC2 up, no data loaded)
  │
  ├── Action: Lambda pushes config to EC2 via admin API:
  │   ├── Copy S3 encrypted files to EC2 instance
  │   ├── Push directory/persona data
  │   ├── Push branding assets
  │   └── Push menu structure
  ├── Response: Show holding page — "Loading your data room..."
  │
  ▼
State 4: READY
  │
  ├── Action: Update CloudFront/Route53 to route traffic to EC2
  ├── Response: Redirect user to live data room
  │
  ▼
State 5: ACTIVE (serving requests)
  │
  ├── Monitor: idle timeout (no requests for N minutes)
  │
  ▼
State 6: SHUTTING_DOWN
  │
  ├── Action: Sync any new ephemeral data back to S3 (encrypted)
  ├── Action: Terminate EC2 instance
  ├── Action: Update routing to point back to Lambda
  │
  ▼
State 1: NO_INSTANCE (ready for next access)
```

### EC2 Instance Security

The EC2 instance is locked down to the absolute minimum:

| Property | Setting |
|---|---|
| **Inbound** | Port 443 only (HTTPS). Nothing else. |
| **Outbound/Egress** | None. Fully isolated. No internet access, no API calls out. |
| **Storage** | Local instance storage only. No EBS volumes. No S3 access from the instance. |
| **Data loading** | Lambda pushes data TO the instance via the admin API. The instance never pulls. |
| **Admin access** | One-time admin token passed as environment variable on boot. Can be deleted after initial configuration. |
| **SSH** | Disabled. No shell access. |
| **IAM role** | None, or minimal (no AWS API access). |

The instance is a sealed box. Data goes in via the admin API. Responses go out via port 443. Nothing else.

### Why Not Lambda for Everything?

Lambda can't guarantee you hit the same function instance. A data room needs state (the loaded directory, the in-memory file system, the session). An EC2 instance provides stable, stateful compute. Lambda provides the orchestration layer.

Future option: containers (ECS Fargate, Cloud Run) could replace EC2 for faster startup and simpler management. The architecture supports this — swap the AMI boot for a container start.

---

## The Data Room as Running Instance

Once booted, the EC2 instance runs a standard SG/Send server (FastAPI):

```
EC2 Instance (data room: investor-x)
│
├── FastAPI server (port 443)
│   ├── Serves the data room UI (HTML/JS/CSS from branding config)
│   ├── Serves encrypted files (from local storage, loaded from S3)
│   ├── Handles PKI operations (verify user keys, encrypt/decrypt)
│   ├── Manages the directory (personas, public keys)
│   └── Handles messaging (encrypted messages between users)
│
├── Local storage (in-memory or instance storage)
│   ├── Memory-FS for file structure (nested folders, metadata as Obj_Ids)
│   ├── Encrypted file blobs (copied from S3 on boot)
│   └── Ephemeral messages (created during session, synced to S3 on shutdown)
│
└── No external access
    ├── No internet
    ├── No AWS API
    └── No S3 direct access
```

The server structure uses Memory-FS for the in-memory file system. Nested folders are supported natively. All data on the server is encrypted blobs and Obj_Ids — the server sees no plaintext, no strings, no metadata.

---

## Data Flow Summary

```
PERSISTENT DATA (GitHub → S3 → EC2):

  GitHub repo          CI/CD pipeline         S3 bucket          EC2 instance
  (cleartext)    ───▶  (SG/Send CLI)   ───▶  (encrypted)  ───▶  (encrypted,
  configs,              encrypts +             blobs +            local copy)
  directory,            uploads via API        Obj_Id index
  branding,
  documents

EPHEMERAL DATA (User → EC2 → S3):

  User browser         EC2 instance           S3 bucket
  (PKI encrypt)  ───▶  (stores encrypted  ──▶ (backup,
  upload file,          blob in memory)        TTL-based,
  send message                                 ephemeral)

  On EC2 shutdown: ephemeral data synced to S3 (encrypted)
  On EC2 boot: ephemeral data loaded from S3
  On TTL expiry: S3 deletes the data. It's gone.
```

---

## DNS and Routing

Each data room gets a subdomain:

```
investor-x.send.sgraph.ai  →  CloudFront distribution
                               │
                               ├── EC2 alive? → route to EC2 instance
                               └── EC2 down?  → route to Lambda (holding page + boot)
```

**DevOps**: the DNS entry and CloudFront distribution are created when a data room is provisioned. This can be automated via the fleet management API (see data room UX brief).

---

## Fleet Management API

All data room operations are API-first. The admin UI is a convenience layer on top.

| Endpoint | Method | Purpose |
|---|---|---|
| `POST /api/fleet/rooms` | POST | Create a new data room (provisions DNS, CloudFront, links GitHub repo) |
| `GET /api/fleet/rooms` | GET | List all data rooms and their status |
| `GET /api/fleet/rooms/{id}` | GET | Get data room status (running, stopped, booting) |
| `POST /api/fleet/rooms/{id}/start` | POST | Boot the EC2 instance for a data room |
| `POST /api/fleet/rooms/{id}/stop` | POST | Shutdown the EC2 instance (sync ephemeral data first) |
| `DELETE /api/fleet/rooms/{id}` | DELETE | Decommission a data room (terminate instance, clean up DNS) |
| `POST /api/fleet/rooms/{id}/sync` | POST | Trigger a GitHub → S3 sync for a data room |
| `GET /api/fleet/rooms/{id}/logs` | GET | Access logs for a data room |

---

## Signed Commits (Future — Customer Demand)

When the SG/Send UI gains write-back capability (editing config, adding personas, uploading persistent documents), changes committed to the GitHub repo can be **signed with the user's PKI key**. The git commit is signed by the person who made the change, using the same key that identifies them in the data room.

This provides cryptographic attribution: every change to the data room's configuration is traceable to a specific authenticated identity. Git's existing signature verification infrastructure supports this.

Not for immediate implementation — flagged for when write-back is built.

---

## Cost Model

For the Accountant:

| Component | Cost Driver | Estimate Needed |
|---|---|---|
| GitHub repo (private) | Per-repo (free on GitHub for small teams, GitHub Enterprise for large) | Varies by plan |
| S3 storage | Per-GB stored × retention period | Measure per data room |
| EC2 compute | Per-hour running (instance type TBD — t3.micro for small, t3.medium for larger) | Measure boot time + active time |
| Lambda orchestrator | Per-invocation (minimal — only during boot/shutdown) | Negligible |
| CloudFront | Per-request + per-GB transferred | Measure per data room |
| DNS (Route53) | Per-hosted zone + per-query | ~$0.50/month per data room |

**Key metric**: cost per data room per month at different usage levels (idle, light, active). This directly informs pricing.

---

This document is released under the Creative Commons Attribution 4.0 International licence (CC BY 4.0). You are free to share and adapt this material for any purpose, including commercially, as long as you give appropriate credit.
