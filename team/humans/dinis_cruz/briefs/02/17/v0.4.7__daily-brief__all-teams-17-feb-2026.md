# Daily Brief: 17 February 2026 â€” Security Review and User Feedback

**version** v0.4.7  
**date** 17 Feb 2026  
**from** Human (project lead)  
**to** All teams â€” Explorer and Villager via Conductors  
**status** P1 INCIDENT â€” trigger incident response protocol  
**product version at time of review** v0.4.7 (16 February 2026)  

---

## Incident Classification

We are handling this as a **P1 incident** â€” not because any individual vulnerability is P1 (none of them are â€” see reclassification below), but because:

- This is our **first external security disclosure** and we want to set the standard for how we handle them
- The report is comprehensive (29 findings) and deserves a thorough, structured response
- The reporter is a key stakeholder who used our product to deliver the report â€” we owe them a professional response
- This is an opportunity to prove our incident response process works

**Important note on severity reclassification**: the reviewer used their own P0â€“P3 severity scale, which is reasonable for a security review. However, our internal incident classification uses a business-impact scale where P0 means "major crisis â€” shut down everything," P1 means "major incident with real major customer impact," and P2 means "significant incident with some customer impact." By that measure, none of these findings are P0, P1, or P2 â€” there is no customer data at risk, no active exploitation, and the zero-knowledge model holds. We have reclassified all findings using our internal scale (P3â€“P8) throughout this document.

**Known vs Unknown risks**: our classification of each finding also depends on **whether we already knew about it**. Some of these issues may already have been identified, documented, and had their risk accepted. Others may be genuinely new â€” unknowns we missed. This distinction matters:

- **Known / risk accepted**: the issue was previously identified, assessed, and a decision was made to accept the risk (e.g., for MVP scope, or because mitigating factors exist). These need their risk acceptance reviewed and confirmed, but they're not process failures.
- **Unknown / newly discovered**: the issue was not previously identified. These are more concerning because they indicate a gap in our security review process. For each unknown, we need to look at the **2nd and 3rd stories** (as described in our incident playbooks): why did we miss this? What process, review, or check should have caught it? What systemic change prevents similar misses in the future?

The AppSec and GRC roles should classify each finding as known/accepted or unknown, and for the unknowns, conduct a brief root cause analysis.

**GRC action required**: this reclassification highlights that we need a formally defined vulnerability classification framework. The GRC role should define our severity scale (P0â€“P10), with clear criteria for each level, and document the mapping between external security review severity ratings and our internal business-impact scale. This framework should be published and used consistently across all future vulnerability reports.

---

## Executive Summary

### What Happened

Two beta users provided feedback on SG/Send. One conducted a full-stack security code review; the other tested the product and requested features. Both confirm the product works. The security review validates our encryption model.

### By the Numbers

| Metric | Value |
|---|---|
| **Users who provided feedback** | 2 |
| **Security findings reported** | 29 |
| **Findings with crisis-level impact (our P0)** | 0 |
| **Findings with real customer impact (our P1/P2)** | 0 |
| **Findings to fix before production (our P3)** | 3 |
| **Defence-in-depth improvements (our P4â€“P5)** | 11 |
| **Low-priority hardening (our P6â€“P8)** | 15 |
| **Feature suggestions from reviewer** | 10 |
| **Feature requests from beta tester** | 3 |
| **Feature suggestions already on our roadmap** | 12 of 13 |
| **Encryption model validated** | Yes â€” AES-256-GCM correct, server never sees plaintext or keys |
| **Data compromised** | None |
| **Zero-knowledge model holds** | Yes |

### What Was Submitted

| Source | What They Did | What They Found | Business Impact |
|---|---|---|---|
| **User A** (security reviewer) | Full-stack code review of open-source codebase. Reviewed crypto, backend, admin, CI/CD across all IFD versions. **Delivered report via SG/Send.** | Crypto is sound. 29 findings: auth/access control gaps, client-side data handling, supply chain hygiene, defence-in-depth improvements. 10 feature suggestions. | No customer impact. No data at risk. Fixes needed before production launch. Multiple findings align with existing roadmap. |
| **User B** (beta tester) | Tested the product end-to-end. Confirmed it works. | 3 feature requests: expiring links, user-defined encryption keys, certificate-based encryption. | All 3 already on roadmap. Validates product direction. Positive confirmation ("worked as described"). |

### Product Validation

User A's follow-up conversation after delivering the report is significant:

> **Human**: "Love it that you use SGraph Send to share this data. It's quite a nice use case for it right?"
>
> **User A**: "Absolutely. I can't tell you how many times I've needed something like this. I mean if you use Signal, Proton, or whatever else, the other party needs the same tech, which is not always the case, right?"

This is a **massive validation** â€” not just of SG/Send working, but of the core value proposition. The pain point is real: encrypted communication tools require both parties to use the same platform. SG/Send doesn't. The recipient just needs a browser and the decryption key. No account, no app, no sign-up.

The Ambassador and Sherpa should be building messaging around this exact insight. This is what we lead with.

---

# Section 1: User Feedback

## User A: Security Review

### Context

- **Invitation**: direct LinkedIn message asking to test-drive send.sgraph.ai with access token `[REDACTED]`
- **Response**: full-stack security review with findings delivered as encrypted text via SG/Send
- **Follow-up**: confirmed the use case ("I can't tell you how many times I've needed something like this")
- **Reviewer profile**: security professional with code review expertise
- **Scope**: full stack â€” crypto, backend, admin, CI/CD across all IFD versions (v0.1.0 through v0.1.6)
- **Stakeholder status**: key stakeholder â€” we report back with resolution status

### Overall Assessment

**Crypto is correct.** AES-256-GCM via Web Crypto API. Server never sees plaintext or keys. The zero-knowledge model holds.

**Findings by reviewer's original severity**: 0 P0 | 5 P1 | 11 P2 | 13 P3

**Findings reclassified to our internal scale**: 0 P0 | 0 P1 | 0 P2 | 3 P3 | 8 P4â€“P5 | 15 P6â€“P8 | 3 non-vuln (test gaps, features)

### Our Severity Scale

| Our Rating | Meaning | Reviewer Equivalent |
|---|---|---|
| **P0** | Major crisis â€” shut down everything. Pull the plug, stop all operations. Active exploitation with confirmed data breach or complete system compromise. | (none in this review) |
| **P1** | Major incident, real major customer impact, active exploitation | (none â€” would be reviewer's P0) |
| **P2** | Significant incident, some customer impact | (none) |
| **P3** | Must fix before production. No current customer impact but would have impact with real users/data. | Reviewer's P1 #4, #5; partially #1 |
| **P4** | Should fix. Real vulnerability but low current risk due to no sensitive data, low traffic, or mitigating factors. | Reviewer's P1 #2, #3; P2 #9, #10 |
| **P5** | Fix when convenient. Defence-in-depth improvement, unlikely preconditions, or compound dependencies. | Reviewer's P2 #6â€“8, #13â€“15 |
| **P6** | Minor improvement. Good security practice but very low exploitability or minor impact. | Reviewer's P2 #11, #20, #23; P3 #12, #18, #19, #26, #28 |
| **P7** | Cosmetic or theoretical. Real issue on paper but negligible practical impact. | Reviewer's P3 #16, #17, #21, #22, #25, #27, #29 |
| **P8â€“P10** | Negligible. No meaningful security impact. | Reviewer's P3 #24 |

### P3 â€” Must Fix Before Production (3 findings)

| Reviewer # | Finding | Location | Fix | Why P3 |
|---|---|---|---|---|
| 4 | **Token validation fails open** â€” missing env var silently skips all auth. Silent exception catch in app setup also results in open access. | `Admin__Service__Client__Setup.py:35-36`, `Fast_API__SGraph__App__Send__User.py:54-55` | Raise exception at startup if admin config missing in production. Never silently skip auth. | Silent auth bypass is the most dangerous class of bug. No impact today (no sensitive data), but catastrophic if this reaches production with real users. |
| 5 | **Plaintext in localStorage** â€” decrypted text (â‰¤50KB) and access tokens stored as plaintext. Persists across sessions. Accessible to any XSS. | `send-download.js:437`, `api-client.js:26-27` | Make history opt-in. Use `sessionStorage` or encrypt stored content. | Directly undermines the zero-knowledge promise. Combined with no CSP (#10), an XSS could exfiltrate decryption history. |
| 1 | **Token auth bypass via race condition** â€” non-atomic read-modify-write on token usage. Concurrent Lambda invocations can bypass usage limits. | `Service__Tokens.py:48-65` | Atomic increment via DynamoDB `ADD` or S3 conditional write. | Auth bypass with realistic preconditions (concurrent requests are normal in Lambda). Lower urgency because current traffic is low and no sensitive data exists, but the pattern must be fixed. |

### P4 â€” Should Fix (5 findings)

| Reviewer # | Finding | Location | Fix | Why P4 |
|---|---|---|---|---|
| 2 | **GitHub Actions pinned to `@dev`** â€” 4 actions use mutable branch ref. | `.github/workflows/ci-pipeline.yml:71,84,98,100` | Pin to specific commit SHA | Supply chain risk, but the repo is our own OWASP project. Quick fix. |
| 3 | **No application-level upload size enforcement** â€” no size check in code. However, Lambda has a 6MB payload limit providing an infrastructure-level cap. The client-side 5MB limit is a UX decision, not a security feature. **Research needed**: when we move to pre-signed S3 URLs, can we enforce max upload size? | `Routes__Transfers.py:79` | Current: low urgency (Lambda 6MB limit exists). Pre-signed URLs: research S3 size constraints. | Infrastructure limit exists today. Becomes P3 when architecture changes to direct S3 uploads. |
| 9 | **Decryption key visible during download** â€” URL hash not cleared until after download/decrypt complete. | `send-download.js` (all versions) | Clear hash immediately after extracting key, before network requests | Narrow window, but principle matters for a zero-knowledge app. One-line fix. |
| 10 | **No CSP on any page** â€” all files contain inline scripts. No XSS mitigation. | All HTML files | Move inline JS to external files, add nonce-based CSP | Amplifier for #5. Important for zero-knowledge app. Medium effort. |
| 14 | **Path injection in admin cache browser** â€” `../` traversal across cache namespaces. | `Routes__Cache__Browser.py:26-35` | Validate paths, reject traversal sequences | Requires admin API key (high precondition), but should be sanitised. |

### P5 â€” Defence-in-Depth (6 findings)

| Reviewer # | Finding | Location | Fix | Why P5 |
|---|---|---|---|---|
| 6 | **Sender IP hardcoded to empty string** â€” audit trail broken. | `Routes__Transfers.py:71` | See Step 6: remove IP hashing, research browser-agent fingerprinting instead. DPO + AppSec + Sherpa to review. | DPO prefers no IPs. Needs deliberate decision. Research browser fingerprinting alternative. |
| 7 | **IP hash unsalted** â€” README claims daily salt, none exists. Blocked behind #6. | `Transfer__Service.py:134-137` | Remove dead hashing code. Fix README immediately (GRC). | Compound dependency on #6. README accuracy is the primary GRC concern. |
| 8 | **S3 bucket missing public access block** | `Storage_FS__S3.py:25` | Add `put_public_access_block()` | AWS defaults since April 2023 mitigate. Defence-in-depth. |
| 13 | **No rate limiting** on any endpoint | All routes | Add `slowapi` or Lambda concurrency limit | Lambda provides partial natural throttle. Cost risk, not data risk. |
| 15 | **All dependencies use wildcard `"*"` versions** | `pyproject.toml:13-17` | Constrain to specific major versions | `poetry.lock` mitigates. Risk is `poetry update` without review. |
| 23 | **Race condition on upload/complete** â€” latent with in-memory; exploitable with S3 backend. | `Transfer__Service.py:66-77` | S3 conditional write or DynamoDB condition expression | Latent â€” only exploitable when we move to S3 storage backend. |

### P6 â€” Minor Improvements (7 findings)

| Reviewer # | Finding | Location | Why P6 |
|---|---|---|---|
| 11 | **Transfer ID only 48-bit entropy** â€” collision at ~19.7M transfers. | `Transfer__Service.py:46` | We're nowhere near 19.7M transfers. Fix when convenient. |
| 12 | **No security headers** â€” missing Referrer-Policy, HSTS, X-Frame-Options. | All responses | Standard hardening. Hash fragments not leaked via Referer per HTTP spec. |
| 18 | **Filename from SGMETA not sanitised** | `send-download.js:377-378, 467` | Browser `download` attribute provides partial sanitisation. |
| 19 | **LaunchList form on download page** â€” third-party form on decryption page. | `download.html` (all versions) | v0.1.1+ removed external JS. Form-only risk is low. |
| 20 | **Transfer existence oracle** â€” unauthenticated info endpoint leaks metadata. | `Routes__Transfers.py:112-118` | Transfer ID entropy makes enumeration impractical. Metadata only. |
| 26 | **Silent exception swallowing** at security boundaries | `Routes__Transfers.py:107-108`, `Middleware__Analytics.py:73` | Operational/forensic gap. Not directly exploitable. |
| 28 | **Static assets served from Python Lambda** â€” same process as API. | Lambda architecture | Architectural concern. Requires dependency compromise first. |

### P7 â€” Cosmetic / Theoretical (7 findings)

| Reviewer # | Finding | Location | Why P7 |
|---|---|---|---|
| 16 | **Plaintext file size + MIME type sent to server** | `api-client.js:51-59` | 28-byte overhead difference is negligible. Reviewer agrees. |
| 17 | **SGMETA integer overflow** | `send-download.js:171-172` | Requires crafting payload inside encrypted content (needs the key). JS memory-safe. |
| 21 | **Unbounded events array** | `Transfer__Service.py:127` | Requires ~100K downloads to impact performance. |
| 22 | **Upload size never validated** â€” declared vs actual never compared. | `Routes__Transfers.py`, `Transfer__Service.py` | No direct security impact from size mismatch. |
| 25 | **Token status leaked in error messages** | `Routes__Transfers.py:46` | Minor info disclosure. Doesn't enable further attack. |
| 27 | **Unvalidated token_name in URL path** | `Admin__Service__Client.py:18,24` | `Safe_Str__Id` likely restricts to URL-safe chars already. |
| 29 | **No SRI on external scripts** | v0.1.0 only | v0.1.6 has no external JS. Historical only. |

### P8 â€” Negligible (1 finding)

| Reviewer # | Finding | Location | Why P8 |
|---|---|---|---|
| 24 | **Zero-byte payload accepted** | `Routes__Transfers.py:79` | Edge case. Minimal impact. |

### Test Gaps Identified

| Gap | Our Priority |
|---|---|
| No test verifies plaintext never reaches server | P3 â€” critical for zero-knowledge claim |
| Tests use literal strings, not real ciphertext | P4 |
| No Playwright E2E for encryption round-trip | P4 |
| No auth edge cases (expired/revoked/exhausted tokens) | P4 |
| No concurrent request tests | P4 |
| No CORS verification tests | P5 |
| No framework behaviour tests (error format, input validation) | P6 |
| No S3 integration tests (LocalStack) | P6 |

### Functionality Suggestions (10)

| Priority | Feature | Approach |
|---|---|---|
| **High** | **Transfer expiration (TTL)** | `expires_at` in metadata. Sender chooses duration (1h, 24h, 7d, 30d). Return 410 Gone if expired. S3 lifecycle for cleanup. `EXPIRED` status exists in code but is never set. |
| **High** | **Orphan cleanup** | Auto-expire `PENDING` transfers after 1 hour. Check on read or periodic Lambda. |
| **High** | **Download limits** | Optional `max_downloads` field (1, 5, 10, unlimited). Enforce in download endpoint. Combine with TTL for "burn after reading" (`max_downloads=1, ttl=24h`). |
| **High** | **Sender-side deletion** | Return `delete_secret` at upload. Store SHA-256 hash in metadata. Possession = proof of ownership. Firefox Send approach. |
| **Medium** | **Browse own files** | Client-side localStorage manifest after each upload. New `<send-my-files>` web component. Zero server changes. Depends on localStorage fix. |
| **Medium** | **Sender status page** | Return `status_url` with secret at upload. Shows download count, time remaining, delete option. Secret = proof of sender identity. |
| **Medium** | **Exportable encrypted manifest** | Encrypt localStorage upload list with user passphrase (AES-256-GCM). Export/import as `.enc` file. Cross-device, zero server trust. |
| **Low** | **Token-scoped file listing** | `GET /tokens/{name}/transfers` (admin-authenticated). `token_name` already stored via `token_use()`. Infrastructure partially built. |
| **Low** | **Password-protected downloads** | Optional `bcrypt(password)` in metadata. Two-factor: something you have (key) + something you know (password). |
| **Low** | **Download notifications** | Webhook or email on first download. Minimal payload â€” event only, no content or key. Privacy consideration for stored email. |

### UX Observation from User A's Report Delivery

The security report was sent as markdown text via SG/Send. It displayed as raw markdown (visible in screenshot â€” `**bold**` markers, `#` headers shown as literal text). **Markdown-to-HTML rendering on the decryption page** would have made this significantly more readable. This is a quick UX win.

---

## User B: Feature Requests

### Context

- **Invitation**: WhatsApp community group with a dedicated access token
- **Response**: tested the product, confirmed it works, provided three feature requests
- **Stakeholder status**: beta user â€” Sherpa to manage the relationship, track feedback, follow up

### Feedback

User B confirmed: **"Tried it this morning â€” worked as described."** Then provided three requests:

| # | Request | What They Want |
|---|---|---|
| 1 | **Expiring links** | Links that auto-expire after a set time. Referenced SharePoint as a comparable. |
| 2 | **User-defined encryption key** | Ability to set their own key so regular sharing partners don't need a new key each time. Persistent key for a relationship, not per-transfer. |
| 3 | **Certificate-based encryption** | Use certificate files to control read/write access. Effectively PKI â€” share a public cert, only the cert holder can decrypt. |

### Human's Response to User B

Already acknowledged the feedback and confirmed all three are on the roadmap:
1. Auto-expiring messages/storage
2. Key management for recurring sharing relationships
3. PKI and certificate support

### Sherpa Action Required

User B is a beta user from a community channel. The Sherpa should:
- Log this as the first community-sourced feedback
- Track the three feature requests against the roadmap
- Follow up when features ship (User B should be notified when expiring links go live â€” it's their #1 request)
- Maintain the relationship â€” this user tested, confirmed it works, and gave constructive feedback. That's exactly the beta user profile we want.

---

# Section 2: First Analysis

**Important note**: this is an initial assessment only. Every finding needs to be fully analysed, researched, and reviewed by the relevant agents (AppSec, DPO, Developer, Architect, DevOps, GRC). This first pass identifies the key themes, validates the severity ratings, and highlights the most critical items.

## Headline: The Zero-Knowledge Model Holds

The reviewer confirmed: **AES-256-GCM is correct, Web Crypto API is used properly, the server never sees plaintext or keys.** This is the most important finding. The foundational security promise of SG/Send â€” that we cannot read your data â€” is validated by an independent external reviewer. No P0 vulnerabilities exist. No customer data at risk.

## Theme 1: Auth and Access Control (P3 #1, #4; P4 #3)

The most important findings cluster around authentication:

- **Fails open** (#4, our P3) â€” the most concerning pattern. If config is missing, auth is silently skipped. Must fix before production.
- **Race condition on tokens** (#1, our P3) â€” concurrent requests can bypass usage limits. Real bug, but low urgency with current traffic. Must fix before production.
- **No application-level upload size limit** (#3, our P4) â€” the Lambda 6MB payload limit provides an infrastructure cap today. Becomes more important when we move to pre-signed S3 URLs. Research task, not an immediate fix.

**Assessment**: none of these are exploitable in a way that compromises user data today (the server only has encrypted bytes even with auth bypass). They become critical as we approach production with real users.

## Theme 2: Client-Side Data Exposure (P3 #5; P4 #9, #10)

These three findings form a chain:

- Decrypted content and tokens in plaintext localStorage (#5, our P3)
- No Content Security Policy (#10, our P4)
- Decryption key visible in URL during download (#9, our P4)

Together: an XSS attack could exfiltrate decrypted content history AND authentication tokens, and the lack of CSP means no XSS mitigation. This is the one area where the zero-knowledge guarantee is weakened â€” not by the crypto or the server, but by client-side data handling after decryption.

**Assessment**: highest-priority theme. Fix #5, #10, and #9 as a group â€” they're interconnected and the combined risk exceeds each individually.

## Theme 3: Supply Chain (P4 #2; P5 #15)

GitHub Actions pinned to `@dev` and wildcard dependency versions.

- The `@dev` actions are from `owasp-sbot/OSBot-GitHub-Actions` â€” our own OWASP project repo, so the risk is lower than a third-party dependency. Still should pin to SHA as best practice.
- `poetry.lock` mitigates the wildcard versions for reproducible builds. The risk is `poetry update` without review.

**Assessment**: real but manageable. Pin actions to SHA, constrain dependency versions. Both are quick fixes.

## Theme 4: IP Address Handling (P5 #6, #7)

Directly relevant to the DPO evidence pack:

- Finding #6: sender IP is **hardcoded to empty string** â€” code has a TODO acknowledging it
- Finding #7: README claims "SHA-256 with daily rotating salt" but no salt exists

The DPO's position (no IP addresses stored) is actually enforced â€” but accidentally, via a hardcoded empty string rather than by design. The README's claim about salted hashing is inaccurate.

**Assessment**: needs a deliberate decision (see Section 3, Step 6). The recommendation is to remove IP hashing entirely and research browser-agent-based fingerprinting as a privacy-respecting alternative. The current state â€” accidentally not storing IPs while claiming to hash them â€” is the worst of both worlds. The Sherpa should map the real use case for audit trail data before we build anything.

## Theme 5: Metadata Leakage (P6 #20; P7 #16, #25)

Several places where the server learns more than it needs to: transfer existence oracle, plaintext file size/MIME (though negligible), token status in error messages.

**Assessment**: defence-in-depth improvements, not urgent. The info endpoint should be authenticated or rate-limited eventually.

## Theme 6: Functionality Suggestions Align with Roadmap

The reviewer's suggestions map almost exactly to features already planned:

| Reviewer Suggestion | Already Planned? | Where |
|---|---|---|
| Transfer expiration (TTL) | Yes | Investor doc "coming soon", User B request #1 |
| Download limits | Yes | Investor doc "coming soon" (one-time access) |
| Sender-side deletion | Yes | Not explicitly, but implied by data room management |
| Orphan cleanup | Partially | Archive/cleanup in SA pipeline, but not for pending transfers |
| Browse own files | Yes | Investor doc "coming soon" (sender status page concept) |
| Sender status page | Yes | Investor doc "coming soon" (read receipts) |
| Exportable manifest | Yes | File transfer engine brief (transfer manifest concept) |
| Password-protected downloads | Partially | Investor doc "coming soon" (Cognito auth layer) |
| Download notifications | No | New â€” add to roadmap |
| Token-scoped file listing | Partially | Admin UI already planned |

User B's three requests also map directly:

| User B Request | Reviewer Equivalent | Roadmap Status |
|---|---|---|
| Expiring links | Transfer expiration (TTL) | Planned |
| User-defined encryption key | (not in security review) | Planned |
| Certificate-based encryption | (not in security review) | Planned â€” PKI |

12 of 13 suggestions are already on our roadmap. This is reassuring â€” we're building what users actually want.

## User A's Validation of the Core Value Proposition

Worth repeating because this is strategically important:

> "I can't tell you how many times I've needed something like this. I mean if you use Signal, Proton, or whatever else, the other party needs the same tech, which is not always the case, right?"

This captures SG/Send's primary differentiator in the user's own words: **the recipient doesn't need to install anything, create an account, or use a specific app.** They just need a browser and the key.

The Ambassador should build messaging around this exact framing. The Sherpa should track this as a validated user pain point. The investor documents should lead with this.

## UX Observation: Markdown Rendering

The security report was delivered as markdown text. The download page displayed it as raw markdown. Adding markdown-to-HTML rendering on the decryption page would be a quick, high-impact UX improvement â€” especially as users send structured text (reports, documentation, code).

---

# Section 3: Next Steps

## Step 1: Trigger P1 Incident

This is a P1 incident per our incident response protocol. Classification:

- **Incident severity**: P1 (first external security disclosure â€” handle with full process rigour)
- **Individual finding severity**: P3â€“P8 (no P1 or P2 findings by our internal business-impact scale)
- **Type**: externally reported vulnerability disclosure
- **Data impact**: none â€” zero-knowledge model validated, no sensitive data on platform
- **Disclosure status**: reporter is aware, code is open source

**Incident lead**: AppSec, supported by DPO and GRC.

## Step 2: Create the Pack of Packs

Every finding becomes its own briefing pack (folder + BRIEF.md + .issues/), following the briefing pack pattern defined in `team/humans/dinis_cruz/briefs/02/16/v0.4.4__briefs__briefing-packs-for-agents.md`. All incident data is captured in the `library/sgraph-send/incidents/` folder:

```
library/sgraph-send/incidents/2026-02-17-security-review/
â”œâ”€â”€ BRIEF.md                          # This document (the incident overview)
â”œâ”€â”€ .issues/
â”‚   â””â”€â”€ tasks.issues                  # Master task list across all findings
â”‚
â”œâ”€â”€ p3-04-token-validation-fails-open/
â”‚   â”œâ”€â”€ BRIEF.md
â”‚   â””â”€â”€ .issues/tasks.issues
â”‚
â”œâ”€â”€ p3-05-localstorage-plaintext/
â”‚   â”œâ”€â”€ BRIEF.md
â”‚   â””â”€â”€ .issues/tasks.issues
â”‚
â”œâ”€â”€ p3-01-token-race-condition/
â”‚   â”œâ”€â”€ BRIEF.md
â”‚   â””â”€â”€ .issues/tasks.issues
â”‚
â”œâ”€â”€ p4-grouped-should-fix/            # P4s grouped by theme
â”‚   â”œâ”€â”€ BRIEF.md
â”‚   â””â”€â”€ .issues/tasks.issues
â”‚
â”œâ”€â”€ p5-defence-in-depth/              # P5s grouped
â”‚   â”œâ”€â”€ BRIEF.md
â”‚   â””â”€â”€ .issues/tasks.issues
â”‚
â”œâ”€â”€ p6-p8-hardening/                  # P6â€“P8 grouped as a single improvement pack
â”‚   â”œâ”€â”€ BRIEF.md
â”‚   â””â”€â”€ .issues/tasks.issues
â”‚
â”œâ”€â”€ test-gaps/
â”‚   â”œâ”€â”€ BRIEF.md
â”‚   â””â”€â”€ .issues/tasks.issues
â”‚
â”œâ”€â”€ functionality-suggestions/
â”‚   â”œâ”€â”€ BRIEF.md
â”‚   â””â”€â”€ .issues/tasks.issues
â”‚
â””â”€â”€ user-feedback/                    # User B feedback for Sherpa
    â”œâ”€â”€ BRIEF.md
    â””â”€â”€ .issues/tasks.issues
```

## Step 3: Immediate Fixes (Next Release)

| Our Priority | Fix | Owner | Effort |
|---|---|---|---|
| **P3** | Token validation fails closed (not open) | Developer, AppSec | Small â€” add startup check |
| **P3** | localStorage: switch to sessionStorage or encrypt, make history opt-in | Developer, AppSec | Medium |
| **P3** | Token race condition: atomic increment | Developer, Architect | Medium â€” needs DynamoDB or S3 conditional write |
| **P4** | Upload size: research pre-signed URL size constraints for future architecture | Architect, DevOps | Research task |
| **P4** | GitHub Actions pin to commit SHA | DevOps | Small â€” update 4 lines in YAML |
| **P4** | Clear decryption key from URL hash immediately | Developer | Small â€” move one line of code |
| **P4** | Add Content-Security-Policy to all pages | Developer, AppSec | Medium â€” requires moving inline JS to external files |
| **Quick win** | Markdown-to-HTML rendering on decryption page â€” write a **mini markdown parser** that supports only safe subset (headings, bold, italic, lists, code blocks, tables). No arbitrary HTML passthrough. Render the output inside an **iframe with `sandbox="allow-same-origin"` and no-script** to prevent any XSS even if the parser has bugs. This is defence-in-depth: limited parser + sandboxed iframe = two layers of protection. | Developer, AppSec | Smallâ€“Medium |

## Step 4: Stakeholder Communication

**User A (security reviewer)**:
- Acknowledge receipt â€” done (via SG/Send: "Love it that you use SGraph Send to share this data")
- Share this brief: "does this capture it all?"
- Report back with fix status as items are resolved
- Credit them appropriately (with their consent) when publishing about this
- Treat as a key stakeholder â€” invite to review fixes when deployed

**User B (beta tester)**:
- Sherpa takes ownership of this relationship
- Log the three feature requests against the roadmap
- Notify when expiring links ship (their #1 request)
- Maintain ongoing relationship â€” invite to test new features
- Their positive feedback ("worked as described") is valuable social proof

## Step 5: DPO/AppSec/GRC Evidence Update

This incident is live evidence for the DPO/AppSec/GRC evidence pack (`v0.4.3__briefs__dpo-appsec-grc-evidence-pack.md`):

- **DPO**: the IP address findings (#6, #7) directly validate the DPO's position on no IP storage â€” and reveal the implementation is accidental rather than deliberate. The DPO should make a formal decision.
- **AppSec**: the entire security review validates having AppSec in the team â€” every finding will be tracked through the AppSec role's process.
- **GRC**: the README claims ("SHA-256 with daily rotating salt") don't match reality. Public claims must match implementation. Also: **define the vulnerability classification framework** (P0â€“P10 with clear business-impact criteria). **Classify each finding** as known/accepted or unknown â€” for unknowns, conduct 2nd/3rd story analysis. **Prepare risk acceptance statements** for no-fix decisions for the human to sign off on.

## Step 6: IP Address and User Fingerprinting Decision (DPO + AppSec + Sherpa)

Current state:
- Code has IP capture infrastructure (hash function exists)
- Code hardcodes IP to empty string (never captures real IPs)
- README claims "SHA-256 with daily rotating salt" (not implemented)
- The DPO has previously said: no IP addresses

**Required decision**: remove the IP hashing approach entirely. Instead, explore **browser-agent-based user fingerprinting** as an alternative for the audit trail:

- **Option A (recommended for now)**: Don't capture IPs. Remove the dead hashing code. Update README to say "IP addresses are not captured or stored." Add a test that verifies no IP data reaches storage. This aligns with the DPO position and is the simplest path.
- **Option B (research)**: Instead of IP hashing, create a privacy-respecting user fingerprint based on the browser user agent string and other non-PII signals. This provides an audit trail ("this download came from the same browser as that download") without storing IP addresses. DPO and AppSec to review the privacy implications. Sherpa to map the real use cases â€” what do we actually need the audit trail for? What decisions does it support? Don't build it until we understand the use case.

**Either way**: fix the README immediately. The current state (claiming salted hashing that doesn't exist) is a documentation accuracy issue that GRC should not accept.

## Step 7: Public Disclosure Approach

Because SG/Send is open source and no sensitive user data exists on the platform, we can handle this in the open:

- Fix the vulnerabilities
- Document the fixes in commit messages referencing the finding numbers
- Publish a security advisory on the GitHub repo
- Credit the reviewer (with consent)
- Write it up as a case study (Journalist + Historian) â€” "How Our First Security Review Went"

This transparency is itself a marketing asset. It demonstrates:
- The open-source model works (users CAN review the code, and they DO)
- We take security reports seriously and fix them quickly
- We credit researchers and treat them as partners
- The zero-knowledge model held up to external scrutiny

## Step 8: Risk Acceptance and No-Fix Decisions

Not every finding will be fixed immediately. Some may be accepted as-is. The process:

1. **GRC classifies each finding** as: fix now, fix later, no-fix (risk accepted), or won't-fix (not applicable)
2. For no-fix decisions, GRC prepares a **risk acceptance statement** with: the finding, the risk, the mitigating factors, and the recommended acceptance period (e.g., "accept for 6 months, review again")
3. The **human (project lead) formally accepts the risk** â€” this is not a decision the agents make alone
4. All findings and their classifications are **published on a page on the docs site** â€” transparent, auditable, and accessible. This page shows: finding number, description, our severity rating, status (fixed / accepted / in progress), and date

This is the mature way to handle vulnerabilities. Not every issue needs an immediate fix. But every issue needs a deliberate decision, a documented rationale, and a public record.

## Step 9: Bug Bounty and Vulnerability Reporting Infrastructure

This first security review highlights the need for a proper vulnerability reporting programme. Tasks:

| Task | Owner | Priority |
|---|---|---|
| **Create a `security.txt`** (well-known URI) at `send.sgraph.ai/.well-known/security.txt` â€” standard format with contact info, preferred reporting method, PGP key if applicable | DevOps | P4 |
| **Create a bug bounty page** on the docs site â€” scope, rules of engagement, what's in/out, responsible disclosure policy | Ambassador, AppSec | P4 |
| **SG/Send as the reporting channel** â€” a dedicated access token (e.g., `security-report`) for submitting vulnerability reports via the platform itself. Eating our own cooking. | Developer | P4 |
| **Vulnerability / feature / bug report leaderboard** â€” public leaderboard on docs site showing who has reported issues, how many, and their severity. Start with User A and User B. For now, the reward is kudos and public recognition. | Ambassador, Designer | P5 |
| **Published vulnerability register** â€” all findings with status, severity, fix date or risk acceptance. Linked from the docs site. | GRC, Librarian | P4 |

The leaderboard and public register are transparency features that build trust with the security community. They signal: we welcome scrutiny, we track everything, and we credit the people who help us improve.

## Step 10: Firefox Send Research (Ambassador + AppSec + GRC)

User A's functionality suggestions reference the Firefox Send approach (specifically the `delete_secret` pattern for sender-side deletion). Firefox Send was a similar service that was eventually shut down.

**Ambassador task**: conduct a thorough review of Firefox Send:
- What features did it have? What worked well?
- Why was it shut down? What problems led to its closure?
- What can we learn from its lifecycle â€” both the successes and the failures?
- How does SG/Send differ architecturally and operationally?

**AppSec + GRC task**: a key reason Firefox Send was shut down was **abuse** â€” it was used to distribute malware via encrypted links that couldn't be scanned. Map out our protections:
- How do we prevent SG/Send from being used to distribute malware?
- What abuse signals can we detect without breaking zero-knowledge? (e.g., volume anomalies, token patterns, access patterns)
- What's our takedown process if abuse is reported?
- What legal/regulatory protections do we need?
- How do we balance zero-knowledge (we can't inspect content) with preventing abuse?

This is a critical research task. If we can't answer "how do you prevent abuse?", we have a business risk that's arguably larger than any of the technical vulnerabilities.

---

# Section 4: Additional Research and Ideas

The following are research tasks and ideas that emerged from this incident and the user feedback. These are not part of the incident response â€” they're future work that should be captured in the roadmap and assigned to appropriate roles.

## Secrets and 2FA in Modern Browsers

**Research task for Architect + AppSec**: investigate how modern browsers (especially Chrome) handle secrets and two-factor authentication:

- Can we leverage the Web Authentication API (WebAuthn / FIDO2) for recipient verification?
- Can we use the Credential Management API for key storage instead of localStorage?
- What browser-native secure storage is available? (e.g., the non-exportable key approach in Web Crypto API)
- Can we integrate with platform authenticators (Touch ID, Windows Hello, Android biometrics) for decryption authorisation?
- What's the state of passkey support and could passkeys replace or supplement our decryption key model?

The goal: can the browser's native security infrastructure replace or strengthen our current key management? This could eliminate the localStorage plaintext issue (#5) entirely by using browser-native secure storage.

## Chrome Extension Detection and Browser Security Assessment

**Research task for AppSec + Architect**: investigate whether it's possible to detect or warn about insecure browser configurations:

- Can we detect if Chrome extensions have permission to read the current page's DOM or network traffic? (Some extensions have `<all_urls>` permission and could read decrypted content.)
- Can we detect if the browser has developer tools open? (Potential exfiltration vector during decryption.)
- Can we check the browser's security configuration (e.g., is HTTPS enforced, is the connection secure)?
- Can we detect if the user is on a corporate network with TLS interception (MITM proxy)?

**The bigger vision**: "How can we help the user know if they are using a Chrome browser/session/network that is insecure or dangerous?" This goes beyond our app â€” it's a user safety feature. Before decryption, we could show a security checklist:

```
ðŸŸ¢ Connection: HTTPS (secure)
ðŸŸ¢ Certificate: valid, not intercepted
ðŸŸ¡ Extensions: 3 extensions with page access detected (tap to review)
ðŸŸ¢ Browser: up to date
ðŸ”´ Network: corporate proxy detected â€” your IT department may be able to inspect traffic
```

This would be a genuine differentiator â€” no other file sharing tool warns users about their browser security posture. It aligns with our philosophy: we don't just protect your data in transit and at rest, we help you understand whether your endpoint is safe.

**Note**: some of this detection is inherently limited by browser sandboxing (browsers don't expose extension lists to pages for privacy reasons). Research what IS possible, what's a best-effort heuristic, and what's impossible.

## User Fingerprinting Alternatives (from Step 6)

**Research task for DPO + AppSec + Sherpa**: beyond IP addresses, investigate privacy-respecting user identification for audit trails:

- Browser user agent fingerprinting (entropy, privacy implications, GDPR considerations)
- Client Hints API (structured, consent-based alternative to user agent strings)
- Canvas fingerprinting (highly unique but privacy-invasive â€” likely a DPO no)
- First-party device tokens (user-generated, stored locally, presented voluntarily)
- The Sherpa's key question: what's the actual use case? Who needs this audit trail and what decisions does it support? Don't build it until the use case is validated.

## Pre-Signed URL Upload Size Constraints (from Finding #3)

**Research task for Architect + DevOps**: when we move from Lambda-proxied uploads to direct S3 uploads via pre-signed URLs:

- Can pre-signed URLs enforce a maximum upload size? (S3 `Content-Length-Range` condition in the presigned POST policy)
- Can we set per-token upload limits?
- How do we handle the transition from Lambda-limited to S3-direct uploads without losing the implicit size protection?

---

## For the Conductors (Both Teams)

**Explorer team**: this is your incident. The P3 fixes are all in Explorer-territory code. The Architect reviews the race condition fixes (#1, #23). The Developer implements. AppSec validates. QA writes the missing tests. The research tasks in Section 4 (browser security, secrets/2FA, Chrome extension detection) are Explorer explorations.

**Villager team**: once fixes are in Explorer, the Villager team deploys through the production discipline pipeline (dev â†’ QA â†’ prod). The Translator should note the decryption page needs translation in all supported languages (especially relevant for the markdown rendering improvement). The Sherpa handles User B's relationship. The Ambassador leads the Firefox Send research and builds messaging around User A's validation quote.

**Both teams**: the functionality suggestions and User B's feature requests should be mapped against the existing roadmap. The Architect should sequence them â€” many are already planned (TTL, download limits, PKI). The question is: does this feedback change the priority order? GRC should classify all findings as known/accepted vs unknown, prepare risk acceptance statements for no-fix items, and publish the vulnerability register on the docs site. The bug bounty infrastructure (security.txt, reporting channel, leaderboard) should be set up before we invite more beta users.

**Ambassador**: User A's quote ("the other party needs the same tech, which is not always the case") is the core messaging. Build around it. The Firefox Send research is your task â€” understand what worked, what didn't, and why it was shut down. The Sherpa should track User A's validation as a use case pattern that applies across all personas â€” investors, corporates, individuals.

Let's handle this well. Our first security review and our first user feedback â€” both positive signals that the product is being used and taken seriously. The findings are fixable. The crypto is sound. The model works. Now we prove we can respond quickly and transparently.
