# Brief: Stakeholder Communication Materials for User A and User B

**version** v0.4.7  
**date** 17 Feb 2026  
**from** Human (project lead)  
**to** Sherpa (lead), Ambassador, Journalist, Historian  
**type** Task brief — guidance for the Sherpa and Journalist to produce, not for this session to write  

---

## What This Brief Is

This is **guidance** for the Sherpa, Journalist, and Historian. It describes what materials need to be produced, for whom, in what format, and with what tone. The actual writing should be done by the Sherpa and Journalist — they are the ones who need to craft, archive, and maintain these communications. This brief provides the structure, context, and detail they need to do that.

This is the beginning of how we systematically interact with our users — the people who have engaged with the platform, given us their time, and provided feedback. How we respond to them sets the tone for every future user relationship.

---

## The Principle: The Sherpa as User Guide

The Sherpa's role is to guide users along the trails. That metaphor applies here literally: these two users have found SG/Send, walked a trail (tested it, reviewed it, gave feedback), and now the Sherpa meets them on the path and says: "Welcome. I heard you. Let me show you what's ahead."

The communications should come **from the Sherpa** (not the Ambassador — the Ambassador faces outward to the market; the Sherpa faces the individual user). The Sherpa introduces themselves, acknowledges what was received, and provides realistic, honest information about what's happening.

---

## Materials Required Per User

For **each user**, produce two documents:

### Document 1: The Acknowledgment Message

**Format**: email-length. A few paragraphs. Something you could paste into an email, a LinkedIn message, or send via SG/Send.

**Purpose**: acknowledge receipt, introduce the Sherpa, show that we listened, provide a realistic status update, and ask a question.

**Tone**: warm, professional, honest. Not corporate. Not overly casual. The tone of a knowledgeable guide who respects the person they're talking to.

**Structure**:
1. Thank you — genuine appreciation for their time and contribution
2. Introduction — "I'm the Sherpa for the SG/Send project. My role is to guide users and make sure your feedback reaches the right people and gets acted on."
3. Acknowledgment — specifically reference what they submitted (not a generic "thanks for your feedback")
4. Status — honest, realistic. What's happening with their input. No promises on timelines, but clear indication that it's been received, processed, and is being acted on.
5. The ask — would they be willing to be interviewed by the Sherpa and the Journalist? This would be a conversational interview using ChatGPT voice mode (or another LLM voice mode) — low friction, just a conversation about their experience, their needs, and what they'd find useful. Explain that this helps us understand the real use cases behind their feedback.
6. Reference to Document 2 — "We've also prepared a more detailed document that shows how we've processed your feedback. If you have a moment to review it, we'd love your confirmation that we've captured your intent correctly."

### Document 2: The Detailed Response

**Format**: multi-page document. Structured, thorough, shareable.

**Purpose**: show the user in detail how their feedback has been processed, what we're planning, and ask them to validate our understanding.

**Tone**: more formal than Document 1, but still accessible. This is a document someone might share with their team or keep for reference.

**The key question in every Document 2**: "Have we captured this correctly? Does this match what you were thinking? Is there anything we've missed or misunderstood?"

---

## User B: Feature Request Response

### Document 1 (Acknowledgment Message)

The Sherpa should cover:

- Thank you for testing the platform and confirming it works ("tried it this morning — worked as described" — this matters to us)
- We received your three feature requests: expiring links, user-defined encryption keys, certificate-based encryption
- All three are already on our roadmap (and were even before your message — which is validating)
- We can't guarantee specific timelines, but these are active priorities
- Would you be willing to have a short conversational interview with our Sherpa and Journalist? We'd love to understand your use cases in more depth — what situations would you use expiring links in? How often do you share with the same person? We can do this via ChatGPT voice mode — it's just a conversation, 10–15 minutes.
- We've attached a more detailed document if you'd like to see how these features are being planned

### Document 2 (Detailed Feature Validation)

The Sherpa and Journalist should produce a document that:

1. **Restates each feature request** in the user's own words
2. **Describes how we're thinking about implementing it** — not technical specs, but enough detail that the user can say "yes, that's what I mean" or "no, I was thinking of something different"
3. **Asks a validation question** for each feature

For each of User B's three requests:

**Feature 1: Expiring Links**
- What User B said: "An expiring link (similar to SharePoint)"
- How we're planning it: sender chooses a duration (1 hour, 24 hours, 7 days, 30 days) when uploading. After that time, the link returns a "this content has expired" message. The encrypted data is automatically cleaned up. Can be combined with download limits for "burn after reading" (one download, expires in 24 hours).
- Validation question: "Is time-based expiry what you had in mind, or were you thinking of something more like 'expires after N downloads'? Or both? Is there a specific duration that would be most useful for your workflow?"

**Feature 2: User-Defined Encryption Key**
- What User B said: "Be able to input your own encryption key (as that way if I regularly share with someone I don't need to pass new keys to them each time)"
- How we're planning it: instead of SG/Send generating a random key, the sender (or recipient) defines a key/passphrase that both parties know. All files encrypted with that key. Persistent key for a relationship — set it once, use it for every transfer.
- Validation question: "Is this about reducing the friction of key exchange for regular sharing partners? Would you want one key per person you share with, or one key for all your sharing? Would you want the ability to rotate the key periodically?"

**Feature 3: Certificate-Based Encryption**
- What User B said: "I wonder if being able to use a cert file would be useful. Similar to being able to share a cert to write / read the files."
- How we're planning it: public key infrastructure (PKI). You publish a public key (or certificate). Anyone who wants to send you something encrypts with your public key. Only your private key can decrypt. No key exchange needed — the public key is, well, public. This also provides sender verification if the sender signs with their private key.
- Validation question: "Is this about removing the need for out-of-band key exchange entirely? Would you use your own certificates (e.g., from your organisation's PKI) or would you want SG/Send to generate and manage certificates for you?"

---

## User A: Security Review Response

### Document 1 (Acknowledgment Message)

The Sherpa should cover:

- Thank you for conducting a thorough security review and for taking the time to produce such a detailed, professional report
- Special acknowledgment: "We loved that you sent the report via SG/Send — it validated the use case while testing the product"
- We received your report: 29 findings across all severity levels, 10 functionality suggestions, 8 test gap identifications
- The headline that matters: **your review confirmed that the crypto is correct** (AES-256-GCM, Web Crypto API, server never sees plaintext). That's the most important validation we've received.
- We've processed every finding. We reclassified them using our internal business-impact severity scale (our P0–P10 vs your P0–P3) — the attached document explains the reclassification and why.
- We're handling this as a P1 incident — not because any finding is P1 (none are, by our scale), but because it's our first external security disclosure and we want to set the standard for how we respond
- Would you be willing to have a conversational interview with our Sherpa and Journalist? We'd love to hear about your experience reviewing the code, what drew your attention to the project, and how you think about zero-knowledge architectures. ChatGPT voice mode, 15–20 minutes, low friction.
- We've attached a detailed document showing how every finding was processed
- Your follow-up comment — "I can't tell you how many times I've needed something like this" — resonated deeply with us. That's exactly the pain point we're building for.
- We'd like to credit you publicly (with your consent) when we publish about how we handled this review. Let us know if that's something you're comfortable with.

### Document 2 (Detailed Findings Response)

This is the longer document. The Sherpa and Journalist should produce:

1. **How we received and processed the report** — timeline, who was involved, how it was routed
2. **Our severity classification framework** — explain the P0–P10 scale (P0 = major crisis shut everything down, P1 = major customer impact, P2 = significant customer impact, through to P10 = negligible). Explain WHY we use a business-impact scale rather than a technical-exploitability scale — because the question isn't "can this be exploited?" but "what's the impact on our users if it is?"
3. **The reclassification** — show every finding with:
   - The reviewer's original severity
   - Our reclassified severity
   - The reasoning (e.g., "No customer data at risk because the server only holds encrypted bytes. The zero-knowledge model means an auth bypass doesn't expose plaintext. Reclassified from your P1 to our P3 — must fix before production, but no current customer impact.")
4. **What we're fixing immediately** — the P3 and P4 items going into the next release
5. **What we're accepting (for now)** — any items we're deferring, with honest reasoning
6. **Functionality suggestions alignment** — show how their 10 suggestions map to our existing roadmap (12 of 13 already planned — reassuring for both parties)
7. **The validation question**: "Have we captured every finding accurately? Is our reclassification reasoning sound? Are there any findings where you think our severity assessment is too low?"

---

## For the Journalist

The Journalist has two jobs here:

### Job 1: Help Write the Materials

Work with the Sherpa to produce the four documents (2 per user). The Journalist brings the narrative skill — making the communications engaging and human, not bureaucratic. The Sherpa brings the user-relationship perspective — what does this person need to hear?

### Job 2: Write the Story

This is a publishable story. The narrative:

- We shipped an MVP
- We invited beta users
- One user tested it, confirmed it works, and requested features that were already on our roadmap
- Another user reviewed the open-source code, found real vulnerabilities, and sent the report via the product itself
- We processed everything transparently, reclassified findings on our own scale, and are fixing them in the open
- The security reviewer's quote ("I can't tell you how many times I've needed something like this. If you use Signal, Proton, or whatever else, the other party needs the same tech, which is not always the case") captures the value proposition better than we ever could

This is a story about: open source working, user engagement working, transparent security response working, and a product that solves a real pain point. The Journalist should write it for publication (LinkedIn article, docs site, blog post).

---

## For the Historian

The Historian should capture and record:

- **First external security review**: date, scope, findings summary, response timeline
- **First beta user feature feedback**: date, source, alignment with roadmap
- **First stakeholder communication cycle**: the brief → process → respond → validate loop working in practice
- **First use of SG/Send for SG/Send feedback**: meta-validation of the product (User A sent a security review of the product using the product)
- **The User A quote** as a significant moment: an external user independently articulated the core value proposition

These are milestones. They should be recorded with dates, context, and references to the source documents.

---

## Interview Format (If Users Accept)

If either user agrees to be interviewed, the format:

- **Platform**: ChatGPT voice mode (or another LLM voice mode) — the user talks to an AI interviewer
- **Duration**: 10–20 minutes
- **Structure**: the Sherpa and Journalist prepare interview questions in advance. The AI conducts the conversation. The transcript is processed afterwards.
- **Questions for User B**: what situations would you use expiring links in? How often do you share sensitive files? Who do you share with? What tools do you use today? What's the biggest friction point?
- **Questions for User A**: what drew you to review the code? How do you typically approach security reviews of open-source projects? What's your experience with zero-knowledge architectures? What would make you recommend SG/Send to others? What's missing?
- **Output**: the Sherpa processes the interview into user insights. The Journalist produces a publishable piece (with the user's consent). The Historian records it.

---

## Summary of Deliverables

| Document | For | Owner | Format | Purpose |
|---|---|---|---|---|
| User B — Acknowledgment message | User B | Sherpa + Journalist | Email-length (few paragraphs) | Thank, acknowledge, ask for interview, reference detailed doc |
| User B — Feature validation doc | User B | Sherpa + Journalist | Multi-page document | Detailed feature plans, validation questions per feature |
| User A — Acknowledgment message | User A | Sherpa + Journalist | Email-length (few paragraphs) | Thank, acknowledge, explain reclassification approach, ask for interview |
| User A — Findings response doc | User A | Sherpa + Journalist | Multi-page document | Full reclassification with reasoning, fix plan, validation questions |
| "How Our First Security Review Went" | Public (LinkedIn, docs site) | Journalist | Article | The narrative of open source + transparent security + user validation |
| Milestone record | Internal | Historian | Knowledge document | First security review, first user feedback, first SG/Send meta-use |
| Interview questions (if accepted) | Internal prep | Sherpa + Journalist | Question set | Prepared questions for ChatGPT voice mode interviews |

---

## For the Conductor

This brief goes to the Sherpa (lead), with the Journalist, Ambassador, and Historian supporting. The Sherpa owns the user relationships. The Journalist owns the narrative. The Historian owns the record. The Ambassador should review the public-facing materials for consistency with the brand voice and messaging strategy.

The materials should be ready for the human to review and send. The human makes the final decision on what gets sent to each user and when.

Don't rush this. These are our first two engaged users. How we treat them now defines how the community thinks about us. Get it right.
