# AppSec Research Brief: Service Worker Trust Anchor — Fixing the CA Trust Model

**version** v0.4.20  
**date** 19 Feb 2026  
**from** Human (project lead) + AppSec analysis  
**to** AppSec (lead), Architect, Developer, GRC  
**type** Security architecture research — novel approach  
**classification** This document describes a security architecture that could become a published research paper or standards proposal.  

---

## The Problem: The CA Trust Model Is Structurally Broken

The entire web security model depends on Certificate Authorities (CAs). Your browser trusts ~150+ root CAs. **Any one of them** can issue a valid TLS certificate for **any domain in the world.** This is not a bug — it's how the system was designed.

The implication: a single compromised, coerced, or negligent CA can issue a fraudulent certificate for `send.sgraph.ai`, and an attacker holding that certificate can perform a man-in-the-middle attack with a green padlock. The user sees nothing wrong. The attacker reads (and modifies) everything.

### This Is Not Theoretical

| Incident | What Happened |
|---|---|
| **DigiNotar (2011)** | CA compromised. Fraudulent certs issued for Google, Yahoo, Mozilla, and others. Used to intercept Iranian Gmail users. |
| **CNNIC (2015)** | Chinese government-affiliated CA issued unauthorised certificates for Google domains via an intermediate CA. |
| **Symantec (2015–2017)** | Mass mis-issuance of certificates. Trust revoked by all major browsers. |
| **Government CAs** | Multiple national CAs have been caught or suspected of issuing surveillance certificates. Any government that controls a trusted root CA can MITM its citizens' traffic. |
| **Corporate TLS inspection** | Enterprises routinely deploy TLS-intercepting proxies with locally trusted root CAs. Every employee's HTTPS traffic is decrypted, inspected, and re-encrypted. |

Certificate Transparency (CT) helps detect fraudulent certificates **after issuance** — but it doesn't prevent the attack. By the time CT logs reveal the fraudulent cert, the damage is done.

### The Fundamental Weakness

```
User trusts browser → Browser trusts 150+ CAs → Any CA can impersonate any site
```

The trust chain is only as strong as the weakest CA. With 150+ root CAs (many controlled by governments, some with poor security practices), the weakest link is very weak indeed.

---

## The Solution: Service Worker as Local Trust Anchor

### Architecture Overview

We introduce a **client-side trust anchor** that is independent of the CA system. Once established on the first visit (Trust On First Use — TOFU), it protects all subsequent interactions regardless of the state of TLS, CAs, or the network.

The trust anchor has three layers:

```
Layer 1: CODE INTEGRITY
  Service Worker pins the hash of bootstrap.js and critical scripts.
  Any modification to code → blocked, user alerted, alert sent to us.

Layer 2: CONTENT AUTHENTICITY
  Service Worker stores the server's public signing key(s).
  All data responses must be signed by a pinned key.
  Unsigned or wrongly-signed content → blocked.

Layer 3: SOURCE RESTRICTION
  Service Worker stores a registry of trusted sources and content types.
  Only content from registered sources, of registered types → accepted.
  Everything else → rejected. Not just blocked — the browser never sees it.
```

### Layer 1: Code Integrity (Hash Pinning)

**On first visit:**
1. User loads the page for the first time over TLS (the one vulnerable moment)
2. A Service Worker is installed
3. The Service Worker caches `bootstrap.js` and computes its hash
4. The hash is stored locally as the **trusted reference**

**On every subsequent visit:**
1. Browser loads the Service Worker from local storage (this happens before any network request)
2. Service Worker intercepts the fetch for `bootstrap.js`
3. Fetches from network, computes hash of received content
4. Compares against stored trusted hash

```
Match    → Serve to page. Everything is normal.
Mismatch → BLOCK the modified code.
           Serve the cached trusted version instead.
           Show user warning: "The security code for this site has 
           changed unexpectedly. This may indicate an attack."
           Phone home: send signed alert to monitoring endpoint.
           Log the tampered payload locally for forensics.
```

**Why this works:** the Service Worker is installed locally. It runs before page code. It cannot be replaced by a network-level attacker — the browser's Service Worker update mechanism requires explicit steps, not just serving new code.

**Why this is like HSTS:** HTTP Strict Transport Security (HSTS) has the same TOFU property — the first visit establishes the policy, and the browser enforces it locally from then on. Our approach applies the same principle to code integrity instead of transport security.

### Layer 2: Content Authenticity (Signed Responses)

**On first visit (in the same trust bundle as Layer 1):**
The Service Worker receives and stores the server's **signing public key(s)**:

```json
{
  "trust_bundle_version": "1.0",
  "server_signing_keys": [
    {
      "key_id": "sg-send-primary-2026",
      "public_key": "-----BEGIN PUBLIC KEY-----\n...",
      "algorithm": "Ed25519",
      "valid_from": "2026-02-01",
      "valid_until": "2027-02-01"
    }
  ],
  "content_signing_required": true,
  "reject_unsigned": true
}
```

**On every subsequent request:**
The server signs all data responses with its private key. The Service Worker verifies the signature before passing the response to the page:

```
Server response:
  {
    "data": "...encrypted page content...",
    "signature": "...Ed25519 signature over data...",
    "key_id": "sg-send-primary-2026"
  }

Service Worker:
  1. Look up key_id in pinned trust bundle
  2. Verify signature using pinned public key
  3a. Valid   → pass response to page
  3b. Invalid → BLOCK. Alert. Phone home.
```

**What this defeats:** an active MITM who has a fraudulent TLS certificate can intercept traffic, but they **cannot sign responses with our private key**. The MITM can modify data in transit, but the modified data fails signature verification. The Service Worker rejects it.

This is the layer that transforms the architecture from "code integrity check" to "full content authenticity". Every byte the page receives has been verified as genuinely from our server.

### Layer 3: Source Restriction (Trust Registry)

**On first visit (or on data room setup):**
The Service Worker receives a **trust registry** — a list of exactly which sources, keys, and content types are authorised:

```json
{
  "trust_registry_version": "1.0",
  "trusted_sources": [
    {
      "source_id": "sg-send-primary",
      "signing_key": "...public key...",
      "allowed_content_types": ["encrypted_message", "encrypted_file", "metadata", "ui_update"],
      "description": "SG/Send primary server"
    },
    {
      "source_id": "data-room-deal-alpha",
      "signing_key": "...public key...",
      "allowed_content_types": ["documents", "messages"],
      "description": "Data room for Deal Alpha — Legal Firm A + Investor Group B"
    }
  ],
  "reject_all_unsigned": true,
  "reject_unknown_sources": true,
  "reject_unknown_content_types": true
}
```

**The Service Worker becomes a local firewall:**
- Only content signed by a registered source → accepted
- Only content types that are registered → accepted
- Unknown sources → rejected, even if properly signed by some key we don't recognise
- Unknown content types → rejected
- Unsigned content → rejected

**The data room scenario:**
A data room for a specific transaction is configured with the public keys of exactly the servers involved. The participant's browser literally **cannot receive content that wasn't signed by an authorised party**. Even if:

- The network is compromised
- A CA is compromised
- The CDN is compromised
- A different server tries to inject content
- The data room server is compromised AFTER setup (it would need the original signing key, which can be rotated)

The participant's Service Worker rejects everything that isn't signed by the pinned keys.

---

## The TOFU Problem and Mitigations

### The Vulnerable Moment

Like HSTS and SSH, the first visit is the trust establishment moment. If the first visit is intercepted by a MITM, the attacker's code and keys get pinned instead of ours.

### Mitigations (Progressive)

| Mitigation | How It Works | Attack Window |
|---|---|---|
| **Plain TOFU** | First visit establishes trust. All subsequent visits are protected. | First visit |
| **Out-of-band hash distribution** | Publish the bootstrap.js hash + server public key fingerprint on the business card, GitHub README, docs site, DNS TXT record. User verifies on first visit. | Zero (if user verifies) |
| **QR code on business card** | Business card includes QR code with the trust bundle hash. User scans → app verifies the trust bundle matches. | Zero (if user scans) |
| **Pre-installed trust bundle** | For enterprise deployments, the trust bundle is pre-loaded on the device (via MDM, group policy, or secure browser configuration). | Zero |
| **Multi-path verification** | On first visit, the Service Worker fetches the trust bundle from multiple independent sources (main server, DNS, GitHub, a separate verification endpoint on a different cloud provider). Requires all to agree. A MITM would need to compromise all paths simultaneously. | Near-zero |
| **Secure browser native support** | The browser itself implements trust bundle pinning. No JavaScript-level trust needed. (Surf Security, Island, etc.) | Zero |

### The Business Card as Trust Anchor

We already print business cards with the URL and access token. Add the **trust bundle fingerprint**:

```
┌──────────────────────────────────┐
│  SG/Send                         │
│  send.sgraph.ai                  │
│                                  │
│  Access: A7X-9F2-K4M             │
│  Trust:  sha256:3a7f...c891      │
│                                  │
│  [QR CODE]                       │
│                                  │
│  Scan to verify security.        │
└──────────────────────────────────┘
```

The physical card becomes a root of trust — something a network attacker cannot modify.

---

## Trust Bundle Updates (Key Rotation)

Keys need to rotate. The bootstrap needs to be updated. The trust bundle must evolve.

### The Update Flow

```
1. Service Worker detects a trust bundle update from the server
2. The NEW trust bundle is signed by the CURRENT trusted key
   (key continuity — like SSH host key rotation)
3. Service Worker verifies the signature on the update using the current pinned key
4. If valid: prompt the user
   "SG/Send is updating its security configuration.
    New trust bundle fingerprint: sha256:4b8e...d912
    [Accept update]  [Reject and keep current]  [Show details]"
5. User accepts → new trust bundle replaces the old one
6. User rejects → old trust bundle remains in effect
```

**Critical**: trust bundle updates REQUIRE user interaction. No silent updates. The user is the final authority on whether to trust new keys. This prevents a compromised server from silently rotating to attacker-controlled keys.

**Key continuity chain**: each trust bundle is signed by the previous key. This creates a verifiable chain of trust over time — like a blockchain of trust bundles. If the chain is broken (new bundle not signed by the previous key), the Service Worker should refuse the update and raise a critical alert.

---

## The Full Security Stack

```
Layer 0: PHYSICAL TRUST ANCHOR
  Business card, QR code, out-of-band hash
  (eliminates TOFU vulnerability)

Layer 1: SERVICE WORKER TRUST ANCHOR
  Installed on first visit (or pre-installed)
  Intercepts all network requests before page code runs
  Cannot be replaced by network-level attacks

Layer 2: CODE INTEGRITY
  Hash-pinned bootstrap.js and critical scripts
  Tampered code → blocked, cached version served, alert raised

Layer 3: CONTENT AUTHENTICITY
  Server signing keys pinned locally
  All responses signature-verified
  Modified content → blocked, alert raised

Layer 4: SOURCE RESTRICTION
  Trust registry of authorised sources and content types
  Unknown sources → rejected
  Unknown content → rejected

Layer 5: WEB CRYPTO PKI
  User's private key (non-extractable, IndexedDB)
  Content encrypted to user's public key
  Even authenticated, integrity-verified content is still encrypted
  (defence in depth — Layers 2–4 protect integrity, Layer 5 protects confidentiality)

Layer 6: ZERO-KNOWLEDGE APPLICATION
  AES-256-GCM encryption in the browser
  Server stores only ciphertext
  (the existing SG/Send model — all the layers above protect THIS)
```

Each layer is independent. Each layer adds protection that the others don't provide. An attacker must defeat ALL layers to compromise the system. Defeating any single layer (CA compromise, server compromise, CDN compromise, network interception) is insufficient.

---

## Comparison with Existing Approaches

| Approach | Protects Code? | Protects Content? | Restricts Sources? | TOFU? | Standard? |
|---|---|---|---|---|---|
| **TLS/HTTPS** | Transport only | Transport only | No (any CA) | No | Yes |
| **HSTS** | Enforces HTTPS | No | No | Yes | Yes |
| **Certificate Pinning (deprecated)** | Pins specific CA/cert | No | Partially | No (pre-configured) | Deprecated |
| **Subresource Integrity (SRI)** | Pins specific script hashes | No | No | No (per-page) | Yes |
| **Our approach** | Full hash pinning | Full signature verification | Full trust registry | Yes (with mitigations) | **New** |

Nothing in the current web standards stack provides all three: code integrity, content authenticity, and source restriction — with a persistent local trust anchor that survives network-level attacks.

---

## Implementation Roadmap

### Phase 1: Service Worker Code Pinning (MVP)

| Task | Owner | Priority |
|---|---|---|
| Implement Service Worker that caches and hash-pins bootstrap.js | Developer | D1 |
| Implement hash comparison on every page load | Developer | D1 |
| Implement "tamper detected" user warning UI | Designer, Developer | D2 |
| Implement phone-home alerting (to a separate monitoring endpoint) | Developer, DevOps | D2 |
| Test: simulate a MITM modifying bootstrap.js — verify detection | AppSec | D1 |

### Phase 2: Content Signing and Verification

| Task | Owner | Priority |
|---|---|---|
| Implement server-side response signing (Ed25519) | Developer, Architect | D2 |
| Implement Service Worker signature verification for all data responses | Developer | D2 |
| Define trust bundle format (JSON schema for keys, sources, content types) | Architect | D2 |
| Implement trust bundle storage and management in Service Worker | Developer | D2 |
| Test: simulate modified data response — verify rejection | AppSec | D2 |

### Phase 3: Source Restriction and Trust Registry

| Task | Owner | Priority |
|---|---|---|
| Implement trust registry (authorised sources, content types, keys) | Developer, Architect | D3 |
| Implement per-source content type filtering in Service Worker | Developer | D3 |
| Design data room trust configuration (per-transaction trust bundles) | Architect | D3 |
| Test: simulate unauthorised source injection — verify rejection | AppSec | D3 |

### Phase 4: TOFU Mitigations

| Task | Owner | Priority |
|---|---|---|
| Add trust bundle fingerprint to business cards (QR code + text) | Designer | D3 |
| Publish trust bundle hash in DNS TXT record | DevOps | D3 |
| Implement multi-path verification on first visit | Architect, Developer | D4 |
| Design trust bundle update flow (key rotation with user interaction) | Architect, Designer | D3 |
| Research: proposal for browser-native code pinning standard | AppSec, Architect | D4 |

### Phase 5: Secure Browser Integration

| Task | Owner | Priority |
|---|---|---|
| Propose native trust bundle pinning to Surf Security | Ambassador, AppSec | D4 |
| Design the browser-native implementation (no JavaScript trust needed) | Architect | D4 |
| Explore W3C / IETF standardisation path | AppSec | D5 |

---

## For AppSec: Research Questions

| Question | Why It Matters |
|---|---|
| Can a MITM force a Service Worker update in any browser? | If yes, Layer 1 has a gap. Research browser-specific SW update behaviour. |
| What happens if the user clears browser data? | The trust anchor is lost. The next visit is a new TOFU moment. Document this risk. |
| Can we detect if a Service Worker has been tampered with at the browser level? | Belt and braces — can the page verify that the SW is the expected one? |
| How does this interact with browser auto-updates? | Do browser updates reset Service Workers? |
| Could a malicious browser extension bypass the Service Worker? | Extensions can modify requests/responses. Can they bypass SW interception? |
| What is the legal/regulatory status of content signing for financial services data rooms? | Does this satisfy any compliance requirements (e.g., eIDAS, MiFID II data integrity)? |

---

## The Bigger Picture

This architecture is not SG/Send-specific. It's a general web security pattern that any application can adopt. A published research paper or IETF draft could propose:

1. **Code Pinning Header** — like HSTS but for script hashes: `Pin-Script: sha256-abc123; max-age=31536000`
2. **Content Signing Standard** — a standard header for signed HTTP responses: `Content-Signature: keyid="server-2026"; algorithm="ed25519"; signature="..."`
3. **Trust Bundle Registration** — a standard mechanism for browsers to store and enforce per-origin trust bundles

If this gains traction, browser vendors (especially privacy-focused ones like Firefox and secure browser vendors like Surf) could implement native support, eliminating the need for the JavaScript/Service Worker layer entirely.

SG/Send would be the proof-of-concept implementation. The standard would be the contribution to web security.

---

This document is released under the Creative Commons Attribution 4.0 International licence (CC BY 4.0). You are free to share and adapt this material for any purpose, including commercially, as long as you give appropriate credit.
