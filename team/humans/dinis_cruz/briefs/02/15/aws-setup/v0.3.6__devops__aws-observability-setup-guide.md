# SGraph Send — AWS Observability Setup (No IP Capture)

**Date:** 15 February 2026 | **Version:** v0.3.5    
**Constraint:** No end-user IP addresses captured in any log or metric.    
**Request path:** Internet → CloudFront → Lambda Function URL → Lambda → S3  

---

## Pre-Requisites: Create Log Buckets

You need two dedicated S3 buckets for logs before enabling anything else.

### Bucket 1: CloudFront Real-Time Logs (via Kinesis → Firehose → S3)

1. Go to **S3 Console** → **Create bucket**
2. Bucket name: `{account_id}--sgraph-send-cf-logs--{region}`
3. Region: same as your Lambda region
4. Block all public access: **ON** (default)
5. Bucket Versioning: **Disabled** (logs don't need versioning)
6. Default encryption: **SSE-S3** (Amazon S3 managed keys)
7. Click **Create bucket**

### Bucket 2: S3 Access Logs

1. Go to **S3 Console** → **Create bucket**
2. Bucket name: `{account_id}--sgraph-send-s3-access-logs--{region}`
3. Region: same as your transfers bucket
4. Block all public access: **ON**
5. Bucket Versioning: **Disabled**
6. Default encryption: **SSE-S3**
7. Click **Create bucket**
8. **After creation** → go into the bucket → **Permissions** tab → **Bucket policy**
9. Add the S3 logging service principal policy:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "S3ServerAccessLogsPolicy",
      "Effect": "Allow",
      "Principal": {
        "Service": "logging.s3.amazonaws.com"
      },
      "Action": "s3:PutObject",
      "Resource": "arn:aws:s3:::{account_id}--sgraph-send-s3-access-logs--{region}/*",
      "Condition": {
        "StringEquals": {
          "aws:SourceAccount": "{account_id}"
        }
      }
    }
  ]
}
```

Replace `{account_id}` and `{region}` with your actual values.

---

## Step 1: CloudFront Real-Time Logs (Without IP)

CloudFront Standard Logs always include `c-ip` (client IP) and you cannot exclude it. So we **skip Standard Logs entirely** and use Real-Time Logs, which let you choose exactly which fields to include.

This requires: a Kinesis Data Stream → Kinesis Firehose → S3.

### 1a. Create Kinesis Data Stream

1. Go to **Amazon Kinesis Console** → **Data streams** → **Create data stream**
2. Data stream name: `sgraph-send-cf-realtime-logs`
3. Capacity mode: **On-demand** (auto-scales, no shard management)
4. Click **Create data stream**
5. Wait for status: **Active**

### 1b. Create Kinesis Firehose Delivery Stream

1. Go to **Amazon Data Firehose** → **Create Firehose stream**
2. Source: **Amazon Kinesis Data Streams**
3. Select the stream: `sgraph-send-cf-realtime-logs`
4. Firehose stream name: `sgraph-send-cf-logs-to-s3`
5. Destination: **Amazon S3**
6. S3 bucket: select `{account_id}--sgraph-send-cf-logs--{region}`
7. S3 prefix: `cloudfront-realtime/year=!{timestamp:yyyy}/month=!{timestamp:MM}/day=!{timestamp:dd}/`
8. S3 error prefix: `cloudfront-realtime-errors/`
9. Buffer hints:
   - Buffer size: **5 MiB** (default)
   - Buffer interval: **300 seconds** (5 minutes — fine for "capture now, read later")
10. Compression: **GZIP**
11. Encryption: **Disabled** (the bucket has SSE-S3 already)
12. Click **Create Firehose stream**

### 1c. Create CloudFront Real-Time Log Configuration

1. Go to **CloudFront Console** → **Telemetry** section in left nav → **Logs**
2. Click **Real-time log configurations** tab → **Create configuration**
3. Name: `sgraph-send-no-ip`
4. Sampling rate: **100** (capture every request — your traffic is low)
5. **Fields — THIS IS THE CRITICAL PART.** Select these fields and **do NOT select `c-ip` or `c-port`**:

**Select these:**

| Field | Why |
|-------|-----|
| `timestamp` | When the request happened |
| `sc-status` | HTTP status code returned |
| `sc-bytes` | Bytes sent to client |
| `cs-method` | HTTP method (GET, POST, etc.) |
| `cs-uri-stem` | URL path (e.g., /transfers/download/abc123) |
| `cs-uri-query` | Query string (usually empty for your app) |
| `cs-protocol` | HTTP or HTTPS |
| `cs-protocol-version` | HTTP/1.1, HTTP/2, HTTP/3 |
| `sc-content-type` | Response content type |
| `sc-content-len` | Response content length |
| `cs-user-agent` | Browser user agent string |
| `cs-referer` | Referrer header |
| `x-edge-location` | Which CloudFront POP served this |
| `x-edge-result-type` | Hit, Miss, Error, etc. |
| `x-edge-response-result-type` | Final result after origin fetch |
| `x-edge-request-id` | Unique request ID (for correlation) |
| `time-taken` | Total time to serve request (seconds) |
| `time-to-first-byte` | Time to first byte from origin |
| `sc-range-start` | Range request start (for downloads) |
| `sc-range-end` | Range request end |
| `x-forwarded-for` | **DO NOT SELECT** — contains client IP |
| `ssl-protocol` | TLS version |
| `ssl-cipher` | TLS cipher suite |
| `cs-accept` | Accept header |
| `cs-accept-encoding` | Accept-Encoding header |
| `cs-host` | Host header |
| `origin-fbl` | Origin first-byte latency |
| `origin-lbl` | Origin last-byte latency |

**DO NOT select:**
- `c-ip` — client IP address
- `c-port` — client port
- `x-forwarded-for` — forwarded client IP
- `c-ip-version` — reveals IP version (v4/v6 could narrow identity)
- `c-country` — skip if you want zero geo data, or include if you just want region-level analytics (your call — it's not PII by itself but it narrows identity)

6. Endpoint: select your Kinesis stream `sgraph-send-cf-realtime-logs`
7. IAM role: **Create new service role** (let CloudFront create it)
8. Click **Create configuration**

### 1d. Attach Real-Time Log Config to Distribution

1. Go to **CloudFront Console** → **Distributions** → select your distribution
2. Go to the **Behaviors** tab
3. Select the default behavior → **Edit**
4. Scroll to **Real-time log configuration**
5. Select: `sgraph-send-no-ip`
6. Click **Save changes**
7. Wait for the distribution to deploy (status: **Deployed**)

---

## Step 2: CloudFront Additional Metrics

1. Go to **CloudFront Console** → **Distributions** → select your distribution
2. Click the **Monitoring** tab (or **Telemetry** → **Additional metrics**)
3. Click **Enable additional metrics**
4. This adds to CloudWatch: `4xxErrorRate`, `5xxErrorRate`, `OriginLatency`, `CacheHitRate`
5. **No IP captured** — these are aggregate metrics only

---

## Step 3: CloudFront Response Headers (Referrer-Policy)

This fixes AppSec threat T8 (P0 — key could leak via Referrer header).

1. Go to **CloudFront Console** → **Policies** → **Response headers** tab
2. Click **Create response headers policy**
3. Name: `sgraph-send-security-headers`
4. Under **Security headers**:
   - **Referrer-Policy**: Enable → select `no-referrer`
   - **Strict-Transport-Security**: Enable → Max age: `31536000` (1 year), Include subdomains: Yes
   - **X-Content-Type-Options**: Enable → `nosniff`
   - **X-Frame-Options**: Enable → `DENY`
5. Click **Create**
6. Go back to your distribution → **Behaviors** tab → edit default behavior
7. Under **Response headers policy**, select `sgraph-send-security-headers`
8. **Save changes**

---

## Step 4: AWS WAF 

Currently not used, since it is incompatible with the use of Cloudfront realtime logs

### 5b. Enable X-Ray on User Lambda

1. Go to **Lambda Console** → select your **User Lambda** (e.g., `user-dev`)
2. **Configuration** tab → **Monitoring and operations tools** → **Edit**
3. Under **AWS X-Ray**:
   - Active tracing: **Enable**
4. Click **Save**
5. **Important:** Your Lambda execution role needs `xray:PutTraceSegments` and `xray:PutTelemetryRecords` permissions. Check:
   - Go to **Configuration** → **Permissions** → click the execution role
   - Verify the role has the `AWSXRayDaemonWriteAccess` managed policy, or add it

### 5c. Enable X-Ray on Admin Lambda

Repeat step 5b for your **Admin Lambda** (e.g., `admin-dev`).

### 5d. Repeat for QA and Prod

Do the same for `user-qa`, `admin-qa`, `user-prod`, `admin-prod` if they exist.

**No IP captured** — X-Ray traces contain request IDs, timing, and service call graphs. No client IP.

---

## Step 6: Lambda Insights (Enhanced Monitoring)

### 6a. User Lambda

1. Go to **Lambda Console** → select your **User Lambda**
2. **Configuration** tab → **Monitoring and operations tools** → **Edit**
3. Under **Amazon CloudWatch Lambda Insights**:
   - Enhanced monitoring: **Enable**
4. This automatically adds the Lambda Insights extension layer
5. Click **Save**

### 6b. Admin Lambda

Repeat for your **Admin Lambda**.

### 6c. Repeat for QA and Prod Lambdas

**No IP captured** — Lambda Insights captures: memory utilisation, CPU time, cold start duration, network throughput, disk I/O. System metrics only.

---

## Step 7: CloudWatch Logs Retention

By default, Lambda log groups retain logs **forever** (growing cost).

### For each log group:

1. Go to **CloudWatch Console** → **Logs** → **Log groups**
2. You should see log groups like:
   - `/aws/lambda/user-dev`
   - `/aws/lambda/admin-dev`
   - `/aws/lambda/user-qa`
   - `/aws/lambda/admin-qa`
   - (and any prod log groups)
3. Click on each log group
4. Click **Actions** → **Edit retention setting**
5. Set to **30 days** (or **90 days** if you want longer retention)
6. Click **Save**

Repeat for every Lambda log group.

**Note:** These logs contain your app's stdout/stderr, which includes your `Middleware__Analytics` output. Your app already hashes IPs before logging, so these logs are safe — they contain `ip_hash`, not raw IPs.

---

## Step 8: CloudTrail Data Events

### 8a. Check your existing trail

1. Go to **CloudTrail Console** → **Trails**
2. You should have at least one trail (most accounts have a default)
3. Click on it

### 8b. Add S3 Data Events

1. In the trail, click **Edit** (or go to **Data events** section)
2. Under **Data events**:
   - Click **Add data event type** → select **S3**
   - Log selector template: **Custom**
   - Field: `resources.ARN`
   - Operator: **starts with**
   - Value: `arn:aws:s3:::{account_id}--sgraph-send-transfers--{region}/`
   - Click **Add selector**
   - Repeat for your cache bucket: `arn:aws:s3:::{your-cache-bucket-name}/`
3. Read/Write type: **Both** (read + write)

### 8c. Add Lambda Data Events

1. Still in data events, click **Add data event type** → select **Lambda**
2. Log selector template: **Custom**
3. Field: `resources.ARN`
4. Add each Lambda function ARN:
   - `arn:aws:lambda:{region}:{account_id}:function:user-dev`
   - `arn:aws:lambda:{region}:{account_id}:function:admin-dev`
   - (and qa/prod functions)
5. Click **Save**

**No end-user IP captured.** CloudTrail's `sourceIP` for S3 events is the Lambda execution environment IP. For Lambda invoke events via Function URLs, it's the CloudFront edge IP. Neither is the end user's IP.

---

## Step 9: S3 Server Access Logging

### 9a. Transfers Bucket

1. Go to **S3 Console** → select your transfers bucket (`{account_id}--sgraph-send-transfers--{region}`)
2. **Properties** tab → scroll to **Server access logging**
3. Click **Edit**
4. Server access logging: **Enable**
5. Target bucket: select `{account_id}--sgraph-send-s3-access-logs--{region}`
6. Target prefix: `transfers-bucket/`
7. Click **Save changes**

### 9b. Cache Bucket

1. Go to **S3 Console** → select your cache bucket
2. **Properties** tab → **Server access logging** → **Edit**
3. Enable, target bucket: same log bucket
4. Target prefix: `cache-bucket/`
5. Save

**No end-user IP captured.** S3 access logs record the "Remote IP" of the requester — which is the Lambda execution environment, not the end user.

---

## Step 10: S3 Request Metrics

1. Go to **S3 Console** → select your transfers bucket
2. **Metrics** tab → **Request metrics**
3. Click **Create filter** (or **View additional charts** → **Request metrics**)
4. Filter name: `all-requests`
5. Choose scope: **This filter applies to all objects in the bucket**
6. Click **Create filter**

This publishes to CloudWatch: `AllRequests`, `GetRequests`, `PutRequests`, `4xxErrors`, `5xxErrors`, `FirstByteLatency`, `TotalRequestLatency`.

**No IP captured** — aggregate metrics only.

---

## Step 11: S3 Storage Lens

1. Go to **S3 Console** → **Storage Lens** (left nav) → **Dashboards**
2. Click **Create dashboard**
3. Dashboard name: `sgraph-send-storage`
4. Home Region: your primary region
5. Dashboard scope: **Select specific buckets** → add your transfers bucket and cache bucket
6. Metrics selection: **Free metrics** (includes storage bytes, object count, request metrics)
7. Click **Create dashboard**

Takes 24-48 hours for initial data to appear.

---

## Step 12: AWS Budgets

1. Go to **AWS Billing Console** → **Budgets** → **Create budget**
2. Budget type: **Cost budget — Recommended**
3. Budget name: `sgraph-send-monthly`
4. Budget amount: **$50** (adjust to your comfort level)
5. Budget scope: **All AWS services** (or filter to Lambda + S3 + CloudFront + Kinesis)
6. Alert thresholds:
   - **Alert 1:** 50% of budget ($25) → Email notification to your email
   - **Alert 2:** 80% of budget ($40) → Email notification
   - **Alert 3:** 100% of budget ($50) → Email notification
7. Click **Create budget**

### Also create a daily budget for spike detection:

1. Create another budget
2. Budget name: `sgraph-send-daily-spike`
3. Period: **Daily**
4. Budget amount: **$5** (or whatever a normal day costs + margin)
5. Alert at 100%
6. This catches sudden spikes from viral WhatsApp shares

---

## Step 13: Cost Anomaly Detection

1. Go to **AWS Cost Management Console** → **Cost Anomaly Detection** → **Create monitor**
2. Monitor type: **AWS services** (monitors all services)
3. Monitor name: `sgraph-send-anomaly`
4. Alert subscription:
   - Threshold: **Alert when impact exceeds $10** (or your preferred threshold)
   - Recipients: your email
   - Frequency: **Individual alerts** (immediate)
5. Click **Create monitor**

---

## Step 14: Lambda Concurrency Limits

This is your runaway scaling protection. Without it, a viral WhatsApp share could spin up hundreds of concurrent Lambda invocations.

### 14a. User Lambda

1. Go to **Lambda Console** → select your **User Lambda** (e.g., `user-dev`)
2. **Configuration** tab → **Concurrency** → **Edit**
3. Select **Reserve concurrency**
4. Reserved concurrency: **50** (handles 50 simultaneous requests; excess gets HTTP 429)
5. Click **Save**

### 14b. Admin Lambda

1. Select your **Admin Lambda**
2. **Configuration** → **Concurrency** → **Edit**
3. Reserved concurrency: **10** (admin traffic is much lower)
4. Save

**Adjust these numbers up** if you find legitimate traffic is being throttled. Start low; it's easy to increase.

**Repeat for QA/Prod** with appropriate limits (prod should probably have higher limits).

---

## Step 15: Contributor Insights (CloudWatch)

This auto-identifies top contributors in your logs (top paths, top error types, top status codes) without you writing queries.

1. Go to **CloudWatch Console** → **Insights** → **Contributor Insights**
2. Click **Create rule**
3. Rule source: **CloudWatch Logs**
4. Log group: select your User Lambda log group (e.g., `/aws/lambda/user-dev`)
5. Choose a rule template or create custom:
   - Rule name: `sgraph-send-top-paths`
   - Contribution: keys from your log fields (if using structured JSON logging, select the `path` field)
6. Click **Create**

**Note:** This works best if your Lambda outputs structured JSON logs. Your current `Middleware__Analytics` output format determines how useful this is. If logs are unstructured, defer this to when you add structured logging.

---

## Summary of What You've Enabled

| # | Service | What It Captures | IP Captured? |
|---|---------|-----------------|-------------|
| 1 | CloudFront Real-Time Logs | Every request: path, status, timing, UA, edge location, TLS | **No** (c-ip excluded) |
| 2 | CloudFront Additional Metrics | 4xx/5xx rates, origin latency, cache hit ratio | No (aggregate) |
| 3 | CloudFront Response Headers | Referrer-Policy, HSTS, X-Frame-Options | N/A (outbound headers) |
| 4 | WAF (rate limiting) | Request count, block count, CloudWatch metrics | **No** (logging disabled or transformed) |
| 5 | X-Ray Tracing | End-to-end trace: CloudFront → Lambda → S3 | No |
| 6 | Lambda Insights | Memory, CPU, cold starts, network per invocation | No |
| 7 | CloudWatch Logs Retention | Cost control (30-day retention) | No (app already hashes IPs) |
| 8 | CloudTrail Data Events | Every S3 and Lambda API call (AWS-level audit) | No (captures Lambda/CF IP, not user) |
| 9 | S3 Access Logging | Every S3 object operation with timing | No (requester is Lambda, not user) |
| 10 | S3 Request Metrics | Request counts, latency, errors in CloudWatch | No (aggregate) |
| 11 | S3 Storage Lens | Storage patterns, growth trends | No |
| 12 | AWS Budgets | Cost alerts at thresholds | No |
| 13 | Cost Anomaly Detection | Automatic anomaly alerts | No |
| 14 | Lambda Concurrency Limits | Runaway scaling protection | No |
| 15 | Contributor Insights | Top log contributors (paths, errors) | No |

---

## What You Deliberately Skipped

| Service | Why Skipped |
|---------|------------|
| CloudFront Standard Logs | Always includes `c-ip` — cannot exclude |
| WAF Full Logging (native) | Includes `clientIp` — no native redaction |
| CloudFront `c-country` field | Your call — not PII but narrows identity |

---

## Estimated Additional Cost

At low traffic (thousands of requests/day):

| Service | Estimated Monthly Cost |
|---------|----------------------|
| Kinesis Data Stream (on-demand) | $2–5 |
| Kinesis Firehose | $1–3 |
| CloudFront Additional Metrics | $0 (included) |
| X-Ray traces | $1–5 (first 100k traces free) |
| Lambda Insights | $0 (free tier: 5 metrics per function) |
| CloudTrail data events | $2–10 (per 100k events) |
| S3 access log storage | <$1 |
| S3 Storage Lens | $0 (free tier) |
| WAF WebACL | $5/month base + $1/million requests |
| Budgets | $0 (first 2 free) |
| Cost Anomaly Detection | $0 |

**Total estimated additional cost: $12–30/month** at low traffic. WAF is the largest fixed cost ($5/month base). Kinesis is the most variable (scales with request volume).

---

## Post-Setup Verification

After enabling everything, verify:

1. **CloudFront Real-Time Logs flowing:**
   - Wait 5 minutes, then check your CF logs S3 bucket for files under `cloudfront-realtime/`
   - Verify the files contain your selected fields but NO `c-ip` field

2. **X-Ray traces appearing:**
   - Go to **X-Ray Console** → **Traces**
   - Make a request to your site, wait 30 seconds, refresh
   - You should see a trace from CloudFront → Lambda → S3

3. **Lambda Insights metrics:**
   - Go to **CloudWatch Console** → **Lambda Insights** (under Application monitoring)
   - Select your function — you should see memory/CPU graphs

4. **WAF counting:**
   - Go to **WAF Console** → your WebACL → **Overview** tab
   - You should see request counts

5. **CloudTrail events:**
   - Go to **CloudTrail Console** → **Event history**
   - Filter by resource type: S3 or Lambda
   - You should see events for your resources

6. **S3 Access Logs:**
   - Wait 1 hour (S3 access logs can have significant delay)
   - Check your S3 access logs bucket for files under `transfers-bucket/`

---

## For the DPO

This setup captures **zero end-user IP addresses** across all logging mechanisms. The only place end-user IPs appear is:

1. **Your application's `Middleware__Analytics`** — which hashes them via `hash_ip()` before any storage
2. **CloudWatch Lambda logs** — which contain your app's output (already hashed)

AWS infrastructure logs (CloudTrail, S3 access logs) capture Lambda execution environment IPs and CloudFront edge IPs, not end-user IPs.

The one exception to be aware of: **WAF sampled requests** in the AWS Console show the last 3 hours of requests with full headers (including IP) for debugging. These are ephemeral and not persisted, but they are visible to anyone with WAF console access. Control access to the WAF console via IAM if this matters.

---

*SGraph Send DevOps — AWS Observability Setup Guide*  
*Version: v0.3.5*  
*Date: 15 February 2026*
