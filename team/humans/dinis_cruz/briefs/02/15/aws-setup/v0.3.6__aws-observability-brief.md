# LLM Implementation Brief: Observability & Metrics Pipeline

**version** v0.3.6
**date** 15 Feb 2026
**project** SGraph-AI__App__Send (repo: `the-cyber-boardroom/SGraph-AI__App__Send`, branch: `dev`)
**target** `sgraph_ai_app_send/lambda__admin/`
**depends on** Daily Brief #1 + #2 (13 Feb 2026)

---

## 1. Objective

Build a comprehensive observability pipeline for SGraph Send that:

- Collects AWS CloudWatch metrics for every infrastructure component (CloudFront, Lambda, S3)
- Implements the LETS (Load, Extract, Transform, Save) aggregation pattern using the cache service
- Produces dashboards (Markdown + HTML) from cached aggregations
- Replaces Google Analytics with server-side analytics (already partially built)
- Tracks AWS costs

All new code lives in the **admin Lambda** (`sgraph_ai_app_send/lambda__admin/`). The admin UI will consume this data.

---

## 2. SGraph Send Infrastructure Map

The full request path is:

```
User Browser
    │
    ▼
CloudFront Distribution          ← AWS/CloudFront metrics + access logs
    │
    ▼
Lambda Function URL              ← (no separate API Gateway)
    │
    ▼
Lambda Function (user)           ← AWS/Lambda metrics
    │
    ├──► S3 (transfers bucket)   ← AWS/S3 request metrics (encrypted file payloads)
    │
    └──► Lambda Function (admin) ← AWS/Lambda metrics
              │
              └──► S3 (cache bucket)  ← AWS/S3 request metrics (cache service storage)
```

There is **no** NLB, EC2 instance, API Gateway, or Comprehend service in this stack. Collectors from the reference architecture that target those services are not needed.

---

## 3. What Already Exists

Before implementing anything, read and understand these existing files. Do not duplicate or conflict with them.

### 3.1 Cache Client (`Send__Cache__Client`)

**File:** `sgraph_ai_app_send/lambda__admin/service/Send__Cache__Client.py`

This is the central data access layer. It wraps `Cache__Service__Client` and provides domain-specific methods. Namespaces are already defined:

```python
NS_ANALYTICS  = 'analytics'     # Raw events + aggregations
NS_TOKENS     = 'tokens'        # Token metadata + usage events
NS_COSTS      = 'costs'         # AWS cost data (declared but not yet used)
NS_TRANSFERS  = 'transfers'     # Per-transfer analytics summaries (declared but not yet used)
```

**Key patterns to follow:**

- Use `store__json` with `strategy='temporal'` for time-series data (raw events, metrics snapshots). This automatically saves to `year/month/day/hour` paths and maintains a `latest` folder.
- Use `store__json__cache_key` with `strategy='key_based'` for keyed lookups (token metadata, aggregation results by window label).
- Use `admin_storage().files__all__path(path=...)` to list files under a namespace/path prefix.
- Use `retrieve().retrieve__cache_id__json(cache_id=..., namespace=...)` to read a single file by cache_id.

### 3.2 Analytics Middleware (`Middleware__Analytics`)

**File:** `sgraph_ai_app_send/lambda__admin/service/Middleware__Analytics.py`

Already built and wired into the user Lambda (`Fast_API__SGraph__App__Send__User.setup_routes()`). Every HTTP request writes a raw event to the cache service under `NS_ANALYTICS` using the temporal strategy. The event schema is:

```python
event_data = dict(
    event_id              = secrets.token_hex(8)               ,
    event_type            = classify_event_type(path, method)  ,  # 'page_view', 'api_call', 'file_upload', 'file_download'
    path                  = path                               ,
    method                = method                             ,
    status_code           = response.status_code               ,
    duration_ms           = duration                           ,
    ip_hash               = hash_ip(client_ip)                 ,
    user_agent_normalised = normalise_user_agent(user_agent)   ,
    content_bytes         = int(content_length)                ,
    transfer_id           = ''                                 ,
    token_id              = ''                                 )
```

**This is the push-model event writer. It is already operational. Do not modify it** (except to add fields if needed in future phases).

### 3.3 Pulse Service (`Service__Analytics__Pulse`)

**File:** `sgraph_ai_app_send/lambda__admin/service/Service__Analytics__Pulse.py`

A basic real-time aggregation that reads raw temporal files and computes active requests/visitors/transfers for a rolling window. Currently does brute-force N+1 reads (list files, then retrieve each one). This works at low volume. The aggregation engine we build will eventually replace the brute-force approach with pre-computed aggregations, but this service remains as the real-time "what's happening right now" endpoint.

### 3.4 Existing Schemas

**Files in:** `sgraph_ai_app_send/lambda__admin/schemas/`

- `Schema__Analytics__Pulse.py` — real-time traffic pulse
- `Schema__Analytics__Raw_Event.py` — raw event per HTTP request

### 3.5 FastAPI Setup

**File:** `sgraph_ai_app_send/lambda__admin/fast_api/Fast_API__SGraph__App__Send__Admin.py`

The admin FastAPI app auto-creates `Send__Cache__Client` via `create_send_cache_client()` and passes it to services. New routes and services should follow the same injection pattern. The `/health/pulse` route is already registered. New routes (e.g., `/metrics/dashboard`, `/metrics/snapshot`) will be added here.

### 3.6 Cache Client Setup

**File:** `sgraph_ai_app_send/lambda__admin/service/Send__Cache__Setup.py`

Factory function `create_send_cache_client()` creates a `Send__Cache__Client` with an IN_MEMORY cache service. The cache service runs in-process within the Lambda — no external service calls. The cache service persists to S3 via the `CACHE__SERVICE__BUCKET_NAME` env var.

---

## 4. Reference Architecture (Port From)

The patterns below are drawn from a proven metrics pipeline built for a separate project. They are provided as **architectural guidance only**. Reimplement them within `sgraph_ai_app_send`.

### 4.1 CloudWatch Client (`CloudWatch__Client`)

**Pattern:** `CloudWatch__Client`

A Type_Safe wrapper around `boto3.client('cloudwatch')` with two core methods:

- `get_metric_data()` — standard statistics (Sum, Average, Maximum)
- `get_metric_data_extended()` — extended statistics (percentiles: p50, p95, p99)

Both return `Schema__Metric__Series` (metric_name, namespace, dimensions, unit, timestamps[], values[]).

Higher-level convenience methods handle namespace/dimension wiring:
- `get_lambda_metric()` / `get_lambda_metric_percentile()` — `AWS/Lambda` namespace, dimension: `FunctionName`
- `get_s3_metric()` — `AWS/S3` namespace, dimensions: `BucketName` + `FilterId`
- `get_nlb_metric()` — not needed for SGraph Send
- `get_comprehend_metric()` — not needed for SGraph Send

**Action:** Port this class to `sgraph_ai_app_send/lambda__admin/service/CloudWatch__Client.py`. Add a new convenience method `get_cloudfront_metric()` for the `AWS/CloudFront` namespace with dimension `DistributionId`.

### 4.2 Collector Pattern

**Pattern:** `Lambda__Metrics__Collector`

Each collector is a Type_Safe class that:
- Takes a `CloudWatch__Client` + service-specific config
- Has a `collect()` method returning a typed schema
- Has individual `collect_*()` methods per metric

**Action:** Port `Lambda__Metrics__Collector` and `S3__Metrics__Collector`. Create new `CloudFront__Metrics__Collector`.

### 4.3 Orchestrator (`Aws_Metrics_Snapshot`)

**Pattern:** `Aws_Metrics_Snapshot`

Single class that: sets up → collects all → evaluates health → saves JSON → renders charts → generates dashboards. The `run()` method executes the full pipeline.

**Action:** Create equivalent `SGraph_Send__Metrics__Snapshot` but adapted to:
- Write to cache service (not local filesystem)
- Collect only CloudFront + Lambda + S3 metrics (not NLB/EC2/Comprehend)
- Integrate with the LETS aggregation engine

### 4.4 Dashboard Generators

**Pattern:**
- `Dashboard__Generator` (Markdown)
- `Dashboard__Html__Generator` (HTML)

Both read from a `Schema__Metrics__Snapshot` and produce static files.

**Action:** Port and adapt. The HTML generator's CSS/structure is good — update the component names, remove NLB/EC2/Comprehend sections, add CloudFront section.

---

## 5. Implementation Plan

### Phase 1: CloudWatch Metrics + Aggregation Engine (P1)

This phase delivers: CloudWatch metrics collection for all SGraph Send infrastructure, the LETS aggregation engine, health evaluation, and dashboard generation. All data flows through the cache service.

#### 5.1 New Schemas

**Location:** `sgraph_ai_app_send/lambda__admin/schemas/`

Follow the existing schema style (Type_Safe classes, typed primitives, comment headers).

```
Schema__Metric__Series.py          — Time-series data (metric_name, namespace, dimensions, unit, timestamps[], values[])
Schema__Metric__Dimension.py       — Single dimension (name, value)
Schema__CloudFront__Metrics.py     — CloudFront metrics container (requests, bytes_downloaded, bytes_uploaded, error_rate_4xx, error_rate_5xx, cache_hit_rate)
Schema__Lambda__Metrics.py         — Lambda metrics container (invocations, errors, duration_avg, duration_p50, duration_p95, duration_p99, duration_max, throttles, concurrent_executions)
Schema__S3__Metrics.py             — S3 metrics container (get_requests, put_requests, first_byte_latency, total_request_latency, errors_4xx, errors_5xx, bytes_downloaded, bytes_uploaded)
Schema__Metrics__Snapshot.py       — Full snapshot container (snapshot_time, region, lookback_minutes, period_seconds, cloudfront, lambdas[], s3_transfers, s3_cache, health_status[])
Schema__Health__Status.py          — Health evaluation result (component, status, status_emoji, message, metrics{})
Schema__Thresholds__Config.py      — Configurable thresholds for health evaluation
Schema__Aggregation__Window.py     — Aggregation metadata (window_label, window_minutes, computed_at, event_count, data{})
```

**Critical:** Port `Schema__Metric__Series` faithfully from the reference. It is the backbone data structure — every collector method returns one. Fields: `metric_name` (Safe_Str), `namespace` (Safe_Str), `dimensions` (List[Schema__Metric__Dimension]), `unit` (Safe_Str), `timestamps` (List[Safe_UInt]), `values` (List[Safe_Float]).

#### 5.2 CloudWatch Client

**File:** `sgraph_ai_app_send/lambda__admin/service/CloudWatch__Client.py`

Port from reference. The class needs:

```python
class CloudWatch__Client(Type_Safe):
    region       : Safe_Str__AWS__Region
    boto3_client : object = None

    def setup(self) -> 'CloudWatch__Client':                    # Initialize boto3 client

    def get_metric_data(self, namespace, metric_name,           # Standard statistics
                        dimensions, statistic, unit,
                        lookback_minutes, period_seconds
                       ) -> Schema__Metric__Series:

    def get_metric_data_extended(self, namespace, metric_name,  # Percentile statistics
                                 dimensions, statistic_label, unit,
                                 lookback_minutes, period_seconds
                                ) -> Schema__Metric__Series:

    # Convenience methods:
    def get_lambda_metric(self, function_name, metric_name, statistic, unit, ...)
    def get_lambda_metric_percentile(self, function_name, metric_name, percentile, ...)
    def get_s3_metric(self, bucket_name, filter_id, metric_name, statistic, unit, ...)
    def get_cloudfront_metric(self, distribution_id, metric_name, statistic, unit, ...)
```

The `get_cloudfront_metric()` method is **new** (not in reference). Implementation:

```python
def get_cloudfront_metric(self, distribution_id, metric_name, statistic='Sum',
                          unit='None', lookback_minutes=60, period_seconds=300):
    # IMPORTANT: CloudFront metrics are only available in us-east-1
    # This method must use a separate boto3 client pointed at us-east-1
    # regardless of the region configured on this CloudWatch__Client
    dimensions = [{'Name': 'DistributionId', 'Value': str(distribution_id)},
                  {'Name': 'Region',         'Value': 'Global'            }]
    return self.get_metric_data(namespace='AWS/CloudFront', ...)
```

**Note on CloudFront metrics region:** CloudFront metrics are **only published to us-east-1**. The `CloudWatch__Client` must handle this — either by using a separate boto3 client for CloudFront calls, or by accepting a region override parameter. The reference `CloudWatch__Client` uses a single region; this needs adaptation.

**Note on boto3 dependency:** `boto3` is available in the Lambda runtime but is not in the package dependencies list. The reference code uses lazy `import boto3` inside `setup()`. Follow the same pattern.

#### 5.3 Collectors

**Location:** `sgraph_ai_app_send/lambda__admin/service/collectors/`

Create this directory with an `__init__.py`.

##### Lambda__Metrics__Collector.py

Port directly from reference. Update imports to use local schemas. The SGraph Send Lambda functions are:

```python
# These will be configured in the orchestrator, not hardcoded in the collector
# User Lambda:  function name from sgraph_ai_app_send.lambda__user.user__config.APP__SEND__USER__SERVICE_NAME
# Admin Lambda: function name from sgraph_ai_app_send.lambda__admin.admin__config.APP__SEND__ADMIN__SERVICE_NAME
```

The collector collects: Invocations, Errors, Duration (Average, p50, p95, p99, Maximum), Throttles, ConcurrentExecutions.

##### S3__Metrics__Collector.py

Port directly from reference. Two instances will be created by the orchestrator:

1. **Transfers bucket** (`SEND__S3_BUCKET` env var or auto-resolved from `Send__Config.resolve_s3_bucket_name()`)
2. **Cache bucket** (`CACHE__SERVICE__BUCKET_NAME` env var)

**Important:** S3 request metrics require bucket request metrics to be enabled in the AWS console. The brief should flag this to DevOps. Each bucket needs a request metrics configuration with a filter ID. The filter IDs will be configurable on the orchestrator.

The collector collects: GetRequests, PutRequests, FirstByteLatency, TotalRequestLatency, 4xxErrors, 5xxErrors, BytesDownloaded, BytesUploaded.

##### CloudFront__Metrics__Collector.py

**New class — no reference equivalent.** Follow the same pattern as the Lambda and S3 collectors.

```python
class CloudFront__Metrics__Collector(Type_Safe):
    cloudwatch_client : CloudWatch__Client
    distribution_id   : Safe_Str__Id                          # CloudFront distribution ID (e.g., 'E1ABC2DEF3GHIJ')
    lookback_minutes  : Safe_UInt = 60
    period_seconds    : Safe_UInt = 300

    def collect(self) -> Schema__CloudFront__Metrics:
        return Schema__CloudFront__Metrics(
            distribution_id   = self.distribution_id                  ,
            requests          = self.collect_requests()               ,
            bytes_downloaded  = self.collect_bytes_downloaded()        ,
            bytes_uploaded    = self.collect_bytes_uploaded()          ,
            error_rate_4xx    = self.collect_error_rate_4xx()          ,
            error_rate_5xx    = self.collect_error_rate_5xx()          ,
            cache_hit_rate    = self.collect_cache_hit_rate()          )

    def collect_requests(self) -> Schema__Metric__Series:
        return self.cloudwatch_client.get_cloudfront_metric(
            distribution_id  = self.distribution_id                   ,
            metric_name      = 'Requests'                             ,
            statistic        = 'Sum'                                  ,
            unit             = 'None'                                 ,  # CloudFront uses 'None' not 'Count'
            lookback_minutes = self.lookback_minutes                  ,
            period_seconds   = self.period_seconds                    )

    # collect_bytes_downloaded  — metric: BytesDownloaded, statistic: Sum, unit: None
    # collect_bytes_uploaded    — metric: BytesUploaded,   statistic: Sum, unit: None
    # collect_error_rate_4xx    — metric: 4xxErrorRate,    statistic: Average, unit: Percent
    # collect_error_rate_5xx    — metric: 5xxErrorRate,    statistic: Average, unit: Percent
    # collect_cache_hit_rate    — metric: CacheHitRate,    statistic: Average, unit: Percent
```

**CloudFront metric notes:**
- Unit is `'None'` for most CloudFront metrics (not `'Count'` or `'Bytes'`)
- Error rates and cache hit rate are percentages (0-100), statistic `Average`
- Minimum period is 60 seconds (not 300)
- All metrics require the `Region: Global` dimension alongside `DistributionId`

#### 5.4 Orchestrator

**File:** `sgraph_ai_app_send/lambda__admin/service/SGraph_Send__Metrics__Snapshot.py`

This is the equivalent of `Aws_Metrics_Snapshot` from the reference, adapted for SGraph Send.

```python
class SGraph_Send__Metrics__Snapshot(Type_Safe):
    # Configuration
    region               : Safe_Str__AWS__Region = 'eu-west-2'
    lookback_minutes     : Safe_UInt             = 60
    period_seconds       : Safe_UInt             = 300

    # Infrastructure identifiers (loaded from env vars or config)
    cloudfront_distribution_id : Safe_Str__Id                              # CloudFront distribution ID
    lambda_function_names      : List[Safe_Str__Id]                        # User + Admin function names
    s3_transfers_bucket        : Safe_Str__Id                              # Transfers bucket name
    s3_transfers_filter_id     : Safe_Str__Id                              # Transfers bucket request metrics filter
    s3_cache_bucket            : Safe_Str__Id                              # Cache service bucket name
    s3_cache_filter_id         : Safe_Str__Id                              # Cache bucket request metrics filter

    # Health thresholds
    thresholds : Schema__Thresholds__Config = None

    # Services (initialised in setup)
    cloudwatch_client  : CloudWatch__Client = None
    send_cache_client  : Send__Cache__Client = None                        # Injected — writes results to cache service

    def setup(self) -> 'SGraph_Send__Metrics__Snapshot':
        # Initialise CloudWatch client
        # Initialise thresholds with defaults if None
        # Lambda function names default to user + admin service names from config

    def collect_all(self) -> Schema__Metrics__Snapshot:
        # 1. Create collectors (CloudFront, Lambda, S3 × 2)
        # 2. Call collect() on each
        # 3. Evaluate health
        # 4. Assemble Schema__Metrics__Snapshot

    def evaluate_health(self, cloudfront, lambdas, s3_transfers, s3_cache) -> List[Schema__Health__Status]:
        # CloudFront: warn if 5xx error rate > threshold
        # Lambda: warn/critical based on aggregate error rate
        # S3: warn if 5xx errors > 0

    def save_to_cache(self, snapshot: Schema__Metrics__Snapshot):
        # Save the full snapshot as a temporal entry in NS_ANALYTICS
        # Also save per-component JSON for granular access
        # Use strategy='temporal' so history is preserved

    def run(self) -> dict:
        # setup() → collect_all() → save_to_cache() → return snapshot as dict
```

**Critical difference from reference:** The reference `Aws_Metrics_Snapshot` writes to local filesystem (`metrics/data/*.json`, `metrics/charts/*.png`). This orchestrator writes to the cache service via `Send__Cache__Client`. Chart rendering is deferred to Phase 1b (or handled client-side in the admin UI).

#### 5.5 LETS Aggregation Engine

**File:** `sgraph_ai_app_send/lambda__admin/service/Service__Analytics__Aggregator.py`

This is the core new component that has no equivalent in the reference architecture.

**Purpose:** Read raw events (from `Middleware__Analytics`) and/or lower-level aggregations, compute higher-level aggregations, save results back to the cache service.

**Design:**

```python
class Service__Analytics__Aggregator(Type_Safe):
    send_cache_client : Send__Cache__Client

    def aggregate_window(self, window_minutes: int) -> Schema__Aggregation__Window:
        # 1. Determine the time range for this window
        # 2. Check if a saved aggregation exists for this window
        # 3. If yes: load it, only process new events since last computation
        # 4. If no: process all raw events in the window
        # 5. Compute aggregation metrics:
        #    - total_requests (count)
        #    - unique_visitors (count of distinct ip_hash)
        #    - requests_by_type (page_view, api_call, file_upload, file_download)
        #    - requests_by_status (2xx, 3xx, 4xx, 5xx)
        #    - avg_duration_ms
        #    - p95_duration_ms
        #    - total_bytes
        #    - top_paths (top 20 by request count)
        #    - active_transfers
        # 6. Save aggregation to cache service (key_based, keyed by window label + timestamp)
        # 7. Return the aggregation

    def aggregate_30min(self) -> Schema__Aggregation__Window:
        return self.aggregate_window(window_minutes=30)

    def aggregate_hourly(self) -> Schema__Aggregation__Window:
        # Combine 2 × 30-minute aggregations (read saved, not raw events)
        # If 30-min aggregations don't exist, compute them first

    def aggregate_daily(self) -> Schema__Aggregation__Window:
        # Combine 24 × hourly aggregations

    def aggregate_all(self) -> dict:
        # Run 30min → hourly → daily cascade
        # Return dict of all computed aggregations
```

**Key principle:** Each level reads from the level below, never from raw events (except the 30-minute level). If a lower level is missing, compute it first.

**Storage strategy for aggregations:**

Use `key_based` strategy with a compound key encoding the window type and time boundary:

```
NS_ANALYTICS / aggregations / 30min  / 2026-02-15T14:00  → {aggregation data}
NS_ANALYTICS / aggregations / hourly / 2026-02-15T14:00  → {aggregation data}
NS_ANALYTICS / aggregations / daily  / 2026-02-15        → {aggregation data}
```

The `latest` folder maintained by the temporal strategy isn't used here — aggregations use explicit time-boundary keys so we can check "does the 14:00 hourly aggregation exist?" directly.

#### 5.6 Cache Client Extensions

**File:** `sgraph_ai_app_send/lambda__admin/service/Send__Cache__Client.py`

Add new methods to the existing class (do not create a new class):

```python
# ═══════════════════════════════════════════════════════════════════════
# AWS Metrics Operations
# ═══════════════════════════════════════════════════════════════════════

def metrics__save_snapshot(self, snapshot_data):                # Save CloudWatch metrics snapshot (temporal)
    return self.cache_client.store().store__json(
        namespace = NS_ANALYTICS ,
        strategy  = 'temporal'   ,
        body      = snapshot_data)

def metrics__save_component(self, component_name, data):       # Save per-component metrics (key_based)
    return self.cache_client.store().store__json__cache_key(
        namespace = NS_ANALYTICS          ,
        strategy  = 'key_based'           ,
        cache_key = f'metrics-{component_name}' ,
        file_id   = component_name        ,
        body      = data                  )

# ═══════════════════════════════════════════════════════════════════════
# Aggregation Operations
# ═══════════════════════════════════════════════════════════════════════

def aggregation__save(self, window_type, time_key, data):      # Save a computed aggregation
    cache_key = f'agg-{window_type}-{time_key}'
    return self.cache_client.store().store__json__cache_key(
        namespace = NS_ANALYTICS ,
        strategy  = 'key_based'  ,
        cache_key = cache_key    ,
        file_id   = cache_key    ,
        body      = data         )

def aggregation__lookup(self, window_type, time_key):          # Retrieve a saved aggregation
    cache_key  = f'agg-{window_type}-{time_key}'
    cache_hash = self.hash_generator.from_string(cache_key)
    response   = self.cache_client.retrieve().retrieve__hash__cache_hash__cache_id(
        cache_hash = str(cache_hash) ,
        namespace  = NS_ANALYTICS    )
    if response and response.get('cache_id'):
        return self.cache_client.retrieve().retrieve__cache_id__json(
            cache_id  = response.get('cache_id') ,
            namespace = NS_ANALYTICS              )
    return None

# ═══════════════════════════════════════════════════════════════════════
# Cost Operations
# ═══════════════════════════════════════════════════════════════════════

def costs__save(self, cost_data):                              # Save AWS cost data (temporal)
    return self.cache_client.store().store__json(
        namespace = NS_COSTS   ,
        strategy  = 'temporal' ,
        body      = cost_data  )
```

#### 5.7 Routes

**File:** `sgraph_ai_app_send/lambda__admin/fast_api/routes/Routes__Metrics.py`

```python
TAG__ROUTES_METRICS = 'metrics'

ROUTES_PATHS__METRICS = ['/metrics/snapshot'     ,
                         '/metrics/dashboard'    ,
                         '/metrics/aggregation'  ]

class Routes__Metrics(Fast_API__Routes):
    tag                      : str = TAG__ROUTES_METRICS
    send_cache_client        : Send__Cache__Client
    metrics_snapshot_service : SGraph_Send__Metrics__Snapshot = None

    def snapshot(self, lookback_minutes: Safe_UInt = 60) -> dict:
        # Run full metrics collection and return snapshot
        # Optionally save to cache

    def dashboard(self) -> HTMLResponse:
        # Generate HTML dashboard from latest snapshot/aggregations
        # Return as HTML response (not a file)

    def aggregation(self, window: str = '30min') -> dict:
        # Run or retrieve aggregation for the specified window
        # window: '30min', 'hourly', 'daily'
```

Register in `Fast_API__SGraph__App__Send__Admin.setup_routes()`:

```python
self.add_routes(Routes__Metrics,
                send_cache_client = self.send_cache_client)
```

#### 5.8 Dashboard Generator (Adapted)

**File:** `sgraph_ai_app_send/lambda__admin/service/Dashboard__Generator.py`

Port the `Dashboard__Html__Generator` pattern. The dashboard should cover CloudFront, Lambda, and S3 only. Brand as SGraph Send.

Sections:
1. **Header** — region, snapshot time, lookback, resolution
2. **Health Summary** — cards with ✅/⚠️/❌ per component
3. **Executive Summary** — KPIs (total requests, error rate, cache hit rate, active transfers)
4. **CloudFront** — requests, throughput, error rates, cache hit rate
5. **Lambda Functions** — invocations, errors, error rate, duration percentiles (table + charts)
6. **S3 Transfers Bucket** — get/put requests, latency, errors
7. **S3 Cache Bucket** — get/put requests, latency, errors
8. **Site Analytics** — data from LETS aggregations (unique visitors, top paths, requests by type)

Charts: In Phase 1 we can render charts inline using embedded SVG sparklines or simple HTML/CSS bar charts rather than requiring matplotlib PNG generation. This avoids adding matplotlib as a Lambda dependency. If full PNG charts are needed, defer to Phase 1b.

#### 5.9 Environment Variables

The orchestrator needs these env vars (add to deploy config):

```python
ENV_VAR__CLOUDFRONT_DISTRIBUTION_ID   = 'SGRAPH_SEND__CLOUDFRONT_DISTRIBUTION_ID'
ENV_VAR__S3_TRANSFERS_BUCKET          = 'SEND__S3_BUCKET'              # Already exists in user config
ENV_VAR__S3_TRANSFERS_FILTER_ID       = 'SGRAPH_SEND__S3_TRANSFERS_FILTER_ID'
ENV_VAR__S3_CACHE_FILTER_ID           = 'SGRAPH_SEND__S3_CACHE_FILTER_ID'
ENV_VAR__CACHE_BUCKET_NAME            = 'CACHE__SERVICE__BUCKET_NAME'  # Already exists in deploy
```

Add to `admin__config.py` and to `Deploy__Service.deploy_lambda()`.

#### 5.10 Lambda Dependencies

`boto3` is available in the Lambda runtime — do not add it to `APP__SEND__ADMIN__LAMBDA_DEPENDENCIES`. If chart rendering requires matplotlib, add it as a Lambda layer (not a pip dependency) due to its size. Prefer HTML/CSS/SVG charts to avoid this.

---

### Phase 2: CloudFront Logs + Cost Explorer (P2)

These are deferred and described here for architectural awareness. Do not implement until Phase 1 is complete and validated.

#### 6.1 CloudFront Log Collector

CloudFront delivers access logs as gzipped W3C files to an S3 bucket. Each log line contains: date, time, edge location, bytes, IP, method, host, URI path, status code, referrer, user agent, query string, cookie, result type, request ID, host header, protocol, bytes sent, time taken.

The collector would:
1. List new log files in the CloudFront log bucket (since last high-water mark)
2. Download and decompress each file
3. Parse each log line into a structured event
4. Hash IP addresses (privacy requirement from DPO)
5. Write events to cache service under `NS_ANALYTICS` with temporal strategy

This is the richest data source for replacing GA — it has every request to every asset, with timing, edge location, and cache status.

#### 6.2 Cost Explorer Collector

Uses `boto3.client('ce')` (not CloudWatch). The `GetCostAndUsage` API returns cost breakdowns by service, date, and various dimensions.

The collector would:
1. Query Cost Explorer for the configured time range
2. Break down by service (CloudFront, Lambda, S3, Data Transfer)
3. Write to cache service under `NS_COSTS` with temporal strategy
4. Compute unit economics: cost per request, cost per transfer, cost per GB

---

## 7. File Structure Summary

New files to create:

```
sgraph_ai_app_send/lambda__admin/
├── schemas/
│   ├── Schema__Metric__Series.py
│   ├── Schema__Metric__Dimension.py
│   ├── Schema__CloudFront__Metrics.py
│   ├── Schema__Lambda__Metrics.py
│   ├── Schema__S3__Metrics.py
│   ├── Schema__Metrics__Snapshot.py
│   ├── Schema__Health__Status.py
│   ├── Schema__Thresholds__Config.py
│   └── Schema__Aggregation__Window.py
├── service/
│   ├── CloudWatch__Client.py
│   ├── SGraph_Send__Metrics__Snapshot.py
│   ├── Service__Analytics__Aggregator.py
│   ├── Dashboard__Generator.py
│   └── collectors/
│       ├── __init__.py
│       ├── CloudFront__Metrics__Collector.py
│       ├── Lambda__Metrics__Collector.py
│       └── S3__Metrics__Collector.py
└── fast_api/
    └── routes/
        └── Routes__Metrics.py
```

Files to modify:

```
sgraph_ai_app_send/lambda__admin/
├── admin__config.py                    — add env var constants, Lambda deps if needed
├── service/
│   └── Send__Cache__Client.py          — add metrics__, aggregation__, costs__ methods
└── fast_api/
    └── Fast_API__SGraph__App__Send__Admin.py  — register Routes__Metrics
```

---

## 8. Implementation Sequence

Follow this order. Each step should be a testable, deployable increment.

```
Step 1: Schemas
         Create all Schema__* classes. No dependencies on services.
         Test: instantiate each with default values, verify json() serialisation.

Step 2: CloudWatch__Client
         Port and adapt. Add get_cloudfront_metric().
         Test: unit test with mocked boto3 client.

Step 3: Collectors (Lambda, S3, CloudFront)
         Port Lambda + S3, create CloudFront.
         Test: unit test each with mocked CloudWatch__Client.

Step 4: Send__Cache__Client extensions
         Add metrics__, aggregation__, costs__ methods.
         Test: integration test with in-memory cache service.

Step 5: SGraph_Send__Metrics__Snapshot orchestrator
         Wire collectors + cache client together.
         Test: integration test with mocked CloudWatch returning sample data.

Step 6: Service__Analytics__Aggregator
         Implement 30min aggregation first, then hourly, then daily.
         Test: write sample raw events to cache, run aggregation, verify output.

Step 7: Dashboard__Generator
         Port and adapt HTML dashboard.
         Test: generate from sample snapshot, verify HTML output.

Step 8: Routes__Metrics + FastAPI registration
         Wire everything into the admin API.
         Test: end-to-end via test client.

Step 9: Deploy configuration
         Add env vars to admin__config.py and Deploy__Service.
         Test: deploy to dev and run /metrics/snapshot.
```

---

## 9. Coding Standards

Follow the existing codebase conventions exactly:

- **Type_Safe everywhere.** All classes extend `Type_Safe`. All public methods use `@type_safe` decorator with typed parameters.
- **Typed primitives.** Use `Safe_UInt`, `Safe_Float`, `Safe_Str__Text`, `Safe_Str__Id`, `Safe_Str__File__Path`, `Timestamp_Now`, etc. Never use raw `str`, `int`, `float` in class attributes.
- **Formatting.** Follow the column-aligned formatting style used throughout the codebase (parameter alignment with spaces, comment alignment with `#`).
- **Comment headers.** Every file starts with a `# ═══...` header block with the class name and one-line description.
- **Imports.** One import per line, column-aligned, grouped by: stdlib → osbot_utils → other packages → local imports.
- **No raw dicts for data.** Use Type_Safe schema classes. The existing codebase has `# todo` comments flagging places where raw dicts should be replaced — don't create new ones.
- **Error handling in analytics.** Analytics/metrics code must never crash user-facing requests. Wrap in try/except where appropriate (see `Middleware__Analytics` pattern).
- **Lazy imports for boto3.** Import `boto3` inside `setup()` methods, not at module level.

---

## 10. Testing Strategy

- **Unit tests** for each schema, collector, and service (mocked dependencies)
- **Integration tests** using `create_send_cache_client()` (in-memory cache service, no AWS needed)
- **Live integration test** (equivalent to `test_Aws_Metrics_Snapshot__run`) that requires AWS credentials — guard with `pytest.skip('boto3 not installed')` pattern from reference

Test files go in the standard test mirror structure:
```
tests/unit/lambda__admin/schemas/test_Schema__Metric__Series.py
tests/unit/lambda__admin/service/test_CloudWatch__Client.py
tests/unit/lambda__admin/service/collectors/test_Lambda__Metrics__Collector.py
tests/integration/lambda__admin/service/test_SGraph_Send__Metrics__Snapshot__run.py
```

---

## 11. DevOps Prerequisites

Before the metrics pipeline can collect real data, DevOps must:

1. **Enable S3 request metrics** on both buckets (transfers + cache) with named filter IDs
2. **Note the CloudFront distribution ID** and provide it as an env var
3. **Verify CloudWatch permissions** — the Lambda execution role needs `cloudwatch:GetMetricStatistics` and `cloudwatch:GetMetricData`
4. **Verify CloudFront metrics are publishing** — CloudFront metrics may need "additional metrics" enabled in the distribution settings for cache hit rate and detailed error breakdowns
5. **Enable CloudFront access logging** to an S3 bucket (Phase 2, but should be enabled now so logs accumulate)
